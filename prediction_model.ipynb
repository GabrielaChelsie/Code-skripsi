{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b05b49c",
   "metadata": {},
   "source": [
    "## prediksi tanpa clustering (K-fold crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ccfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf00b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================\n",
      "Proses sheet cluster : Monthly_Fixed_clustered\n",
      "Output Excel sheet   : Monthly\n",
      "===================================================\n",
      "\n",
      "[Monthly_Fixed_clustered] Fold 1: MAE=73139.59 | RMSE=121950.09 | RPMSE=51.37% | R²=0.715\n",
      "[Monthly_Fixed_clustered] Fold 2: MAE=70907.72 | RMSE=119148.29 | RPMSE=48.16% | R²=0.770\n",
      "[Monthly_Fixed_clustered] Fold 3: MAE=77135.84 | RMSE=125754.90 | RPMSE=50.65% | R²=0.777\n",
      "[Monthly_Fixed_clustered] Fold 4: MAE=77756.11 | RMSE=135166.34 | RPMSE=55.52% | R²=0.784\n",
      "[Monthly_Fixed_clustered] Fold 5: MAE=76162.87 | RMSE=126805.85 | RPMSE=52.13% | R²=0.685\n",
      "\n",
      "=== Hasil 5-Fold Cross-Validation (Monthly_Fixed_clustered) ===\n",
      "MAE   : 75020.43 ± 2596.77\n",
      "RMSE  : 125765.10 ± 5436.97\n",
      "RPMSE : 51.56% ± 2.38%\n",
      "R²    : 0.746 ± 0.039\n",
      "\n",
      "Prediksi OOF tersimpan di file: catboost_oof_pred_without_cluster_feature.xlsx | sheet: Monthly\n",
      "\n",
      "===================================================\n",
      "Proses sheet cluster : Daily_Fixed_clustered\n",
      "Output Excel sheet   : Daily\n",
      "===================================================\n",
      "\n",
      "[Daily_Fixed_clustered] Fold 1: MAE=6259.37 | RMSE=9583.06 | RPMSE=28.90% | R²=0.799\n",
      "[Daily_Fixed_clustered] Fold 2: MAE=6514.28 | RMSE=9903.36 | RPMSE=27.52% | R²=0.818\n",
      "[Daily_Fixed_clustered] Fold 3: MAE=6402.96 | RMSE=10156.02 | RPMSE=29.99% | R²=0.772\n",
      "[Daily_Fixed_clustered] Fold 4: MAE=6652.30 | RMSE=9728.44 | RPMSE=28.24% | R²=0.819\n",
      "[Daily_Fixed_clustered] Fold 5: MAE=6506.80 | RMSE=9784.06 | RPMSE=29.17% | R²=0.771\n",
      "\n",
      "=== Hasil 5-Fold Cross-Validation (Daily_Fixed_clustered) ===\n",
      "MAE   : 6467.14 ± 130.66\n",
      "RMSE  : 9830.99 ± 192.39\n",
      "RPMSE : 28.76% ± 0.84%\n",
      "R²    : 0.796 ± 0.021\n",
      "\n",
      "Prediksi OOF tersimpan di file: catboost_oof_pred_without_cluster_feature.xlsx | sheet: Daily\n",
      "\n",
      "Semua hasil OOF tersimpan di file: catboost_oof_pred_without_cluster_feature.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Konfigurasi kolom\n",
    "\n",
    "FILE_CLUSTERED = \"D:/DATA SKRIPSI/kontrak_sewa_bersih.xlsx\"\n",
    "CLUSTER_COL    = \"cluster\"        \n",
    "PRICE_COL      = \"CuryUnitPrice\"  \n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\",\"LeaseMonthStart\",\"LeaseDayStart\",\n",
    "    \"LeaseMonthEnd\",\"LeaseDayEnd\",\"TranCode\",\n",
    "    \"ContractPeriod\",\"ContractType\",\"Building\", \"UnitArea\", \"UnitFloor\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"BuildingArea\",\"LeaseDurationDays\",\"LeaseDurationMonths\",\n",
    "    \"LeaseYearStart\",\"LeaseYearEnd\",\"n_subunit\"\n",
    "]\n",
    "\n",
    "# Konfigurasi per periode \n",
    "SHEET_CONFIGS = [\n",
    "    {\n",
    "        \"sheet_cluster\": \"Monthly_Fixed_clustered\",\n",
    "        \"sheet_name_out\": \"Monthly\",      \n",
    "    },\n",
    "    {\n",
    "        \"sheet_cluster\": \"Daily_Fixed_clustered\",\n",
    "        \"sheet_name_out\": \"Daily\",        \n",
    "    },\n",
    "]\n",
    "\n",
    "OUTPUT_FILE = \"catboost_oof_pred_without_cluster_feature.xlsx\"\n",
    "\n",
    "\n",
    "# Fungsi\n",
    "\n",
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_for_sheet(\n",
    "    file_path: str,\n",
    "    sheet_cluster: str,\n",
    "    sheet_name_out: str,\n",
    "    writer: pd.ExcelWriter,\n",
    "):\n",
    "    \"\"\"\n",
    "    Jalankan CatBoost + 5-fold CV untuk satu sheet *_Fixed_clustered\n",
    "    (tanpa menggunakan cluster sebagai fitur), lalu simpan OOF\n",
    "    (cluster, harga aktual, prediksi) ke sheet Excel.\n",
    "    \"\"\"\n",
    "    print(\"\\n===================================================\")\n",
    "    print(f\"Proses sheet cluster : {sheet_cluster}\")\n",
    "    print(f\"Output Excel sheet   : {sheet_name_out}\")\n",
    "    print(\"=============================================\\n\")\n",
    "\n",
    "    \n",
    "    # Load sheet utama \n",
    "    \n",
    "    try:\n",
    "        df_main = clean_columns(pd.read_excel(file_path, sheet_name=sheet_cluster))\n",
    "    except ValueError:\n",
    "        df_main = clean_columns(pd.read_excel(file_path, sheet_name=0))\n",
    "\n",
    "    \n",
    "    if CLUSTER_COL not in df_main.columns:\n",
    "        raise KeyError(\n",
    "            f\"Kolom cluster '{CLUSTER_COL}' tidak ditemukan di sheet '{sheet_cluster}'. \"\n",
    "            \"Pastikan hasil clustering sudah disimpan sebagai kolom tersebut.\"\n",
    "        )\n",
    "\n",
    "    \n",
    "    price_col = PRICE_COL\n",
    "    if price_col not in df_main.columns:\n",
    "        cands = [c for c in df_main.columns if \"price\" in c.lower()]\n",
    "        if not cands:\n",
    "            raise KeyError(\n",
    "                f\"Kolom target '{PRICE_COL}' tidak ditemukan dan tidak ada kolom mirip 'price' di sheet '{sheet_cluster}'.\"\n",
    "            )\n",
    "        price_col = cands[0]\n",
    "        print(f\"[INFO] Kolom {PRICE_COL} tidak ditemukan, pakai kolom mirip: {price_col}\")\n",
    "\n",
    "   \n",
    "    y_all = (\n",
    "        pd.to_numeric(df_main[price_col], errors=\"coerce\")\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    cat_all = [c for c in CATEGORICAL_COLS if c in df_main.columns]\n",
    "    num_all = [c for c in NUMERIC_COLS if c in df_main.columns]\n",
    "    feature_cols = cat_all + num_all   \n",
    "\n",
    "    X_all = df_main[feature_cols].copy()\n",
    "\n",
    "    # kategorikal -> string\n",
    "    for c in cat_all:\n",
    "        X_all[c] = X_all[c].astype(str)\n",
    "\n",
    "    # numerik -> float\n",
    "    for c in num_all:\n",
    "        X_all[c] = pd.to_numeric(X_all[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    keep_mask = ~y_all.isna()\n",
    "    X = X_all.loc[keep_mask].reset_index(drop=True)\n",
    "    y = y_all.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    # index kolom kategorikal untuk CatBoost\n",
    "    cat_feature_idx = [X.columns.get_loc(c) for c in cat_all]\n",
    "\n",
    "    \n",
    "    # 5-Fold Cross Validation dengan CatBoost\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mae_scores, rmse_scores, r2_scores, rpmse_scores = [], [], [], []\n",
    "\n",
    "    # oof_pred untuk seluruh df_main (index asli)\n",
    "    oof_pred = np.full(len(df_main), np.nan)\n",
    "    idx_map  = np.where(keep_mask)[0]\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X), 1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "        valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"RMSE\",\n",
    "            depth=8,\n",
    "            learning_rate=0.05,\n",
    "            l2_leaf_reg=3.0,\n",
    "            iterations=2000,\n",
    "            random_seed=42,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=100,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "        pred_va = model.predict(valid_pool)\n",
    "        oof_pred[idx_map[va_idx]] = pred_va\n",
    "\n",
    "        # metrik\n",
    "        mae   = mean_absolute_error(y_va, pred_va)\n",
    "        rmse  = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "        r2    = r2_score(y_va, pred_va)\n",
    "        rpmse = (rmse / np.mean(y_va)) * 100  # RPMSE (%)\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        rpmse_scores.append(rpmse)\n",
    "\n",
    "        print(\n",
    "            f\"[{sheet_cluster}] Fold {fold}: \"\n",
    "            f\"MAE={mae:.2f} | RMSE={rmse:.2f} | RPMSE={rpmse:.2f}% | R²={r2:.3f}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n=== Hasil 5-Fold Cross-Validation ({sheet_cluster}) ===\")\n",
    "    print(f\"MAE   : {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "    print(f\"RMSE  : {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")\n",
    "    print(f\"RPMSE : {np.mean(rpmse_scores):.2f}% ± {np.std(rpmse_scores):.2f}%\")\n",
    "    print(f\"R²    : {np.mean(r2_scores):.3f} ± {np.std(r2_scores):.3f}\")\n",
    "\n",
    "    \n",
    "    # Simpan hasil OOF \n",
    "    \n",
    "    df_out = df_main.copy()\n",
    "    df_out[\"oof_pred\"] = oof_pred\n",
    "\n",
    "    if price_col not in df_out.columns:\n",
    "        df_out[price_col] = y_all.values\n",
    "\n",
    "    cols_to_save = [CLUSTER_COL, price_col, \"oof_pred\"]\n",
    "    df_out[cols_to_save].to_excel(\n",
    "        writer,\n",
    "        sheet_name=sheet_name_out,\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\nPrediksi OOF tersimpan di file: {OUTPUT_FILE} | sheet: {sheet_name_out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with pd.ExcelWriter(OUTPUT_FILE) as writer:\n",
    "        for cfg in SHEET_CONFIGS:\n",
    "            run_for_sheet(\n",
    "                file_path=FILE_CLUSTERED,\n",
    "                sheet_cluster=cfg[\"sheet_cluster\"],\n",
    "                sheet_name_out=cfg[\"sheet_name_out\"],\n",
    "                writer=writer,\n",
    "            )\n",
    "\n",
    "    print(f\"\\nSemua hasil OOF tersimpan di file: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b2c03",
   "metadata": {},
   "source": [
    "## Prediksi pakai walk forwad CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39690efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=== PROSES SHEET: Monthly_Fixed ===\n",
      "Kolom di file: ['RowID', 'ContractType', 'ContractPeriod', 'BusinessType', 'TranCode', 'BuildingArea', 'CuryUnitPrice', 'LeaseYearStart', 'LeaseMonthStart', 'LeaseDayStart', 'LeaseYearEnd', 'LeaseMonthEnd', 'LeaseDayEnd', 'LeaseDurationDays', 'LeaseDurationMonths', 'n_subunit', 'Building', 'UnitArea', 'UnitFloor', 'UnitNum', 'UnitID']\n",
      "\n",
      "Deskripsi CuryUnitPrice (setelah parsing):\n",
      "count    3.914000e+03\n",
      "mean     2.439664e+05\n",
      "std      2.531769e+05\n",
      "min      9.000000e+03\n",
      "25%      6.750000e+04\n",
      "50%      1.750000e+05\n",
      "75%      3.000000e+05\n",
      "max      2.444444e+06\n",
      "Name: CuryUnitPrice, dtype: float64\n",
      "\n",
      "Range tanggal sewa: 2015-01-01 00:00:00 -> 2025-04-23 00:00:00\n",
      "\n",
      "Jumlah data : 3914\n",
      "Jumlah fitur: 32\n",
      "Fitur kategorik: ['Building', 'BusinessType', 'ContractPeriod', 'ContractType', 'TranCode', 'UnitArea', 'UnitFloor']\n",
      "Fold 1: MAE=83,749.57 | RMSE=159,351.99 | RPMSE=62.96% | R²=0.510\n",
      "Fold 2: MAE=85,195.63 | RMSE=150,598.46 | RPMSE=64.24% | R²=0.495\n",
      "Fold 3: MAE=91,298.24 | RMSE=156,279.51 | RPMSE=66.43% | R²=0.523\n",
      "Fold 4: MAE=91,398.58 | RMSE=149,817.88 | RPMSE=62.69% | R²=0.519\n",
      "Fold 5: MAE=135,851.69 | RMSE=331,684.42 | RPMSE=137.86% | R²=0.223\n",
      "\n",
      "=== Hasil Walk-Forward CV (Monthly_Fixed, LOG TARGET) ===\n",
      "MAE   : 97,498.74 ± 19,426.85\n",
      "RMSE  : 189,546.45 ± 71,157.44\n",
      "RPMSE : 78.84% ± 29.54%\n",
      "R²    : 0.454 ± 0.116\n",
      "\n",
      "Model final untuk sheet 'Monthly_Fixed' telah dilatih (tidak disimpan ke file).\n",
      "Catatan: model memprediksi log1p(CuryUnitPrice), jadi saat inferensi perlu np.expm1(pred).\n",
      "\n",
      "Preview OOF DF untuk sheet: Monthly_Fixed\n",
      "  LeaseStartDate LeaseEndDate Building          UnitID UnitNum  BusinessType  \\\n",
      "0     2015-01-01   2015-04-30      0PW  0PW000UG000039  000039            99   \n",
      "1     2015-01-01   2015-01-31      0PW  0PW00004000073  000073            99   \n",
      "2     2015-01-01   2015-12-31      0PE  0PE00K02000003  000003            99   \n",
      "3     2015-01-01   2015-06-30      0PE  0PE00KLG000018  000018            99   \n",
      "4     2015-01-01   2016-03-03      0PE  0PEATN04000001  000001            99   \n",
      "\n",
      "     ContractType ContractPeriod  CuryUnitPrice  oof_pred  fold  abs_error  \\\n",
      "0         Leasing        Monthly       250000.0       0.0     0   250000.0   \n",
      "1         Leasing        Monthly       160000.0       0.0     0   160000.0   \n",
      "2  Casual Leasing        Monthly        20000.0       0.0     0    20000.0   \n",
      "3  Casual Leasing        Monthly       250000.0       0.0     0   250000.0   \n",
      "4         Leasing        Monthly       168000.0       0.0     0   168000.0   \n",
      "\n",
      "     ape  \n",
      "0  100.0  \n",
      "1  100.0  \n",
      "2  100.0  \n",
      "3  100.0  \n",
      "4  100.0  \n",
      "Kolom OOF DF: ['LeaseStartDate', 'LeaseEndDate', 'Building', 'UnitID', 'UnitNum', 'BusinessType', 'ContractType', 'ContractPeriod', 'CuryUnitPrice', 'oof_pred', 'fold', 'abs_error', 'ape']\n",
      "\n",
      "================================================================================\n",
      "=== PROSES SHEET: Daily_Fixed ===\n",
      "Kolom di file: ['ContractType', 'ContractPeriod', 'BusinessType', 'TranCode', 'BuildingArea', 'CuryUnitPrice', 'LeaseYearStart', 'LeaseMonthStart', 'LeaseDayStart', 'LeaseYearEnd', 'LeaseMonthEnd', 'LeaseDayEnd', 'LeaseDurationDays', 'LeaseDurationMonths', 'n_subunit', 'Building', 'UnitArea', 'UnitFloor', 'UnitNum', 'UnitID', 'RowID']\n",
      "\n",
      "Deskripsi CuryUnitPrice (setelah parsing):\n",
      "count     2773.000000\n",
      "mean     34200.389486\n",
      "std      21885.283765\n",
      "min      10000.000000\n",
      "25%      18750.000000\n",
      "50%      27000.000000\n",
      "75%      43214.285750\n",
      "max      99642.857500\n",
      "Name: CuryUnitPrice, dtype: float64\n",
      "\n",
      "Range tanggal sewa: 2015-01-05 00:00:00 -> 2025-09-06 00:00:00\n",
      "\n",
      "Jumlah data : 2773\n",
      "Jumlah fitur: 32\n",
      "Fitur kategorik: ['Building', 'BusinessType', 'ContractPeriod', 'ContractType', 'TranCode', 'UnitArea', 'UnitFloor']\n",
      "Fold 1: MAE=3,400.88 | RMSE=7,163.10 | RPMSE=21.51% | R²=0.878\n",
      "Fold 2: MAE=3,311.53 | RMSE=7,735.67 | RPMSE=20.35% | R²=0.907\n",
      "Fold 3: MAE=1,536.74 | RMSE=3,241.71 | RPMSE=8.72% | R²=0.982\n",
      "Fold 4: MAE=2,525.94 | RMSE=5,381.94 | RPMSE=16.81% | R²=0.934\n",
      "Fold 5: MAE=1,125.79 | RMSE=1,963.88 | RPMSE=6.09% | R²=0.989\n",
      "\n",
      "=== Hasil Walk-Forward CV (Daily_Fixed, LOG TARGET) ===\n",
      "MAE   : 2,380.18 ± 918.19\n",
      "RMSE  : 5,097.26 ± 2,216.81\n",
      "RPMSE : 14.70% ± 6.20%\n",
      "R²    : 0.938 ± 0.043\n",
      "\n",
      "Model final untuk sheet 'Daily_Fixed' telah dilatih (tidak disimpan ke file).\n",
      "Catatan: model memprediksi log1p(CuryUnitPrice), jadi saat inferensi perlu np.expm1(pred).\n",
      "\n",
      "Preview OOF DF untuk sheet: Daily_Fixed\n",
      "  LeaseStartDate LeaseEndDate Building          UnitID  UnitNum  BusinessType  \\\n",
      "0     2015-01-05   2015-01-18      0PC  0PCP01LG000011       11            99   \n",
      "1     2015-01-05   2015-01-11      0PC  0PCP0102000011       11            99   \n",
      "2     2015-01-05   2015-01-18      0PE  0PEATRLG000011       11            99   \n",
      "3     2015-01-05   2015-01-11      0PC  0PCP0105000012       12            99   \n",
      "4     2015-01-05   2015-01-11      0PW  0PWATRUG000001        1            99   \n",
      "\n",
      "     ContractType ContractPeriod  CuryUnitPrice  oof_pred  fold  abs_error  \\\n",
      "0  Casual Leasing          Daily        12000.0       0.0     0    12000.0   \n",
      "1  Casual Leasing          Daily        12375.0       0.0     0    12375.0   \n",
      "2  Casual Leasing          Daily        85000.0       0.0     0    85000.0   \n",
      "3  Casual Leasing          Daily        22000.0       0.0     0    22000.0   \n",
      "4  Casual Leasing          Daily        22000.0       0.0     0    22000.0   \n",
      "\n",
      "     ape  \n",
      "0  100.0  \n",
      "1  100.0  \n",
      "2  100.0  \n",
      "3  100.0  \n",
      "4  100.0  \n",
      "Kolom OOF DF: ['LeaseStartDate', 'LeaseEndDate', 'Building', 'UnitID', 'UnitNum', 'BusinessType', 'ContractType', 'ContractPeriod', 'CuryUnitPrice', 'oof_pred', 'fold', 'abs_error', 'ape']\n",
      "\n",
      "Semua OOF prediction tersimpan di file Excel: hasil_catboost_oof_pred.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "def parse_num_id(value):\n",
    "   \n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "\n",
    "    if isinstance(value, (int, float, np.integer, np.floating)):\n",
    "        return float(value)\n",
    "\n",
    "    s = str(value).strip()\n",
    "    if s == \"\":\n",
    "        return np.nan\n",
    "\n",
    "    s = s.replace(\" \", \"\")\n",
    "\n",
    "    if \",\" in s:\n",
    "        left, right = s.split(\",\", 1)\n",
    "        left = left.replace(\".\", \"\")\n",
    "        s_clean = left + \".\" + right\n",
    "        try:\n",
    "            return float(s_clean)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    " \n",
    "    else:\n",
    "        s_clean = s.replace(\".\", \"\")\n",
    "        try:\n",
    "            return float(s_clean)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "def train_catboost_for_sheet(FILE_PATH, SHEET_NAME, model_suffix):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"=== PROSES SHEET: {SHEET_NAME} ===\")\n",
    "\n",
    "    df = pd.read_excel(FILE_PATH, sheet_name=SHEET_NAME)\n",
    "\n",
    "    print(\"Kolom di file:\", list(df.columns))\n",
    "\n",
    "    # parse kolom numerik\n",
    "    numeric_cols = [\n",
    "        'BuildingArea',\n",
    "        'CuryUnitPrice',\n",
    "        'LeaseDuration',\n",
    "        'DurationMonth',\n",
    "        'LeaseDurationDays',\n",
    "        'LeaseDurationMonths',\n",
    "        'n_subunit'\n",
    "    ]\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(parse_num_id)\n",
    "\n",
    "    TARGET_COL = 'CuryUnitPrice'\n",
    "    if TARGET_COL not in df.columns:\n",
    "        raise ValueError(f\"Kolom '{TARGET_COL}' (target) tidak ditemukan di sheet {SHEET_NAME}.\")\n",
    "\n",
    "    print(\"\\nDeskripsi CuryUnitPrice (setelah parsing):\")\n",
    "    print(df[TARGET_COL].describe())\n",
    "\n",
    "    # urutkan tanggal\n",
    "\n",
    "    # Tanggal mulai sewa\n",
    "    if {'LeaseYearStart', 'LeaseMonthStart', 'LeaseDayStart'}.issubset(df.columns):\n",
    "        df['LeaseStartDate'] = pd.to_datetime(\n",
    "            dict(\n",
    "                year=df['LeaseYearStart'],\n",
    "                month=df['LeaseMonthStart'],\n",
    "                day=df['LeaseDayStart']\n",
    "            ),\n",
    "            errors='coerce'\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Kolom LeaseYearStart/LeaseMonthStart/LeaseDayStart tidak lengkap di sheet {SHEET_NAME}.\"\n",
    "        )\n",
    "\n",
    "    # Tanggal akhir sewa\n",
    "    if {'LeaseYearEnd', 'LeaseMonthEnd', 'LeaseDayEnd'}.issubset(df.columns):\n",
    "        df['LeaseEndDate'] = pd.to_datetime(\n",
    "            dict(\n",
    "                year=df['LeaseYearEnd'],\n",
    "                month=df['LeaseMonthEnd'],\n",
    "                day=df['LeaseDayEnd']\n",
    "            ),\n",
    "            errors='coerce'\n",
    "        )\n",
    "    else:\n",
    "        df['LeaseEndDate'] = pd.NaT\n",
    "\n",
    "    df = df.dropna(subset=['LeaseStartDate'])\n",
    "    df = df.sort_values('LeaseStartDate').reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nRange tanggal sewa:\", df['LeaseStartDate'].min(), \"->\", df['LeaseStartDate'].max())\n",
    "\n",
    "\n",
    "    df = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "    # --- fitur tanggal dasar ---\n",
    "    df['Year'] = df['LeaseStartDate'].dt.year\n",
    "    df['Month'] = df['LeaseStartDate'].dt.month\n",
    "    df['Quarter'] = df['LeaseStartDate'].dt.quarter\n",
    "\n",
    "    df['YearMonth'] = df['LeaseStartDate'].dt.to_period('M')\n",
    "    df['TrendIndex'] = (df['YearMonth'] - df['YearMonth'].min()).apply(lambda x: x.n)\n",
    "\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "\n",
    "    df = df.sort_values('LeaseStartDate').reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    df['global_mean_target'] = df[TARGET_COL].expanding().mean().shift(1)\n",
    "    overall_mean = df[TARGET_COL].mean()\n",
    "    df['global_mean_target'] = df['global_mean_target'].fillna(overall_mean)\n",
    "\n",
    "    # Lag & rolling per Building \n",
    "    if 'Building' in df.columns:\n",
    "        g_bld = df.groupby('Building', group_keys=False)\n",
    "        df['lag1_bld'] = g_bld[TARGET_COL].shift(1)\n",
    "        df['lag3_bld'] = g_bld[TARGET_COL].shift(3)\n",
    "        df['lag6_bld'] = g_bld[TARGET_COL].shift(6)\n",
    "        df['roll3_bld'] = g_bld[TARGET_COL].shift(1).rolling(window=3, min_periods=1).mean()\n",
    "        df['roll6_bld'] = g_bld[TARGET_COL].shift(1).rolling(window=6, min_periods=1).mean()\n",
    "    else:\n",
    "        df['lag1_bld'] = df['lag3_bld'] = df['lag6_bld'] = np.nan\n",
    "        df['roll3_bld'] = df['roll6_bld'] = np.nan\n",
    "\n",
    "    if {'Building', 'BusinessType'}.issubset(df.columns):\n",
    "        g_bb = df.groupby(['Building', 'BusinessType'], group_keys=False)\n",
    "        df['lag1_bld_bus'] = g_bb[TARGET_COL].shift(1)\n",
    "        df['roll3_bld_bus'] = g_bb[TARGET_COL].shift(1).rolling(window=3, min_periods=1).mean()\n",
    "    else:\n",
    "        df['lag1_bld_bus'] = df['roll3_bld_bus'] = np.nan\n",
    "\n",
    "    for col in [\n",
    "        'lag1_bld', 'lag3_bld', 'lag6_bld',\n",
    "        'roll3_bld', 'roll6_bld',\n",
    "        'lag1_bld_bus', 'roll3_bld_bus'\n",
    "    ]:\n",
    "        df[col] = df[col].fillna(df['global_mean_target'])\n",
    "\n",
    "    # siapkan fitur numerik & kategorik\n",
    "    drop_cols = [TARGET_COL, 'LeaseStartDate', 'LeaseEndDate', 'YearMonth']\n",
    "    drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "    remove_features = ['UnitID', 'UnitNum']\n",
    "    feature_cols = [c for c in feature_cols if c not in remove_features]\n",
    "\n",
    "    X = df[feature_cols].copy()\n",
    "    y_raw = df[TARGET_COL].copy()\n",
    "    y = np.log1p(y_raw)           \n",
    "\n",
    "    # Kategori eksplisit\n",
    "    explicit_cat = [\n",
    "        'ContractType',\n",
    "        'ContractPeriod',\n",
    "        'BusinessType',\n",
    "        'TranCode',\n",
    "        'Building',\n",
    "        'UnitArea',\n",
    "        'UnitFloor'\n",
    "    ]\n",
    "    explicit_cat = [c for c in explicit_cat if c in X.columns]\n",
    "    auto_cat = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    cat_cols = sorted(list(set(explicit_cat) | set(auto_cat)))\n",
    "\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].astype(str)\n",
    "\n",
    "    cat_idx = [X.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    print(\"\\nJumlah data :\", len(df))\n",
    "    print(\"Jumlah fitur:\", len(feature_cols))\n",
    "    print(\"Fitur kategorik:\", cat_cols)\n",
    "\n",
    "    # catboost + walkforwardCV\n",
    "\n",
    "    def rpmse(y_true, y_pred):\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "        return rmse / np.mean(y_true) * 100.0, rmse\n",
    "\n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    fold_results = []\n",
    "    oof_pred = np.zeros(len(df))\n",
    "    fold_id = np.zeros(len(df), dtype=int)  \n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X, y), start=1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_log, y_val_log = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        y_val_true = y_raw.iloc[val_idx]  \n",
    "\n",
    "        train_pool = Pool(X_train, y_train_log, cat_features=cat_idx)\n",
    "        val_pool = Pool(X_val, y_val_log, cat_features=cat_idx)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function='RMSE',\n",
    "            depth=6,\n",
    "            learning_rate=0.03,\n",
    "            n_estimators=3000,\n",
    "            random_seed=42,\n",
    "            l2_leaf_reg=8,\n",
    "            random_strength=1.5,\n",
    "            bagging_temperature=1.0,\n",
    "            eval_metric='RMSE',\n",
    "            od_type='Iter',\n",
    "            od_wait=100,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "        y_val_pred_log = model.predict(X_val)\n",
    "        y_val_pred = np.expm1(y_val_pred_log)  \n",
    "        oof_pred[val_idx] = y_val_pred\n",
    "        fold_id[val_idx] = fold  \n",
    "\n",
    "        mae = mean_absolute_error(y_val_true, y_val_pred)\n",
    "        rp, rmse = rpmse(y_val_true, y_val_pred)\n",
    "        r2 = r2_score(y_val_true, y_val_pred)\n",
    "\n",
    "        fold_results.append((mae, rmse, rp, r2))\n",
    "\n",
    "        print(f\"Fold {fold}: MAE={mae:,.2f} | RMSE={rmse:,.2f} | RPMSE={rp:.2f}% | R²={r2:.3f}\")\n",
    "\n",
    "    mae_list, rmse_list, rp_list, r2_list = map(np.array, zip(*fold_results))\n",
    "\n",
    "    print(f\"\\n=== Hasil Walk-Forward CV ({SHEET_NAME}, LOG TARGET) ===\")\n",
    "    print(f\"MAE   : {mae_list.mean():,.2f} ± {mae_list.std():,.2f}\")\n",
    "    print(f\"RMSE  : {rmse_list.mean():,.2f} ± {rmse_list.std():,.2f}\")\n",
    "    print(f\"RPMSE : {rp_list.mean():.2f}% ± {rp_list.std():.2f}%\")\n",
    "    print(f\"R²    : {r2_list.mean():.3f} ± {r2_list.std():.3f}\")\n",
    "\n",
    "    # train model final\n",
    "    final_pool = Pool(X, y, cat_features=cat_idx)\n",
    "    final_model = CatBoostRegressor(\n",
    "        loss_function='RMSE',\n",
    "        depth=6,\n",
    "        learning_rate=0.03,\n",
    "        n_estimators=3000,\n",
    "        random_seed=42,\n",
    "        l2_leaf_reg=8,\n",
    "        random_strength=1.5,\n",
    "        bagging_temperature=1.0,\n",
    "        eval_metric='RMSE',\n",
    "        od_type='Iter',\n",
    "        od_wait=100,\n",
    "        verbose=False\n",
    "    )\n",
    "    final_model.fit(final_pool)\n",
    "\n",
    "    print(f\"\\nModel final untuk sheet '{SHEET_NAME}' telah dilatih (tidak disimpan ke file).\")\n",
    "    print(\"Catatan: model memprediksi log1p(CuryUnitPrice), jadi saat inferensi perlu np.expm1(pred).\")\n",
    "\n",
    "    # simpan hasil prediksi\n",
    "\n",
    "    id_cols = [\n",
    "        'LeaseStartDate', 'LeaseEndDate',\n",
    "        'Building', 'UnitID', 'UnitNum',\n",
    "        'BusinessType', 'ContractType', 'ContractPeriod'\n",
    "    ]\n",
    "    id_cols = [c for c in id_cols if c in df.columns]\n",
    "\n",
    "    oof_df = df[id_cols].copy()\n",
    "\n",
    "    oof_df['CuryUnitPrice'] = y_raw.values      \n",
    "    oof_df['oof_pred'] = oof_pred              \n",
    "    oof_df['fold'] = fold_id                   \n",
    "    oof_df['abs_error'] = (oof_df['CuryUnitPrice'] - oof_df['oof_pred']).abs()\n",
    "    oof_df['ape'] = oof_df['abs_error'] / oof_df['CuryUnitPrice'] * 100.0\n",
    "\n",
    "    \n",
    "    print(\"\\nPreview OOF DF untuk sheet:\", SHEET_NAME)\n",
    "    print(oof_df.head())\n",
    "    print(\"Kolom OOF DF:\", list(oof_df.columns))\n",
    "\n",
    "    return oof_df  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FILE_PATH = \"D:/DATA SKRIPSI/kontrak_sewa_bersih.xlsx\"  \n",
    "\n",
    "    \n",
    "    sheets_to_run = {\n",
    "        \"Monthly_Fixed\": \"monthly_sheet\",\n",
    "        \"Daily_Fixed\": \"daily_sheet\"\n",
    "    }\n",
    "\n",
    "    all_oof = {}\n",
    "\n",
    "    for sheet_name, suffix in sheets_to_run.items():\n",
    "        oof_df = train_catboost_for_sheet(FILE_PATH, sheet_name, suffix)\n",
    "        all_oof[sheet_name] = oof_df\n",
    "\n",
    "    output_excel = \"hasil_catboost_oof_pred.xlsx\"\n",
    "\n",
    "    with pd.ExcelWriter(output_excel) as writer:\n",
    "        for sheet_name, oof_df in all_oof.items():\n",
    "            oof_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"\\nSemua OOF prediction tersimpan di file Excel: {output_excel}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8187ca6",
   "metadata": {},
   "source": [
    "## Prediksi + clustering (K-prototypes) (K-fold crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d02b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CLUSTERED = r\"D:/DATA SKRIPSI/kontrak_sewa_bersih_clustered.xlsx\"\n",
    "INFLATION_FILE = r\"D:/DATA SKRIPSI/Laju Inflasi Di Kota Surabaya Tahun 2006-2020.csv\"\n",
    "PDRB_FILE = r\"D:/DATA SKRIPSI/Laju Pertumbuhan Produk Domestik Regional Bruto Atas Dasar Harga Konstan 2010 Menurut Lapangan Usaha di Kota Surabaya (persen), 2024.csv\"\n",
    "\n",
    "CLUSTER_COL = \"cluster\"\n",
    "\n",
    "SHEET_CONFIGS = [\n",
    "    {\n",
    "        \"freq_name\": \"Monthly\",\n",
    "        \"SHEET_CLUSTER\": \"Monthly_Fixed_clustered\",\n",
    "        \"PRICE_COL\": \"CuryUnitPrice\",\n",
    "        \"sheet_name_out\": \"Monthly\",\n",
    "    },\n",
    "    {\n",
    "        \"freq_name\": \"Daily\",\n",
    "        \"SHEET_CLUSTER\": \"Daily_Fixed_clustered\",\n",
    "        \"PRICE_COL\": \"CuryUnitPrice\",\n",
    "        \"sheet_name_out\": \"Daily\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\", \"LeaseMonthStart\", \"LeaseDayStart\",\n",
    "    \"LeaseMonthEnd\", \"LeaseDayEnd\", \"TranCode\",\n",
    "    \"ContractPeriod\", \"ContractType\", \"Building\",\n",
    "    \"UnitArea\", \"UnitFloor\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"BuildingArea\", \"LeaseDurationDays\", \"LeaseDurationMonths\",\n",
    "    \"LeaseYearStart\", \"LeaseYearEnd\", \"n_subunit\",\n",
    "]\n",
    "\n",
    "\n",
    "PLOT_SHAP_SUMMARY = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffbe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Proses sheet: Monthly_Fixed_clustered\n",
      "Output sheet: Monthly_OOF\n",
      "==============================\n",
      "\n",
      "Fold 1: MAE=30328.69 | RMSE=47588.57 | RPMSE=20.05% | R²=0.957\n",
      "Fold 2: MAE=37558.73 | RMSE=66962.05 | RPMSE=27.07% | R²=0.927\n",
      "Fold 3: MAE=32963.66 | RMSE=52074.25 | RPMSE=20.97% | R²=0.962\n",
      "Fold 4: MAE=37630.79 | RMSE=64469.69 | RPMSE=26.48% | R²=0.951\n",
      "Fold 5: MAE=32927.63 | RMSE=51777.19 | RPMSE=21.28% | R²=0.948\n",
      "\n",
      "=== Hasil 5-Fold Cross-Validation ( Monthly_OOF ) ===\n",
      "MAE   : 34281.90 ± 2868.88\n",
      "RMSE  : 56574.35 ± 7671.36\n",
      "RPMSE : 23.17% ± 2.98%\n",
      "R²    : 0.949 ± 0.012\n",
      "\n",
      "Prediksi OOF untuk 'Monthly_OOF' tersimpan di file Excel (sheet: Monthly_OOF)\n",
      "\n",
      "==============================\n",
      "Proses sheet: Daily_Fixed_clustered\n",
      "Output sheet: Daily_OOF\n",
      "==============================\n",
      "\n",
      "Fold 1: MAE=2963.75 | RMSE=3971.00 | RPMSE=11.98% | R²=0.966\n",
      "Fold 2: MAE=3221.35 | RMSE=4377.32 | RPMSE=12.16% | R²=0.964\n",
      "Fold 3: MAE=2986.94 | RMSE=4136.26 | RPMSE=12.21% | R²=0.962\n",
      "Fold 4: MAE=3095.76 | RMSE=4356.46 | RPMSE=12.64% | R²=0.964\n",
      "Fold 5: MAE=3032.07 | RMSE=4022.85 | RPMSE=11.99% | R²=0.961\n",
      "\n",
      "=== Hasil 5-Fold Cross-Validation ( Daily_OOF ) ===\n",
      "MAE   : 3059.97 ± 92.41\n",
      "RMSE  : 4172.78 ± 167.39\n",
      "RPMSE : 12.20% ± 0.24%\n",
      "R²    : 0.963 ± 0.002\n",
      "\n",
      "Prediksi OOF untuk 'Daily_OOF' tersimpan di file Excel (sheet: Daily_OOF)\n",
      "\n",
      "Semua hasil OOF tersimpan di file: catboost_oof_pred_with_cluster.xlsx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Konfigurasi umum\n",
    "\n",
    "FILE_CLUSTERED = \"D:/DATA SKRIPSI/kontrak_sewa_bersih_clustered.xlsx\"\n",
    "\n",
    "SHEET_CLUSTER_MONTHLY = \"Monthly_Fixed_clustered\"\n",
    "SHEET_CLUSTER_DAILY   = \"Daily_Fixed_clustered\"\n",
    "\n",
    "CLUSTER_COL = \"cluster\"          \n",
    "PRICE_COL   = \"CuryUnitPrice\"    \n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\",\"LeaseMonthStart\",\"LeaseDayStart\",\n",
    "    \"LeaseMonthEnd\",\"LeaseDayEnd\",\"TranCode\",\n",
    "    \"ContractPeriod\",\"ContractType\",\"Building\", \"UnitArea\", \"UnitFloor\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"BuildingArea\",\"LeaseDurationDays\",\"LeaseDurationMonths\",\n",
    "    \"LeaseYearStart\",\"LeaseYearEnd\",\"n_subunit\"\n",
    "]\n",
    "\n",
    "\n",
    "# Fungsi bantu\n",
    "\n",
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def run_catboost_for_sheet(\n",
    "    file_path: str,\n",
    "    sheet_cluster: str,\n",
    "    out_sheet_name: str,\n",
    "    writer: pd.ExcelWriter\n",
    "):\n",
    "    \"\"\"\n",
    "    Jalankan pipeline CatBoost + 5-fold CV untuk satu sheet *_Fixed_clustered,\n",
    "    lalu simpan hasil OOF (cluster, harga aktual, prediksi) ke sheet Excel.\n",
    "    \"\"\"\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Proses sheet: {sheet_cluster}\")\n",
    "    print(f\"Output sheet: {out_sheet_name}\")\n",
    "    print(f\"==============================\\n\")\n",
    "\n",
    "    try:\n",
    "        df_main = clean_columns(pd.read_excel(file_path, sheet_name=sheet_cluster))\n",
    "    except ValueError:\n",
    "        df_main = clean_columns(pd.read_excel(file_path, sheet_name=0))\n",
    "\n",
    "    for col in [CLUSTER_COL, PRICE_COL]:\n",
    "        if col not in df_main.columns:\n",
    "            raise KeyError(\n",
    "                f\"Kolom '{col}' tidak ditemukan di sheet '{sheet_cluster}'. \"\n",
    "                \"Pastikan hasil clustering & CuryUnitPrice sudah ada di sheet tersebut.\"\n",
    "            )\n",
    "\n",
    "    y_all = pd.to_numeric(df_main[PRICE_COL], errors=\"coerce\").astype(float)\n",
    "\n",
    "    \n",
    "    all_cat_cols = CATEGORICAL_COLS + [CLUSTER_COL]\n",
    "\n",
    "    cat_all = [c for c in all_cat_cols if c in df_main.columns]\n",
    "    num_all = [c for c in NUMERIC_COLS if c in df_main.columns]\n",
    "    feature_cols = cat_all + num_all\n",
    "\n",
    "    X_all = df_main[feature_cols].copy()\n",
    "\n",
    "    for c in cat_all:\n",
    "        X_all[c] = X_all[c].astype(str)\n",
    "\n",
    "    for c in num_all:\n",
    "        X_all[c] = pd.to_numeric(X_all[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    keep_mask = ~y_all.isna()\n",
    "    X = X_all.loc[keep_mask].reset_index(drop=True)\n",
    "    y = y_all.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    cat_feature_idx = [X.columns.get_loc(c) for c in cat_all]\n",
    "\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mae_scores, rmse_scores, r2_scores, rpmse_scores = [], [], [], []\n",
    "\n",
    "    # kolom prediksi\n",
    "    oof_pred = np.full(len(df_main), np.nan)\n",
    "    idx_map  = np.where(keep_mask)[0]\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X), 1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "        valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"RMSE\",\n",
    "            depth=8,\n",
    "            learning_rate=0.05,\n",
    "            l2_leaf_reg=3.0,\n",
    "            iterations=2000,\n",
    "            random_seed=42,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=100,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "        pred_va = model.predict(valid_pool)\n",
    "        oof_pred[idx_map[va_idx]] = pred_va\n",
    "\n",
    "        # hitung metrik\n",
    "        mae   = mean_absolute_error(y_va, pred_va)\n",
    "        rmse  = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "        r2    = r2_score(y_va, pred_va)\n",
    "        rpmse = (rmse / np.mean(y_va)) * 100  \n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        rpmse_scores.append(rpmse)\n",
    "\n",
    "        print(f\"Fold {fold}: MAE={mae:.2f} | RMSE={rmse:.2f} | RPMSE={rpmse:.2f}% | R²={r2:.3f}\")\n",
    "\n",
    "    print(\"\\n=== Hasil 5-Fold Cross-Validation (\", out_sheet_name, \") ===\")\n",
    "    print(f\"MAE   : {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "    print(f\"RMSE  : {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")\n",
    "    print(f\"RPMSE : {np.mean(rpmse_scores):.2f}% ± {np.std(rpmse_scores):.2f}%\")\n",
    "    print(f\"R²    : {np.mean(r2_scores):.3f} ± {np.std(r2_scores):.3f}\")\n",
    "\n",
    "    \n",
    "    df_out = df_main.copy()\n",
    "    df_out[\"oof_pred\"] = oof_pred\n",
    "\n",
    "    cols_to_save = [CLUSTER_COL, PRICE_COL, \"oof_pred\"]\n",
    "    df_out[cols_to_save].to_excel(writer, sheet_name=out_sheet_name, index=False)\n",
    "\n",
    "    print(f\"\\nPrediksi OOF untuk '{out_sheet_name}' tersimpan di file Excel (sheet: {out_sheet_name})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT_FILE = \"catboost_oof_pred_with_cluster_kfold.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_FILE) as writer:\n",
    "    # Monthly\n",
    "    run_catboost_for_sheet(\n",
    "        file_path=FILE_CLUSTERED,\n",
    "        sheet_cluster=SHEET_CLUSTER_MONTHLY,\n",
    "        out_sheet_name=\"Monthly_OOF\",\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "    # Daily\n",
    "    run_catboost_for_sheet(\n",
    "        file_path=FILE_CLUSTERED,\n",
    "        sheet_cluster=SHEET_CLUSTER_DAILY,\n",
    "        out_sheet_name=\"Daily_OOF\",\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "print(f\"\\nSemua hasil OOF tersimpan di file: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b06b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inf = pd.read_excel(\"inflasi.xlsx\")\n",
    "\n",
    "df_inf_long = df_inf.melt(\n",
    "    id_vars=[\"Bulan\"],\n",
    "    var_name=\"Year\",\n",
    "    value_name=\"Inflasi\"\n",
    ")\n",
    "\n",
    "df_inf_long[\"Year\"] = df_inf_long[\"Year\"].astype(int)\n",
    "df_inf_long[\"Month\"] = df_inf_long[\"Bulan\"].map({\n",
    "    \"Januari\":1,\"Februari\":2,\"Maret\":3,\"April\":4,\"Mei\":5,\"Juni\":6,\n",
    "    \"Juli\":7,\"Agustus\":8,\"September\":9,\"Oktober\":10,\"November\":11,\"Desember\":12\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97294afa",
   "metadata": {},
   "source": [
    "## Prediksi + cluster + ext. data with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21537041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import shap  \n",
    "\n",
    "\n",
    "# Konfigurasi file & kolom\n",
    "\n",
    "FILE_CLUSTERED = r\"D:/DATA SKRIPSI/kontrak_sewa_bersih_clustered.xlsx\"\n",
    "INFLATION_FILE = r\"D:/DATA SKRIPSI/Laju Inflasi Di Kota Surabaya Tahun 2006-2020.csv\"\n",
    "PDRB_FILE = r\"D:/DATA SKRIPSI/Laju Pertumbuhan Produk Domestik Regional Bruto Atas Dasar Harga Konstan 2010 Menurut Lapangan Usaha di Kota Surabaya (persen), 2024.csv\"\n",
    "\n",
    "CLUSTER_COL = \"cluster\"\n",
    "\n",
    "SHEET_CONFIGS = [\n",
    "    {\n",
    "        \"freq_name\": \"Monthly\",\n",
    "        \"SHEET_CLUSTER\": \"Monthly_Fixed_clustered\",\n",
    "        \"PRICE_COL\": \"CuryUnitPrice\",\n",
    "        \"sheet_name_out\": \"Monthly_OOF\",\n",
    "    },\n",
    "    {\n",
    "        \"freq_name\": \"Daily\",\n",
    "        \"SHEET_CLUSTER\": \"Daily_Fixed_clustered\",\n",
    "        \"PRICE_COL\": \"CuryUnitPrice\",\n",
    "        \"sheet_name_out\": \"Daily_OOF\",\n",
    "    },\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\", \"LeaseMonthStart\", \"LeaseDayStart\",\n",
    "    \"LeaseMonthEnd\", \"LeaseDayEnd\", \"TranCode\",\n",
    "    \"ContractPeriod\", \"ContractType\", \"Building\",\n",
    "    \"UnitArea\", \"UnitFloor\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"BuildingArea\", \"LeaseDurationDays\", \"LeaseDurationMonths\",\n",
    "    \"LeaseYearStart\", \"LeaseYearEnd\", \"n_subunit\",\n",
    "]\n",
    "\n",
    "PLOT_SHAP_SUMMARY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2964032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Proses sheet: Monthly_Fixed_clustered\n",
      "Output sheet: Monthly_OOF\n",
      "==============================\n",
      "\n",
      "Fold 1: MAE=30263.20 | RMSE=46022.97 | RPMSE=19.39% | R²=0.959\n",
      "Fold 2: MAE=37542.03 | RMSE=63500.73 | RPMSE=25.67% | R²=0.935\n",
      "Fold 3: MAE=32575.87 | RMSE=51055.47 | RPMSE=20.56% | R²=0.963\n",
      "Fold 4: MAE=37619.42 | RMSE=64458.63 | RPMSE=26.48% | R²=0.951\n",
      "Fold 5: MAE=33228.57 | RMSE=51378.49 | RPMSE=21.12% | R²=0.948\n",
      "\n",
      "=== Hasil 5-Fold Cross-Validation ( Monthly_OOF ) ===\n",
      "MAE   : 34245.82 ± 2895.89\n",
      "RMSE  : 55283.26 ± 7356.48\n",
      "RPMSE : 22.64% ± 2.87%\n",
      "R²    : 0.951 ± 0.010\n",
      "\n",
      "Prediksi OOF untuk 'Monthly_OOF' tersimpan di file Excel (sheet: Monthly_OOF)\n",
      "SHAP summary untuk 'Monthly_OOF' tersimpan di sheet: Monthly_OOF_SHAP\n",
      "\n",
      "==============================\n",
      "Proses sheet: Daily_Fixed_clustered\n",
      "Output sheet: Daily_OOF\n",
      "==============================\n",
      "\n",
      "Fold 1: MAE=2949.07 | RMSE=3973.72 | RPMSE=11.99% | R²=0.966\n",
      "Fold 2: MAE=3168.78 | RMSE=4293.10 | RPMSE=11.93% | R²=0.966\n",
      "Fold 3: MAE=2988.85 | RMSE=4144.01 | RPMSE=12.24% | R²=0.962\n",
      "Fold 4: MAE=3171.60 | RMSE=4349.95 | RPMSE=12.63% | R²=0.964\n",
      "Fold 5: MAE=3027.75 | RMSE=3999.76 | RPMSE=11.93% | R²=0.962\n",
      "\n",
      "=== Hasil 5-Fold Cross-Validation ( Daily_OOF ) ===\n",
      "MAE   : 3061.21 ± 92.40\n",
      "RMSE  : 4152.11 ± 151.07\n",
      "RPMSE : 12.14% ± 0.27%\n",
      "R²    : 0.964 ± 0.002\n",
      "\n",
      "Prediksi OOF untuk 'Daily_OOF' tersimpan di file Excel (sheet: Daily_OOF)\n",
      "SHAP summary untuk 'Daily_OOF' tersimpan di sheet: Daily_OOF_SHAP\n",
      "\n",
      "Semua hasil OOF dan SHAP summary tersimpan di file: catboost_oof_pred_with_cluster_kfold_with_macro_shap.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_price_column(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    s = df[col].astype(str).str.strip()\n",
    "    s = s.str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def load_monthly_inflation(path: str) -> pd.DataFrame:\n",
    "    df_raw = pd.read_csv(path, sep=';', engine='python')\n",
    "    df_raw = clean_columns(df_raw)\n",
    "\n",
    "    year_labels = df_raw.iloc[0, 1:]\n",
    "\n",
    "    month_map = {\n",
    "        \"Januari\": 1, \"Februari\": 2, \"Maret\": 3, \"April\": 4, \"Mei\": 5,\n",
    "        \"Juni\": 6, \"Juli\": 7, \"Agustus\": 8, \"September\": 9, \"Oktober\": 10,\n",
    "        \"November\": 11, \"Desember\": 12\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for i in range(3, len(df_raw)):\n",
    "        month_name = df_raw.iloc[i, 0]\n",
    "        if not isinstance(month_name, str):\n",
    "            continue\n",
    "        month_name = month_name.strip()\n",
    "        if month_name == \"\" or \"sumber\" in month_name.lower():\n",
    "            continue\n",
    "\n",
    "        m = month_map.get(month_name)\n",
    "        if m is None:\n",
    "            continue\n",
    "\n",
    "        for col in df_raw.columns[1:]:\n",
    "            year_val = year_labels[col]\n",
    "            try:\n",
    "                y = int(str(year_val))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            val = df_raw.at[i, col]\n",
    "            if isinstance(val, str):\n",
    "                val = val.replace(\",\", \".\")\n",
    "            try:\n",
    "                infl_val = float(val)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"LeaseYearStart\": y,\n",
    "                \"LeaseMonthStart\": m,\n",
    "                \"Inflation\": infl_val\n",
    "            })\n",
    "\n",
    "    infl_long = pd.DataFrame(rows)\n",
    "    infl_long = (\n",
    "        infl_long\n",
    "        .groupby([\"LeaseYearStart\", \"LeaseMonthStart\"], as_index=False)[\"Inflation\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    return infl_long\n",
    "\n",
    "\n",
    "\n",
    "# Load Pertumbuhan PDRB\n",
    "\n",
    "def load_pdrb_growth(path: str) -> pd.DataFrame:\n",
    "    df_raw = pd.read_csv(\n",
    "        path,\n",
    "        sep=';',\n",
    "        header=None,\n",
    "        encoding='utf-8-sig'\n",
    "    )\n",
    "\n",
    "    col_year_raw = df_raw.iloc[:, 0].astype(str).str.strip()\n",
    "    col_year = pd.to_numeric(col_year_raw, errors=\"coerce\")\n",
    "\n",
    "    col_growth_raw = df_raw.iloc[:, 1].astype(str).str.strip()\n",
    "    col_growth_clean = (\n",
    "        col_growth_raw\n",
    "        .str.replace(\"%\", \"\", regex=False)\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    col_growth = pd.to_numeric(col_growth_clean, errors=\"coerce\")\n",
    "\n",
    "    mask = ~col_year.isna() & ~col_growth.isna()\n",
    "\n",
    "    pdrb = pd.DataFrame({\n",
    "        \"LeaseYearStart\": col_year[mask].astype(\"Int64\"),\n",
    "        \"GDP_Growth\": col_growth[mask]\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    return pdrb\n",
    "\n",
    "\n",
    "\n",
    "# Fungsi utama per sheet (KFold + inflasi & PDRB + SHAP)\n",
    "def run_catboost_for_sheet(\n",
    "    file_path: str,\n",
    "    sheet_cluster: str,\n",
    "    out_sheet_name: str,\n",
    "    writer: pd.ExcelWriter,\n",
    "    price_col_name: str,\n",
    "    infl_long: pd.DataFrame,\n",
    "    pdrb_growth: pd.DataFrame,\n",
    "):\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Proses sheet: {sheet_cluster}\")\n",
    "    print(f\"Output sheet: {out_sheet_name}\")\n",
    "    print(f\"==============================\\n\")\n",
    "\n",
    "    try:\n",
    "        df_main = clean_columns(pd.read_excel(file_path, sheet_name=sheet_cluster))\n",
    "    except ValueError:\n",
    "        df_main = clean_columns(pd.read_excel(file_path, sheet_name=0))\n",
    "\n",
    "    df_main[\"__orig_idx__\"] = np.arange(len(df_main))\n",
    "\n",
    "    if CLUSTER_COL not in df_main.columns:\n",
    "        raise KeyError(\n",
    "            f\"Kolom '{CLUSTER_COL}' tidak ditemukan di sheet '{sheet_cluster}'. \"\n",
    "            \"Pastikan hasil clustering sudah ada di sheet tersebut.\"\n",
    "        )\n",
    "\n",
    "    if price_col_name not in df_main.columns:\n",
    "        cands = [c for c in df_main.columns if \"price\" in c.lower()]\n",
    "        if not cands:\n",
    "            raise KeyError(\n",
    "                f\"Kolom target '{price_col_name}' tidak ditemukan dan tidak ada kolom mirip 'price' di sheet '{sheet_cluster}'.\"\n",
    "            )\n",
    "        print(f\"[INFO] Kolom price '{price_col_name}' tidak ditemukan, pakai kolom mirip: {cands[0]}\")\n",
    "        price_col = cands[0]\n",
    "    else:\n",
    "        price_col = price_col_name\n",
    "\n",
    "    # Merge Inflasi\n",
    "    if {\"LeaseYearStart\", \"LeaseMonthStart\"}.issubset(df_main.columns):\n",
    "        df_main = df_main.merge(\n",
    "            infl_long,\n",
    "            on=[\"LeaseYearStart\", \"LeaseMonthStart\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"PERINGATAN: LeaseYearStart/LeaseMonthStart tidak lengkap, Inflasi tidak bisa di-merge.\")\n",
    "\n",
    "    # Merge PDRB\n",
    "    if \"LeaseYearStart\" in df_main.columns and \"LeaseYearStart\" in pdrb_growth.columns:\n",
    "        df_main = df_main.merge(\n",
    "            pdrb_growth,\n",
    "            on=\"LeaseYearStart\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"PERINGATAN: 'LeaseYearStart' tidak ada di pdrb_growth – GDP_Growth tidak dipakai.\")\n",
    "\n",
    "    # Target\n",
    "    y_all = parse_price_column(df_main, price_col)\n",
    "\n",
    "    # Fitur\n",
    "    all_cat_cols = CATEGORICAL_COLS + [CLUSTER_COL]\n",
    "\n",
    "    cat_all = [c for c in all_cat_cols if c in df_main.columns]\n",
    "    num_all = [c for c in NUMERIC_COLS if c in df_main.columns]\n",
    "\n",
    "    for extra in [\"Inflation\", \"GDP_Growth\"]:\n",
    "        if extra in df_main.columns and extra not in num_all:\n",
    "            num_all.append(extra)\n",
    "\n",
    "    feature_cols = cat_all + num_all\n",
    "    X_all = df_main[feature_cols].copy()\n",
    "\n",
    "    for c in cat_all:\n",
    "        X_all[c] = X_all[c].astype(str)\n",
    "    for c in num_all:\n",
    "        X_all[c] = pd.to_numeric(X_all[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    keep_mask = ~y_all.isna()\n",
    "    X = X_all.loc[keep_mask].reset_index(drop=True)\n",
    "    y = y_all.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    cat_feature_idx = [X.columns.get_loc(c) for c in cat_all]\n",
    "\n",
    "    # 5-Fold CV + SHAP\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mae_scores, rmse_scores, r2_scores, rpmse_scores = [], [], [], []\n",
    "\n",
    "    oof_pred = np.full(len(df_main), np.nan)\n",
    "    idx_map = np.where(keep_mask)[0]\n",
    "\n",
    "    n_rows = len(df_main)\n",
    "    n_features = X.shape[1]\n",
    "    oof_shap = np.full((n_rows, n_features + 1), np.nan, dtype=float)  # +1 utk base value\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X), 1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "        valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"RMSE\",\n",
    "            depth=8,\n",
    "            learning_rate=0.05,\n",
    "            l2_leaf_reg=3.0,\n",
    "            iterations=2000,\n",
    "            random_seed=42,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=100,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "        pred_va = model.predict(valid_pool)\n",
    "        oof_pred[idx_map[va_idx]] = pred_va\n",
    "\n",
    "        shap_vals = model.get_feature_importance(\n",
    "            valid_pool,\n",
    "            type=\"ShapValues\"\n",
    "        ) \n",
    "\n",
    "        oof_shap[idx_map[va_idx], :] = shap_vals\n",
    "\n",
    "        mae = mean_absolute_error(y_va, pred_va)\n",
    "        rmse = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "        r2 = r2_score(y_va, pred_va)\n",
    "        rpmse = (rmse / np.mean(y_va)) * 100\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        rpmse_scores.append(rpmse)\n",
    "\n",
    "        print(f\"Fold {fold}: MAE={mae:.2f} | RMSE={rmse:.2f} | RPMSE={rpmse:.2f}% | R²={r2:.3f}\")\n",
    "\n",
    "        if PLOT_SHAP_SUMMARY and fold == 1:\n",
    "            shap.summary_plot(\n",
    "                shap_vals[:, :-1],\n",
    "                X_va,\n",
    "                feature_names=feature_cols,\n",
    "                show=True\n",
    "            )\n",
    "\n",
    "    print(\"\\n=== Hasil 5-Fold Cross-Validation (\", out_sheet_name, \") ===\")\n",
    "    print(f\"MAE   : {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "    print(f\"RMSE  : {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")\n",
    "    print(f\"RPMSE : {np.mean(rpmse_scores):.2f}% ± {np.std(rpmse_scores):.2f}%\")\n",
    "    print(f\"R²    : {np.mean(r2_scores):.3f} ± {np.std(r2_scores):.3f}\")\n",
    "\n",
    "    # Simpan hasil prediksi\n",
    "    df_out = df_main.copy()\n",
    "    df_out[\"oof_pred\"] = oof_pred\n",
    "\n",
    "    cols_to_save = [\n",
    "        c for c in [\n",
    "            CLUSTER_COL,\n",
    "            price_col,\n",
    "            \"Inflation\",\n",
    "            \"GDP_Growth\",\n",
    "            \"oof_pred\",\n",
    "            \"__orig_idx__\",\n",
    "        ]\n",
    "        if c in df_out.columns\n",
    "    ]\n",
    "\n",
    "    df_save = (\n",
    "        df_out[cols_to_save]\n",
    "        .sort_values(\"__orig_idx__\")\n",
    "        .drop(columns=\"__orig_idx__\", errors=\"ignore\")\n",
    "    )\n",
    "\n",
    "    df_save.to_excel(writer, sheet_name=out_sheet_name, index=False)\n",
    "    print(f\"\\nPrediksi OOF untuk '{out_sheet_name}' tersimpan di file Excel (sheet: {out_sheet_name})\")\n",
    "\n",
    "    shap_valid = oof_shap[keep_mask, :-1]  \n",
    "\n",
    "    # Rata-rata absolut per kolom fitur\n",
    "    mean_abs_shap = np.nanmean(np.abs(shap_valid), axis=0)\n",
    "\n",
    "    df_shap_summary = pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"mean_abs_shap\": mean_abs_shap\n",
    "    }).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "    shap_sheet_name = f\"{out_sheet_name}_SHAP\"\n",
    "    df_shap_summary.to_excel(writer, sheet_name=shap_sheet_name, index=False)\n",
    "\n",
    "    print(f\"SHAP summary untuk '{out_sheet_name}' tersimpan di sheet: {shap_sheet_name}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    infl_long = load_monthly_inflation(INFLATION_FILE)\n",
    "    pdrb_growth = load_pdrb_growth(PDRB_FILE)\n",
    "\n",
    "    OUTPUT_FILE = \"catboost_oof_pred_with_cluster_kfold_with_macro_shap.xlsx\"\n",
    "\n",
    "    with pd.ExcelWriter(OUTPUT_FILE) as writer:\n",
    "        for cfg in SHEET_CONFIGS:\n",
    "            run_catboost_for_sheet(\n",
    "                file_path=FILE_CLUSTERED,\n",
    "                sheet_cluster=cfg[\"SHEET_CLUSTER\"],\n",
    "                out_sheet_name=cfg[\"sheet_name_out\"],\n",
    "                writer=writer,\n",
    "                price_col_name=cfg[\"PRICE_COL\"],\n",
    "                infl_long=infl_long,\n",
    "                pdrb_growth=pdrb_growth,\n",
    "            )\n",
    "\n",
    "    print(f\"\\nSemua hasil OOF dan SHAP summary tersimpan di file: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6557d6a",
   "metadata": {},
   "source": [
    "## Prediksi + cluster with walk forward CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56997eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit   \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b9e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== PERIODE: Monthly_Fixed ==========\n",
      "Fold 1: MAE=50525.23 | RMSE=76711.82 | RPMSE=30.36% | R²=0.886\n",
      "Fold 2: MAE=42265.84 | RMSE=70642.76 | RPMSE=30.23% | R²=0.889\n",
      "Fold 3: MAE=37245.78 | RMSE=57333.29 | RPMSE=24.25% | R²=0.936\n",
      "Fold 4: MAE=43071.62 | RMSE=60936.85 | RPMSE=25.50% | R²=0.920\n",
      "Fold 5: MAE=72020.08 | RMSE=227851.16 | RPMSE=94.70% | R²=0.633\n",
      "\n",
      "=== Hasil Walk-Forward CV (TimeSeriesSplit) ===\n",
      "MAE   : 49025.71 ± 12254.82\n",
      "RMSE  : 98695.18 ± 64943.01\n",
      "RPMSE : 41.01% ± 26.96%\n",
      "R²    : 0.853 ± 0.111\n",
      "\n",
      "Prediksi OOF tersimpan di: catboost_oof_pred_with_cluster_walkforward_Monthly_Fixed.xlsx\n",
      "\n",
      "========== PERIODE: Daily_Fixed ==========\n",
      "Fold 1: MAE=4244.41 | RMSE=5594.90 | RPMSE=16.80% | R²=0.925\n",
      "Fold 2: MAE=3994.12 | RMSE=5043.17 | RPMSE=13.28% | R²=0.961\n",
      "Fold 3: MAE=4039.10 | RMSE=5360.00 | RPMSE=14.40% | R²=0.951\n",
      "Fold 4: MAE=4296.00 | RMSE=5452.65 | RPMSE=17.03% | R²=0.932\n",
      "Fold 5: MAE=3648.21 | RMSE=4796.38 | RPMSE=14.88% | R²=0.934\n",
      "\n",
      "=== Hasil Walk-Forward CV (TimeSeriesSplit) ===\n",
      "MAE   : 4044.37 ± 229.27\n",
      "RMSE  : 5249.42 ± 290.06\n",
      "RPMSE : 15.28% ± 1.43%\n",
      "R²    : 0.940 ± 0.013\n",
      "\n",
      "Prediksi OOF tersimpan di: catboost_oof_pred_with_cluster_walkforward_Daily_Fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Konfigurasi umum\n",
    "FILE_CLUSTERED = \"D:/DATA SKRIPSI/kontrak_sewa_bersih_clustered.xlsx\"\n",
    "CLUSTER_COL    = \"cluster\"   \n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\",\"LeaseMonthStart\",\"LeaseDayStart\",\n",
    "    \"LeaseMonthEnd\",\"LeaseDayEnd\",\"TranCode\",\n",
    "    \"ContractPeriod\",\"ContractType\",\"Building\", \"UnitArea\", \"UnitFloor\"\n",
    "    \n",
    "]\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"BuildingArea\",\"LeaseDurationDays\",\"LeaseDurationMonths\",\n",
    "    \"LeaseYearStart\",\"LeaseYearEnd\",\"n_subunit\"\n",
    "]\n",
    "\n",
    "PRICE_COL_NAME = \"CuryUnitPrice\"      \n",
    "\n",
    "\n",
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def run_catboost_for_period(\n",
    "    file_path: str,\n",
    "    sheet_cluster: str,\n",
    "    sheet_price: str,\n",
    "    price_col: str = PRICE_COL_NAME,\n",
    "    cluster_col: str = CLUSTER_COL,\n",
    "    output_prefix: str = \"catboost_oof_pred_with_cluster_walkforward\"\n",
    "):\n",
    "    print(f\"\\n========== PERIODE: {sheet_cluster.replace('_clustered','')} ==========\")\n",
    "\n",
    "    \n",
    "    # Load sheet utama (+ cluster)\n",
    "    \n",
    "    try:\n",
    "        df_main = clean_columns(pd.read_excel(file_path, sheet_name=sheet_cluster))\n",
    "    except ValueError:\n",
    "        df_main = clean_columns(pd.read_excel(file_path, sheet_name=0))\n",
    "\n",
    "    if cluster_col not in df_main.columns:\n",
    "        raise KeyError(\n",
    "            f\"Kolom cluster '{cluster_col}' tidak ditemukan di sheet '{sheet_cluster}'. \"\n",
    "            \"Pastikan hasil clustering sudah disimpan sebagai kolom tersebut.\"\n",
    "        )\n",
    "\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    if sheet_price not in xls.sheet_names:\n",
    "        raise KeyError(f\"Sheet '{sheet_price}' tidak ditemukan di {file_path}.\")\n",
    "\n",
    "    df_price = clean_columns(pd.read_excel(file_path, sheet_name=sheet_price))\n",
    "\n",
    "    target_price_col = price_col\n",
    "    if target_price_col not in df_price.columns:\n",
    "        cands = [c for c in df_price.columns if \"price\" in c.lower()]\n",
    "        if not cands:\n",
    "            raise KeyError(\n",
    "                f\"Kolom target '{price_col}' tidak ditemukan dan tidak ada kolom mirip 'price' di sheet '{sheet_price}'.\"\n",
    "            )\n",
    "        target_price_col = cands[0]\n",
    "        print(f\"Kolom harga default '{price_col}' tidak ditemukan, pakai kolom '{target_price_col}'.\")\n",
    "\n",
    "    # mapping harga ke baris df_main\n",
    "    if \"RowID\" in df_price.columns:\n",
    "        df_price[\"RowID\"] = pd.to_numeric(df_price[\"RowID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        s_price = df_price.set_index(\"RowID\")[target_price_col]\n",
    "        y_all = pd.Series(df_main.index, index=df_main.index).map(s_price).astype(float)\n",
    "    else:\n",
    "        if len(df_price) != len(df_main):\n",
    "            raise ValueError(\n",
    "                f\"Panjang sheet utama ({len(df_main)}) berbeda dengan sheet '{sheet_price}' ({len(df_price)}). \"\n",
    "                \"Tambahkan kolom RowID di price sheet agar bisa dipetakan.\"\n",
    "            )\n",
    "        y_all = (\n",
    "            pd.to_numeric(df_price[target_price_col], errors=\"coerce\")\n",
    "            .astype(float)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    \n",
    "    need_cols = {\"LeaseYearStart\", \"LeaseMonthStart\", \"LeaseDayStart\"}\n",
    "    if not need_cols.issubset(df_main.columns):\n",
    "        raise KeyError(\n",
    "            \"Untuk walk-forward CV dibutuhkan kolom LeaseYearStart, LeaseMonthStart, LeaseDayStart.\"\n",
    "        )\n",
    "\n",
    "    lease_start_date = pd.to_datetime(\n",
    "        dict(\n",
    "            year=df_main[\"LeaseYearStart\"],\n",
    "            month=df_main[\"LeaseMonthStart\"],\n",
    "            day=df_main[\"LeaseDayStart\"],\n",
    "        ),\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "\n",
    "    # buang baris yang tidak punya tanggal valid\n",
    "    valid_date_mask = ~lease_start_date.isna()\n",
    "    df_main = df_main.loc[valid_date_mask].reset_index(drop=True)\n",
    "    y_all   = y_all.loc[valid_date_mask].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.loc[valid_date_mask].reset_index(drop=True)\n",
    "\n",
    "    # sort berdasarkankolom LeaseStartDate\n",
    "    order = np.argsort(lease_start_date.values)\n",
    "    df_main = df_main.iloc[order].reset_index(drop=True)\n",
    "    y_all   = y_all.iloc[order].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.iloc[order].reset_index(drop=True)\n",
    "\n",
    "    #siapkan kolom input\n",
    "    all_cat_cols = CATEGORICAL_COLS + [cluster_col]\n",
    "\n",
    "    cat_all = [c for c in all_cat_cols if c in df_main.columns]\n",
    "    num_all = [c for c in NUMERIC_COLS if c in df_main.columns]\n",
    "    feature_cols = cat_all + num_all\n",
    "\n",
    "    X_all = df_main[feature_cols].copy()\n",
    "\n",
    "    for c in cat_all:\n",
    "        X_all[c] = X_all[c].astype(str)\n",
    "\n",
    "    for c in num_all:\n",
    "        X_all[c] = pd.to_numeric(X_all[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    keep_mask = ~y_all.isna()\n",
    "    X = X_all.loc[keep_mask].reset_index(drop=True)\n",
    "    y = y_all.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    cat_feature_idx = [X.columns.get_loc(c) for c in cat_all]\n",
    "\n",
    "    \n",
    "    # Walk-Forward Cross Validation dengan CatBoost (TimeSeriesSplit)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    mae_scores, rmse_scores, r2_scores, rpmse_scores = [], [], [], []\n",
    "\n",
    "    # prediksi\n",
    "    oof_pred = np.full(len(df_main), np.nan)\n",
    "    idx_map  = np.where(keep_mask)[0]   \n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(X), 1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "        valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"RMSE\",\n",
    "            depth=8,\n",
    "            learning_rate=0.05,\n",
    "            l2_leaf_reg=3.0,\n",
    "            iterations=2000,\n",
    "            random_seed=42,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=100,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "        pred_va = model.predict(valid_pool)\n",
    "\n",
    "        oof_pred[idx_map[va_idx]] = pred_va\n",
    "\n",
    "        # hitung metrik\n",
    "        mae   = mean_absolute_error(y_va, pred_va)\n",
    "        rmse  = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "        r2    = r2_score(y_va, pred_va)\n",
    "        rpmse = (rmse / np.mean(y_va)) * 100  \n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        rpmse_scores.append(rpmse)\n",
    "\n",
    "        print(f\"Fold {fold}: MAE={mae:.2f} | RMSE={rmse:.2f} | RPMSE={rpmse:.2f}% | R²={r2:.3f}\")\n",
    "\n",
    "    print(\"\\n=== Hasil Walk-Forward CV (TimeSeriesSplit) ===\")\n",
    "    print(f\"MAE   : {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "    print(f\"RMSE  : {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")\n",
    "    print(f\"RPMSE : {np.mean(rpmse_scores):.2f}% ± {np.std(rpmse_scores):.2f}%\")\n",
    "    print(f\"R²    : {np.mean(r2_scores):.3f} ± {np.std(r2_scores):.3f}\")\n",
    "\n",
    "    \n",
    "    # Simpan hasil\n",
    "    \n",
    "    df_out = df_main.copy()\n",
    "    df_out[\"oof_pred\"] = oof_pred\n",
    "\n",
    "    if target_price_col not in df_out.columns:\n",
    "        df_out[target_price_col] = y_all.values\n",
    "\n",
    "    cols_to_save = [cluster_col, target_price_col, \"oof_pred\"]\n",
    "\n",
    "    period_label = sheet_cluster.replace(\"_clustered\", \"\")\n",
    "    out_file = f\"{output_prefix}_{period_label}.xlsx\"\n",
    "    df_out[cols_to_save].to_excel(out_file, index=False)\n",
    "\n",
    "    print(f\"\\nPrediksi OOF tersimpan di: {out_file}\")\n",
    "\n",
    "\n",
    "\n",
    "run_catboost_for_period(\n",
    "    file_path=FILE_CLUSTERED,\n",
    "    sheet_cluster=\"Monthly_Fixed_clustered\",\n",
    "    sheet_price=\"Monthly_Fixed_CuryUnitPrice\",\n",
    "    output_prefix=\"catboost_oof_pred_with_cluster_walkforward\"\n",
    ")\n",
    "\n",
    "run_catboost_for_period(\n",
    "    file_path=FILE_CLUSTERED,\n",
    "    sheet_cluster=\"Daily_Fixed_clustered\",\n",
    "    sheet_price=\"Daily_Fixed_CuryUnitPrice\",\n",
    "    output_prefix=\"catboost_oof_pred_with_cluster_walkforward\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db75d8",
   "metadata": {},
   "source": [
    "## Prediksi + cluster + Inflation data (walkforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CLUSTERED = \"D:/DATA SKRIPSI/kontrak_sewa_bersih_clustered.xlsx\"\n",
    "INFLATION_FILE = \"D:/DATA SKRIPSI/Laju Inflasi Di Kota Surabaya Tahun 2006-2020.csv\"\n",
    "CLUSTER_COL    = \"cluster\"  \n",
    "\n",
    "SHEET_CONFIGS = [\n",
    "    {\n",
    "        \"freq_name\": \"Monthly\",\n",
    "        \"SHEET_CLUSTER\": \"Monthly_Fixed_clustered\",\n",
    "        \"PRICE_SHEET\": \"Monthly_Fixed_CuryUnitPrice\",\n",
    "        \"PRICE_COL\": \"CuryUnitPrice\",\n",
    "        \"OUTPUT_FILE\": \"catboost_oof_pred_with_cluster_walkforward_Monthly.xlsx\",\n",
    "    },\n",
    "    {\n",
    "        \"freq_name\": \"Daily\",\n",
    "        \"SHEET_CLUSTER\": \"Daily_Fixed_clustered\",\n",
    "        \"PRICE_SHEET\": \"Daily_Fixed_CuryUnitPrice\",\n",
    "        \"PRICE_COL\": \"CuryUnitPrice\",\n",
    "        \"OUTPUT_FILE\": \"catboost_oof_pred_with_cluster_walkforward_Daily.xlsx\",\n",
    "    },\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\",\"LeaseMonthStart\",\"LeaseDayStart\",\n",
    "    \"LeaseMonthEnd\",\"LeaseDayEnd\",\"TranCode\",\n",
    "    \"ContractPeriod\",\"ContractType\",\"Building\", \"UnitArea\", \"UnitFloor\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"BuildingArea\",\"LeaseDurationDays\",\"LeaseDurationMonths\",\n",
    "    \"LeaseYearStart\",\"LeaseYearEnd\",\"n_subunit\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def parse_price_column(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    \n",
    "    s = df[col].astype(str).str.strip()\n",
    "    s = s.str.replace(\",\", \".\", regex=False)   \n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def load_monthly_inflation(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Membaca file inflasi BPS (format wide: kolom tahun 2015, 2016, ...; baris bulan)\n",
    "    lalu mengembalikan DataFrame long: Year, Month, Inflation\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_csv(path, sep=';', engine='python')\n",
    "    df_raw = clean_columns(df_raw)\n",
    "\n",
    "    # nama kolom pertama = nama bulan\n",
    "    month_col = df_raw.columns[0]\n",
    "\n",
    "    # baris pertama (index 0) berisi label tahun untuk kolom-kolom lain\n",
    "    year_labels = df_raw.iloc[0, 1:]  # kolom 1 dst\n",
    "\n",
    "    month_map = {\n",
    "        \"Januari\": 1, \"Februari\": 2, \"Maret\": 3, \"April\": 4, \"Mei\": 5,\n",
    "        \"Juni\": 6, \"Juli\": 7, \"Agustus\": 8, \"September\": 9, \"Oktober\": 10,\n",
    "        \"November\": 11, \"Desember\": 12\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    # data bulan mulai di baris index 3 (lihat file asli)\n",
    "    for i in range(3, len(df_raw)):\n",
    "        month_name = df_raw.iloc[i, 0]\n",
    "        if not isinstance(month_name, str):\n",
    "            continue\n",
    "        month_name = month_name.strip()\n",
    "        if month_name == \"\" or \"sumber\" in month_name.lower():\n",
    "            continue\n",
    "\n",
    "        m = month_map.get(month_name)\n",
    "        if m is None:\n",
    "            continue\n",
    "\n",
    "        # loop setiap kolom tahun\n",
    "        for col in df_raw.columns[1:]:\n",
    "            year_val = year_labels[col]\n",
    "            try:\n",
    "                y = int(str(year_val))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            val = df_raw.at[i, col]\n",
    "            if isinstance(val, str):\n",
    "                val = val.replace(\",\", \".\")\n",
    "            try:\n",
    "                infl_val = float(val)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            rows.append({\"LeaseYearStart\": y, \"LeaseMonthStart\": m, \"Inflation\": infl_val})\n",
    "\n",
    "    infl_long = pd.DataFrame(rows)\n",
    "\n",
    "    # jika ada duplikat (Year, Month) ambil rata-rata\n",
    "    infl_long = (\n",
    "        infl_long\n",
    "        .groupby([\"LeaseYearStart\", \"LeaseMonthStart\"], as_index=False)[\"Inflation\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    return infl_long\n",
    "\n",
    "\n",
    "\n",
    "# Fungsi utama untuk memproses satu pasangan sheet (Monthly / Daily)\n",
    "def run_for_sheet(\n",
    "    xls: pd.ExcelFile,\n",
    "    sheet_cluster: str,\n",
    "    price_sheet: str,\n",
    "    price_col_name: str,\n",
    "    output_file: str,\n",
    "):\n",
    "    print(f\"\\n================= Proses {sheet_cluster} / {price_sheet} =================\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Load sheet utama (sudah termasuk kolom cluster)\n",
    "    # --------------------------------------------------\n",
    "    if sheet_cluster not in xls.sheet_names:\n",
    "        raise KeyError(\n",
    "            f\"Sheet cluster '{sheet_cluster}' tidak ditemukan di {FILE_CLUSTERED}.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        df_main = clean_columns(pd.read_excel(xls, sheet_name=sheet_cluster))\n",
    "    except ValueError:\n",
    "        df_main = clean_columns(pd.read_excel(xls, sheet_name=0))\n",
    "\n",
    "    # pastikan kolom cluster ada\n",
    "    if CLUSTER_COL not in df_main.columns:\n",
    "        raise KeyError(\n",
    "            f\"Kolom cluster '{CLUSTER_COL}' tidak ditemukan di sheet '{sheet_cluster}'. \"\n",
    "            \"Pastikan hasil clustering sudah disimpan sebagai kolom tersebut.\"\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Load price sheet dan selaraskan dengan data utama\n",
    "    # --------------------------------------------------\n",
    "    if price_sheet not in xls.sheet_names:\n",
    "        raise KeyError(f\"Sheet '{price_sheet}' tidak ditemukan di {FILE_CLUSTERED}.\")\n",
    "\n",
    "    df_price = clean_columns(pd.read_excel(xls, sheet_name=price_sheet))\n",
    "\n",
    "    # gunakan local variable untuk kolom price\n",
    "    price_col = price_col_name\n",
    "\n",
    "    # pastikan kolom harga ada (atau fallback cari yang mengandung 'price')\n",
    "    if price_col not in df_price.columns:\n",
    "        cands = [c for c in df_price.columns if \"price\" in c.lower()]\n",
    "        if not cands:\n",
    "            raise KeyError(\n",
    "                f\"Kolom target '{price_col}' tidak ditemukan dan tidak ada kolom mirip 'price' di sheet '{price_sheet}'.\"\n",
    "            )\n",
    "        price_col = cands[0]\n",
    "\n",
    "    # mapping harga ke baris df_main\n",
    "    if \"RowID\" in df_price.columns:\n",
    "        # map berdasarkan RowID -> baris df_main (diasumsikan RowID = index asli 0..n-1)\n",
    "        df_price[\"RowID\"] = pd.to_numeric(df_price[\"RowID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        s_price = df_price.set_index(\"RowID\")[price_col]\n",
    "        y_all = pd.Series(df_main.index, index=df_main.index).map(s_price).astype(float)\n",
    "    else:\n",
    "        # kalau tidak ada RowID, sejajarkan by-position (panjang harus sama)\n",
    "        if len(df_price) != len(df_main):\n",
    "            raise ValueError(\n",
    "                f\"Panjang sheet utama ({len(df_main)}) berbeda dengan sheet '{price_sheet}' ({len(df_price)}). \"\n",
    "                \"Tambahkan kolom RowID di price sheet agar bisa dipetakan.\"\n",
    "            )\n",
    "        y_all = (\n",
    "            pd.to_numeric(df_price[price_col], errors=\"coerce\")\n",
    "            .astype(float)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # URUTKAN BERDASARKAN TANGGAL (UNTUK WALK-FORWARD)\n",
    "    # --------------------------------------------------\n",
    "    need_cols = {\"LeaseYearStart\", \"LeaseMonthStart\", \"LeaseDayStart\"}\n",
    "    if not need_cols.issubset(df_main.columns):\n",
    "        raise KeyError(\n",
    "            \"Untuk walk-forward CV dibutuhkan kolom LeaseYearStart, LeaseMonthStart, LeaseDayStart.\"\n",
    "        )\n",
    "\n",
    "    lease_start_date = pd.to_datetime(\n",
    "        dict(\n",
    "            year=df_main[\"LeaseYearStart\"],\n",
    "            month=df_main[\"LeaseMonthStart\"],\n",
    "            day=df_main[\"LeaseDayStart\"],\n",
    "        ),\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "\n",
    "    # buang baris yang tidak punya tanggal valid\n",
    "    valid_date_mask = ~lease_start_date.isna()\n",
    "    df_main = df_main.loc[valid_date_mask].reset_index(drop=True)\n",
    "    y_all   = y_all.loc[valid_date_mask].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.loc[valid_date_mask].reset_index(drop=True)\n",
    "\n",
    "    # sort berdasarkan tanggal mulai sewa\n",
    "    order = np.argsort(lease_start_date.values)\n",
    "    df_main = df_main.iloc[order].reset_index(drop=True)\n",
    "    y_all   = y_all.iloc[order].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.iloc[order].reset_index(drop=True)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Siapkan fitur (termasuk kolom cluster sebagai kategori)\n",
    "    # --------------------------------------------------\n",
    "    all_cat_cols = CATEGORICAL_COLS + [CLUSTER_COL]\n",
    "\n",
    "    cat_all = [c for c in all_cat_cols if c in df_main.columns]\n",
    "    num_all = [c for c in NUMERIC_COLS if c in df_main.columns]\n",
    "    feature_cols = cat_all + num_all\n",
    "\n",
    "    X_all = df_main[feature_cols].copy()\n",
    "\n",
    "    # kategorikal -> string\n",
    "    for c in cat_all:\n",
    "        X_all[c] = X_all[c].astype(str)\n",
    "\n",
    "    # numerik -> float\n",
    "    for c in num_all:\n",
    "        X_all[c] = pd.to_numeric(X_all[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    # buang baris tanpa target\n",
    "    keep_mask = ~y_all.isna()\n",
    "    X = X_all.loc[keep_mask].reset_index(drop=True)\n",
    "    y = y_all.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    # index kolom kategorikal untuk CatBoost\n",
    "    cat_feature_idx = [X.columns.get_loc(c) for c in cat_all]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Walk-Forward Cross Validation dengan CatBoost\n",
    "    # --------------------------------------------------\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    mae_scores, rmse_scores, r2_scores, rpmse_scores = [], [], [], []\n",
    "\n",
    "    # oof_pred untuk seluruh df_main (setelah sort & filter tanggal)\n",
    "    oof_pred = np.full(len(df_main), np.nan)\n",
    "    idx_map  = np.where(keep_mask)[0]   # posisi baris yang punya target, di df_main yang sudah disort\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(X), 1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "        valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"RMSE\",\n",
    "            depth=8,\n",
    "            learning_rate=0.05,\n",
    "            l2_leaf_reg=3.0,\n",
    "            iterations=2000,\n",
    "            random_seed=42,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=100,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "        # ==================================================\n",
    "        # Hitung Train RMSE\n",
    "        # ==================================================\n",
    "        pred_tr = model.predict(train_pool)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_tr, pred_tr))\n",
    "\n",
    "        # ==================================================\n",
    "        # Prediksi Validation\n",
    "        # ==================================================\n",
    "        pred_va = model.predict(valid_pool)\n",
    "        oof_pred[idx_map[va_idx]] = pred_va\n",
    "\n",
    "        # ==================================================\n",
    "        # Hitung Validation Metrics\n",
    "        # ==================================================\n",
    "        mae   = mean_absolute_error(y_va, pred_va)\n",
    "        rmse  = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "        r2    = r2_score(y_va, pred_va)\n",
    "        rpmse = (rmse / np.mean(y_va)) * 100\n",
    "\n",
    "        print(\n",
    "            f\"[{sheet_cluster}] Fold {fold}: \"\n",
    "            f\"Train RMSE={rmse_train:.2f} | \"\n",
    "            f\"Val RMSE={rmse:.2f} | \"\n",
    "            f\"MAE={mae:.2f} | \"\n",
    "            f\"RPMSE={rpmse:.2f}% | \"\n",
    "            f\"R²={r2:.3f}\"\n",
    "        )\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        rpmse_scores.append(rpmse)\n",
    "\n",
    "\n",
    "        # print(f\"[{sheet_cluster}] Fold {fold}: MAE={mae:.2f} | RMSE={rmse:.2f} | RPMSE={rpmse:.2f}% | R²={r2:.3f}\")\n",
    "\n",
    "    print(f\"\\n=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk {sheet_cluster} ===\")\n",
    "    print(f\"MAE   : {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "    print(f\"RMSE  : {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")\n",
    "    print(f\"RPMSE : {np.mean(rpmse_scores):.2f}% ± {np.std(rpmse_scores):.2f}%\")\n",
    "    print(f\"R²    : {np.mean(r2_scores):.3f} ± {np.std(r2_scores):.3f}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Simpan hasil OOF (termasuk cluster, harga aktual, prediksi)\n",
    "    # --------------------------------------------------\n",
    "    df_out = df_main.copy()\n",
    "    df_out[\"oof_pred\"] = oof_pred\n",
    "\n",
    "    # tambahkan kolom harga aktual jika belum ada\n",
    "    if price_col not in df_out.columns:\n",
    "        df_out[price_col] = y_all.values\n",
    "\n",
    "    # pastikan kolom cluster ikut tersimpan\n",
    "    cols_to_save = [CLUSTER_COL, price_col, \"oof_pred\"]\n",
    "    df_out[cols_to_save].to_excel(output_file, index=False)\n",
    "\n",
    "    print(f\"\\nPrediksi OOF tersimpan di: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb40acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Proses Monthly_Fixed_clustered / Monthly_Fixed_CuryUnitPrice =================\n",
      "[Monthly_Fixed_clustered] Fold 1: Train RMSE=45627.04 | Val RMSE=76711.82 | MAE=50525.23 | RPMSE=30.36% | R²=0.886\n",
      "[Monthly_Fixed_clustered] Fold 2: Train RMSE=38999.86 | Val RMSE=70642.76 | MAE=42265.84 | RPMSE=30.23% | R²=0.889\n",
      "[Monthly_Fixed_clustered] Fold 3: Train RMSE=40146.31 | Val RMSE=57333.29 | MAE=37245.78 | RPMSE=24.25% | R²=0.936\n",
      "[Monthly_Fixed_clustered] Fold 4: Train RMSE=53871.20 | Val RMSE=60936.85 | MAE=43071.62 | RPMSE=25.50% | R²=0.920\n",
      "[Monthly_Fixed_clustered] Fold 5: Train RMSE=39160.72 | Val RMSE=227851.16 | MAE=72020.08 | RPMSE=94.70% | R²=0.633\n",
      "\n",
      "=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk Monthly_Fixed_clustered ===\n",
      "MAE   : 49025.71 ± 12254.82\n",
      "RMSE  : 98695.18 ± 64943.01\n",
      "RPMSE : 41.01% ± 26.96%\n",
      "R²    : 0.853 ± 0.111\n",
      "\n",
      "Prediksi OOF tersimpan di: catboost_oof_pred_with_cluster_walkforward_Monthly.xlsx\n",
      "\n",
      "================= Proses Daily_Fixed_clustered / Daily_Fixed_CuryUnitPrice =================\n",
      "[Daily_Fixed_clustered] Fold 1: Train RMSE=3341.65 | Val RMSE=5594.90 | MAE=4244.41 | RPMSE=16.80% | R²=0.925\n",
      "[Daily_Fixed_clustered] Fold 2: Train RMSE=3549.29 | Val RMSE=5043.17 | MAE=3994.12 | RPMSE=13.28% | R²=0.961\n",
      "[Daily_Fixed_clustered] Fold 3: Train RMSE=4060.47 | Val RMSE=5360.00 | MAE=4039.10 | RPMSE=14.40% | R²=0.951\n",
      "[Daily_Fixed_clustered] Fold 4: Train RMSE=4119.29 | Val RMSE=5452.65 | MAE=4296.00 | RPMSE=17.03% | R²=0.932\n",
      "[Daily_Fixed_clustered] Fold 5: Train RMSE=3529.37 | Val RMSE=4796.38 | MAE=3648.21 | RPMSE=14.88% | R²=0.934\n",
      "\n",
      "=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk Daily_Fixed_clustered ===\n",
      "MAE   : 4044.37 ± 229.27\n",
      "RMSE  : 5249.42 ± 290.06\n",
      "RPMSE : 15.28% ± 1.43%\n",
      "R²    : 0.940 ± 0.013\n",
      "\n",
      "Prediksi OOF tersimpan di: catboost_oof_pred_with_cluster_walkforward_Daily.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main\n",
    "xls = pd.ExcelFile(FILE_CLUSTERED)\n",
    "\n",
    "for cfg in SHEET_CONFIGS:\n",
    "    run_for_sheet(\n",
    "        xls=xls,\n",
    "        sheet_cluster=cfg[\"SHEET_CLUSTER\"],\n",
    "        price_sheet=cfg[\"PRICE_SHEET\"],\n",
    "        price_col_name=cfg[\"PRICE_COL\"],\n",
    "        output_file=cfg[\"OUTPUT_FILE\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33557c8b",
   "metadata": {},
   "source": [
    "### ini + PDRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "67cacce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CLUSTERED = r\"D:/DATA SKRIPSI/kontrak_sewa_bersih_clustered.xlsx\"\n",
    "INFLATION_FILE = r\"D:/DATA SKRIPSI/Laju Inflasi Di Kota Surabaya Tahun 2006-2020.csv\"\n",
    "PDRB_FILE = r\"D:/DATA SKRIPSI/Laju Pertumbuhan Produk Domestik Regional Bruto Atas Dasar Harga Konstan 2010 Menurut Lapangan Usaha di Kota Surabaya (persen), 2024.csv\"\n",
    "\n",
    "CLUSTER_COL = \"cluster\"\n",
    "\n",
    "SHEET_CONFIGS = [\n",
    "    {\n",
    "        \"freq_name\": \"Monthly\",\n",
    "        \"SHEET_CLUSTER\": \"Monthly_Fixed_clustered\",\n",
    "        \"PRICE_COL\": \"CuryUnitPrice\",\n",
    "        \"sheet_name_out\": \"Monthly\",\n",
    "    },\n",
    "    {\n",
    "        \"freq_name\": \"Daily\",\n",
    "        \"SHEET_CLUSTER\": \"Daily_Fixed_clustered\",\n",
    "        \"PRICE_COL\": \"CuryUnitPrice\",\n",
    "        \"sheet_name_out\": \"Daily\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\", \"LeaseMonthStart\", \"LeaseDayStart\",\n",
    "    \"LeaseMonthEnd\", \"LeaseDayEnd\", \"TranCode\",\n",
    "    \"ContractPeriod\", \"ContractType\", \"Building\",\n",
    "    \"UnitArea\", \"UnitFloor\"\n",
    "]\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"BuildingArea\", \"LeaseDurationDays\", \"LeaseDurationMonths\",\n",
    "    \"LeaseYearStart\", \"LeaseYearEnd\", \"n_subunit\",\n",
    "]\n",
    "\n",
    "# Flag opsional: kalau mau langsung menampilkan summary plot SHAP\n",
    "PLOT_SHAP_SUMMARY = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee43a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_price_column(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    s = df[col].astype(str).str.strip()\n",
    "    s = s.str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Load Inflasi Bulanan (wide → long)\n",
    "# ============================================\n",
    "def load_monthly_inflation(path: str) -> pd.DataFrame:\n",
    "    df_raw = pd.read_csv(path, sep=';', engine='python')\n",
    "    df_raw = clean_columns(df_raw)\n",
    "\n",
    "    # baris pertama (index 0) berisi label tahun untuk kolom-kolom lain\n",
    "    year_labels = df_raw.iloc[0, 1:]\n",
    "\n",
    "    month_map = {\n",
    "        \"Januari\": 1, \"Februari\": 2, \"Maret\": 3, \"April\": 4, \"Mei\": 5,\n",
    "        \"Juni\": 6, \"Juli\": 7, \"Agustus\": 8, \"September\": 9, \"Oktober\": 10,\n",
    "        \"November\": 11, \"Desember\": 12\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    # data bulan mulai di baris index 3 (sesuai file inflasi)\n",
    "    for i in range(3, len(df_raw)):\n",
    "        month_name = df_raw.iloc[i, 0]\n",
    "        if not isinstance(month_name, str):\n",
    "            continue\n",
    "        month_name = month_name.strip()\n",
    "        if month_name == \"\" or \"sumber\" in month_name.lower():\n",
    "            continue\n",
    "\n",
    "        m = month_map.get(month_name)\n",
    "        if m is None:\n",
    "            continue\n",
    "\n",
    "        for col in df_raw.columns[1:]:\n",
    "            year_val = year_labels[col]\n",
    "            try:\n",
    "                y = int(str(year_val))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            val = df_raw.at[i, col]\n",
    "            if isinstance(val, str):\n",
    "                val = val.replace(\",\", \".\")\n",
    "            try:\n",
    "                infl_val = float(val)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"LeaseYearStart\": y,\n",
    "                \"LeaseMonthStart\": m,\n",
    "                \"Inflation\": infl_val\n",
    "            })\n",
    "\n",
    "    infl_long = pd.DataFrame(rows)\n",
    "\n",
    "    infl_long = (\n",
    "        infl_long\n",
    "        .groupby([\"LeaseYearStart\", \"LeaseMonthStart\"], as_index=False)[\"Inflation\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    return infl_long\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Load Pertumbuhan PDRB (bentuk seperti screenshot)\n",
    "# ============================================\n",
    "def load_pdrb_growth(path: str) -> pd.DataFrame:\n",
    "    import pandas as pd\n",
    "\n",
    "    # Paksa pakai delimiter ';'\n",
    "    df_raw = pd.read_csv(\n",
    "        path,\n",
    "        sep=';',            # <--- ganti ini\n",
    "        header=None,\n",
    "        encoding='utf-8-sig'  # buang karakter BOM di awal \"﻿Lapangan...\"\n",
    "    )\n",
    "    # kalau mau, baru panggil clean_columns di sini\n",
    "    # df_raw = clean_columns(df_raw)\n",
    "\n",
    "    # --- kolom 0: tahun ---\n",
    "    col_year_raw = df_raw.iloc[:, 0].astype(str).str.strip()\n",
    "    col_year = pd.to_numeric(col_year_raw, errors=\"coerce\")\n",
    "\n",
    "    # --- kolom 1: pertumbuhan ---\n",
    "    col_growth_raw = df_raw.iloc[:, 1].astype(str).str.strip()\n",
    "    col_growth_clean = (\n",
    "        col_growth_raw\n",
    "        .str.replace(\"%\", \"\", regex=False)\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    col_growth = pd.to_numeric(col_growth_clean, errors=\"coerce\")\n",
    "\n",
    "    mask = ~col_year.isna() & ~col_growth.isna()\n",
    "\n",
    "    pdrb = pd.DataFrame({\n",
    "        \"LeaseYearStart\": col_year[mask].astype(\"Int64\"),\n",
    "        \"GDP_Growth\": col_growth[mask]\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    return pdrb\n",
    "\n",
    "\n",
    "# Fungsi utama per sheet\n",
    "\n",
    "\n",
    "OOF_FILE = \"catboost_oof_pred_with_cluster_walkforward.xlsx\"\n",
    "SHAP_FILE = \"catboost_oof_pred_with_cluster_walkforward_SHAP_importance.xlsx\"\n",
    "\n",
    "\n",
    "def run_for_sheet(\n",
    "    xls: pd.ExcelFile,\n",
    "    sheet_cluster: str,\n",
    "    price_col_name: str,\n",
    "    sheet_name_out: str,\n",
    "    infl_long: pd.DataFrame,\n",
    "    pdrb_growth: pd.DataFrame,\n",
    "):\n",
    "    print(f\"\\n================= Proses {sheet_cluster} =================\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # BEST PARAMETER PER PERIODE\n",
    "    # ----------------------------------------------------\n",
    "    BEST_CB_PARAMS = {\n",
    "        \"monthly\": {\n",
    "            \"depth\": 4,\n",
    "            \"learning_rate\": 0.017,\n",
    "            \"l2_leaf_reg\": 9.951,\n",
    "            \"iterations\": 1491,\n",
    "        },\n",
    "        \"daily\": {\n",
    "            \"depth\": 8,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"l2_leaf_reg\": 3.0,\n",
    "            \"iterations\": 2000,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    sheet_lower = sheet_cluster.lower()\n",
    "    if \"monthly\" in sheet_lower:\n",
    "        period_key = \"monthly\"\n",
    "    elif \"daily\" in sheet_lower:\n",
    "        period_key = \"daily\"\n",
    "    else:\n",
    "        period_key = None\n",
    "\n",
    "    if period_key in BEST_CB_PARAMS:\n",
    "        cb_params = BEST_CB_PARAMS[period_key]\n",
    "    else:\n",
    "        cb_params = {\n",
    "            \"depth\": 8,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"l2_leaf_reg\": 3.0,\n",
    "            \"iterations\": 2000,\n",
    "        }\n",
    "\n",
    "    # ===================== LOAD SHEET CLUSTER =====================\n",
    "    if sheet_cluster not in xls.sheet_names:\n",
    "        raise KeyError(\n",
    "            f\"Sheet cluster '{sheet_cluster}' tidak ditemukan di {FILE_CLUSTERED}.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        df_main = clean_columns(pd.read_excel(xls, sheet_name=sheet_cluster))\n",
    "    except ValueError:\n",
    "        df_main = clean_columns(pd.read_excel(xls, sheet_name=0))\n",
    "\n",
    "    # simpan urutan asli sebelum ada filtering/sorting apa pun\n",
    "    df_main[\"__orig_idx__\"] = np.arange(len(df_main))\n",
    "\n",
    "    if CLUSTER_COL not in df_main.columns:\n",
    "        raise KeyError(\n",
    "            f\"Kolom cluster '{CLUSTER_COL}' tidak ditemukan di sheet '{sheet_cluster}'. \"\n",
    "            \"Pastikan hasil clustering sudah disimpan sebagai kolom tersebut.\"\n",
    "        )\n",
    "\n",
    "    # ---- merge Inflasi dan PDRB ----\n",
    "    if {\"LeaseYearStart\", \"LeaseMonthStart\"}.issubset(df_main.columns):\n",
    "        df_main = df_main.merge(\n",
    "            infl_long,\n",
    "            on=[\"LeaseYearStart\", \"LeaseMonthStart\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "    if \"LeaseYearStart\" in df_main.columns and \"LeaseYearStart\" in pdrb_growth.columns:\n",
    "        df_main = df_main.merge(\n",
    "            pdrb_growth,\n",
    "            on=\"LeaseYearStart\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"PERINGATAN: 'LeaseYearStart' tidak ada di pdrb_growth – GDP_Growth tidak dipakai.\")\n",
    "\n",
    "    # ===================== LOAD PRICE DARI SHEET CLUSTER =====================\n",
    "    price_col = price_col_name\n",
    "    if price_col not in df_main.columns:\n",
    "        # fallback cari kolom yang mengandung kata 'price'\n",
    "        cands = [c for c in df_main.columns if \"price\" in c.lower()]\n",
    "        if not cands:\n",
    "            raise KeyError(\n",
    "                f\"Kolom target '{price_col}' tidak ditemukan dan tidak ada kolom mirip 'price' di sheet '{sheet_cluster}'.\"\n",
    "            )\n",
    "        price_col = cands[0]\n",
    "        print(f\"[INFO] Kolom price tidak ditemukan, pakai kolom mirip: {price_col}\")\n",
    "\n",
    "    # konversi harga ke numerik (pakai helper yang sudah ada)\n",
    "    y_all = parse_price_column(df_main, price_col)\n",
    "\n",
    "    # ---- urutkan berdasarkan tanggal ----\n",
    "    need_cols = {\"LeaseYearStart\", \"LeaseMonthStart\", \"LeaseDayStart\"}\n",
    "    if not need_cols.issubset(df_main.columns):\n",
    "        raise KeyError(\n",
    "            \"Untuk walk-forward CV dibutuhkan kolom LeaseYearStart, LeaseMonthStart, LeaseDayStart.\"\n",
    "        )\n",
    "\n",
    "    lease_start_date = pd.to_datetime(\n",
    "        dict(\n",
    "            year=df_main[\"LeaseYearStart\"],\n",
    "            month=df_main[\"LeaseMonthStart\"],\n",
    "            day=df_main[\"LeaseDayStart\"],\n",
    "        ),\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "\n",
    "    valid_date_mask = ~lease_start_date.isna()\n",
    "    df_main = df_main.loc[valid_date_mask].reset_index(drop=True)\n",
    "    y_all = y_all.loc[valid_date_mask].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.loc[valid_date_mask].reset_index(drop=True)\n",
    "\n",
    "    order = np.argsort(lease_start_date.values)\n",
    "    df_main = df_main.iloc[order].reset_index(drop=True)\n",
    "    y_all = y_all.iloc[order].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.iloc[order].reset_index(drop=True)\n",
    "\n",
    "    # ---- fitur ----\n",
    "    all_cat_cols = CATEGORICAL_COLS + [CLUSTER_COL]\n",
    "\n",
    "    cat_all = [c for c in all_cat_cols if c in df_main.columns]\n",
    "    num_all = [c for c in NUMERIC_COLS if c in df_main.columns]\n",
    "\n",
    "    for extra in [\"Inflation\", \"GDP_Growth\"]:\n",
    "        if extra in df_main.columns and extra not in num_all:\n",
    "            num_all.append(extra)\n",
    "\n",
    "    feature_cols = cat_all + num_all\n",
    "\n",
    "    X_all = df_main[feature_cols].copy()\n",
    "\n",
    "    for c in cat_all:\n",
    "        X_all[c] = X_all[c].astype(str)\n",
    "    for c in num_all:\n",
    "        X_all[c] = pd.to_numeric(X_all[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    keep_mask = ~y_all.isna()\n",
    "    X = X_all.loc[keep_mask].reset_index(drop=True)\n",
    "    y = y_all.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    cat_feature_idx = [X.columns.get_loc(c) for c in cat_all]\n",
    "\n",
    "    # ---- Walk-forward CV CatBoost ----\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    mae_scores, rmse_scores, r2_scores, rpmse_scores = [], [], [], []\n",
    "\n",
    "    oof_pred = np.full(len(df_main), np.nan)\n",
    "    idx_map = np.where(keep_mask)[0]\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(X), 1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "        valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"RMSE\",\n",
    "            depth=cb_params[\"depth\"],\n",
    "            learning_rate=cb_params[\"learning_rate\"],\n",
    "            l2_leaf_reg=cb_params[\"l2_leaf_reg\"],\n",
    "            iterations=cb_params[\"iterations\"],\n",
    "            random_seed=42,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=100,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "        pred_tr = model.predict(train_pool)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_tr, pred_tr))\n",
    "\n",
    "        pred_va = model.predict(valid_pool)\n",
    "        oof_pred[idx_map[va_idx]] = pred_va\n",
    "\n",
    "        mae = mean_absolute_error(y_va, pred_va)\n",
    "        rmse = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "        r2 = r2_score(y_va, pred_va)\n",
    "        rpmse = (rmse / np.mean(y_va)) * 100\n",
    "\n",
    "        print(\n",
    "            f\"[{sheet_cluster}] Fold {fold}: \"\n",
    "            f\"Train RMSE={rmse_train:.2f} | \"\n",
    "            f\"Val RMSE={rmse:.2f} | \"\n",
    "            f\"MAE={mae:.2f} | \"\n",
    "            f\"RPMSE={rpmse:.2f}% | \"\n",
    "            f\"R²={r2:.3f}\"\n",
    "        )\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        rpmse_scores.append(rpmse)\n",
    "\n",
    "    print(f\"\\n=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk {sheet_cluster} ===\")\n",
    "    print(f\"MAE   : {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "    print(f\"RMSE  : {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")\n",
    "    print(f\"RPMSE : {np.mean(rpmse_scores):.2f}% ± {np.std(rpmse_scores):.2f}%\")\n",
    "    print(f\"R²    : {np.mean(r2_scores):.3f} ± {np.std(r2_scores):.3f}\")\n",
    "\n",
    "    \n",
    "    # SHAP: Train 1 model final di seluruh data X,y\n",
    "    \n",
    "    print(f\"\\n[SHAP] Training final CatBoost model untuk SHAP pada sheet {sheet_cluster} ...\")\n",
    "\n",
    "    final_model = CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        depth=cb_params[\"depth\"],\n",
    "        learning_rate=cb_params[\"learning_rate\"],\n",
    "        l2_leaf_reg=cb_params[\"l2_leaf_reg\"],\n",
    "        iterations=cb_params[\"iterations\"],\n",
    "        random_seed=42,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=100,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    final_pool = Pool(X, y, cat_features=cat_feature_idx)\n",
    "    final_model.fit(final_pool)\n",
    "\n",
    "    shap_values_cat = final_model.get_feature_importance(\n",
    "        final_pool,\n",
    "        type=\"ShapValues\"\n",
    "    )\n",
    "    shap_values = shap_values_cat[:, :-1]\n",
    "    base_values = shap_values_cat[:, -1]\n",
    "\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    shap_importance = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"mean_abs_shap\": mean_abs_shap\n",
    "    }).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "    print(\"\\n[SHAP] Global feature importance (mean |SHAP|):\")\n",
    "    print(shap_importance)\n",
    "\n",
    "    # ============================================\n",
    "    # SAVE SHAP IMPORTANCE → 1 FILE, MULTI-SHEET\n",
    "    # ============================================\n",
    "    if os.path.exists(SHAP_FILE):\n",
    "        mode = \"a\"\n",
    "        if_sheet_exists = \"replace\"\n",
    "    else:\n",
    "        mode = \"w\"\n",
    "        if_sheet_exists = None\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "        SHAP_FILE,\n",
    "        engine=\"openpyxl\",\n",
    "        mode=mode,\n",
    "        if_sheet_exists=if_sheet_exists\n",
    "    ) as writer:\n",
    "        shap_importance.to_excel(writer, sheet_name=sheet_name_out, index=False)\n",
    "\n",
    "    print(f\"[SHAP] Rangkuman SHAP importance tersimpan di file: {SHAP_FILE} | sheet: {sheet_name_out}\")\n",
    "\n",
    "    save_row_shap = False\n",
    "    if save_row_shap:\n",
    "        df_shap_row = pd.DataFrame(shap_values, columns=[f\"SHAP_{c}\" for c in X.columns])\n",
    "        df_shap_row[\"base_value\"] = base_values\n",
    "        df_shap_row[\"y_true\"] = y.values\n",
    "\n",
    "        shap_row_file = f\"SHAP_per_row_{sheet_name_out}.xlsx\"\n",
    "        df_shap_row.to_excel(shap_row_file, index=False)\n",
    "        print(f\"[SHAP] SHAP per baris tersimpan di: {shap_row_file}\")\n",
    "\n",
    "    if PLOT_SHAP_SUMMARY:\n",
    "        try:\n",
    "            explainer = shap.TreeExplainer(final_model)\n",
    "            shap_values_for_plot = explainer.shap_values(X)\n",
    "\n",
    "            shap.summary_plot(\n",
    "                shap_values_for_plot,\n",
    "                X,\n",
    "                feature_names=X.columns,\n",
    "                show=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[SHAP] Gagal membuat summary_plot: {e}\")\n",
    "\n",
    "    # ============================================\n",
    "    # SAVE OOF → 1 FILE, MULTI-SHEET\n",
    "    # ============================================\n",
    "    df_out = df_main.copy()\n",
    "    df_out[\"oof_pred\"] = oof_pred\n",
    "\n",
    "    if price_col not in df_out.columns:\n",
    "        df_out[price_col] = y_all.values\n",
    "\n",
    "    cols_to_save = [\n",
    "        c for c in [CLUSTER_COL, price_col, \"Inflation\", \"GDP_Growth\", \"oof_pred\", \"__orig_idx__\"]\n",
    "        if c in df_out.columns\n",
    "    ]\n",
    "\n",
    "    # urutkan kembali sesuai urutan baris awal input\n",
    "    df_save = df_out[cols_to_save].sort_values(\"__orig_idx__\").drop(columns=\"__orig_idx__\")\n",
    "\n",
    "    if os.path.exists(OOF_FILE):\n",
    "        mode = \"a\"\n",
    "        if_sheet_exists = \"replace\"\n",
    "    else:\n",
    "        mode = \"w\"\n",
    "        if_sheet_exists = None\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "        OOF_FILE,\n",
    "        engine=\"openpyxl\",\n",
    "        mode=mode,\n",
    "        if_sheet_exists=if_sheet_exists\n",
    "    ) as writer:\n",
    "        df_save.to_excel(writer, sheet_name=sheet_name_out, index=False)\n",
    "\n",
    "    print(f\"\\nPrediksi OOF tersimpan di: {OOF_FILE} | sheet: {sheet_name_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "75604958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Proses Monthly_Fixed_clustered =================\n",
      "[Monthly_Fixed_clustered] Fold 1: Train RMSE=54750.01 | Val RMSE=73954.17 | MAE=50236.89 | RPMSE=29.27% | R²=0.894\n",
      "[Monthly_Fixed_clustered] Fold 2: Train RMSE=58915.05 | Val RMSE=68417.27 | MAE=47618.57 | RPMSE=29.27% | R²=0.896\n",
      "[Monthly_Fixed_clustered] Fold 3: Train RMSE=54391.71 | Val RMSE=63105.43 | MAE=41802.57 | RPMSE=26.69% | R²=0.923\n",
      "[Monthly_Fixed_clustered] Fold 4: Train RMSE=65114.44 | Val RMSE=61113.31 | MAE=43620.23 | RPMSE=25.57% | R²=0.920\n",
      "[Monthly_Fixed_clustered] Fold 5: Train RMSE=55289.33 | Val RMSE=136939.37 | MAE=60499.96 | RPMSE=56.92% | R²=0.868\n",
      "\n",
      "=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk Monthly_Fixed_clustered ===\n",
      "MAE   : 48755.64 ± 6574.71\n",
      "RMSE  : 80705.91 ± 28469.09\n",
      "RPMSE : 33.55% ± 11.77%\n",
      "R²    : 0.900 ± 0.020\n",
      "\n",
      "[SHAP] Training final CatBoost model untuk SHAP pada sheet Monthly_Fixed_clustered ...\n",
      "\n",
      "[SHAP] Global feature importance (mean |SHAP|):\n",
      "                feature  mean_abs_shap\n",
      "11              cluster  132187.564961\n",
      "12         BuildingArea   28278.188011\n",
      "7          ContractType   12669.140244\n",
      "8              Building    9803.882082\n",
      "5              TranCode    2411.158621\n",
      "14  LeaseDurationMonths    2037.846922\n",
      "13    LeaseDurationDays    1773.733376\n",
      "2         LeaseDayStart    1570.741384\n",
      "10            UnitFloor    1527.784536\n",
      "16         LeaseYearEnd    1291.668266\n",
      "18            Inflation    1231.378858\n",
      "1       LeaseMonthStart    1200.272513\n",
      "3         LeaseMonthEnd    1154.539980\n",
      "9              UnitArea     859.996975\n",
      "15       LeaseYearStart     723.582764\n",
      "0          BusinessType     636.853882\n",
      "4           LeaseDayEnd     588.429365\n",
      "19           GDP_Growth     389.385522\n",
      "17            n_subunit     318.288022\n",
      "6        ContractPeriod       0.000000\n",
      "[SHAP] Rangkuman SHAP importance tersimpan di file: catboost_oof_pred_with_cluster_walkforward_SHAP_importance.xlsx | sheet: Monthly\n",
      "\n",
      "Prediksi OOF tersimpan di: catboost_oof_pred_with_cluster_walkforward.xlsx | sheet: Monthly\n",
      "\n",
      "================= Proses Daily_Fixed_clustered =================\n",
      "[Daily_Fixed_clustered] Fold 1: Train RMSE=3146.38 | Val RMSE=5788.99 | MAE=4424.46 | RPMSE=17.38% | R²=0.920\n",
      "[Daily_Fixed_clustered] Fold 2: Train RMSE=3694.48 | Val RMSE=5396.39 | MAE=4250.41 | RPMSE=14.21% | R²=0.955\n",
      "[Daily_Fixed_clustered] Fold 3: Train RMSE=4026.96 | Val RMSE=5616.55 | MAE=4205.43 | RPMSE=15.09% | R²=0.946\n",
      "[Daily_Fixed_clustered] Fold 4: Train RMSE=4096.21 | Val RMSE=5312.65 | MAE=4254.90 | RPMSE=16.60% | R²=0.936\n",
      "[Daily_Fixed_clustered] Fold 5: Train RMSE=3391.56 | Val RMSE=4633.12 | MAE=3610.86 | RPMSE=14.38% | R²=0.938\n",
      "\n",
      "=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk Daily_Fixed_clustered ===\n",
      "MAE   : 4149.21 ± 279.34\n",
      "RMSE  : 5349.54 ± 395.28\n",
      "RPMSE : 15.53% ± 1.25%\n",
      "R²    : 0.939 ± 0.012\n",
      "\n",
      "[SHAP] Training final CatBoost model untuk SHAP pada sheet Daily_Fixed_clustered ...\n",
      "\n",
      "[SHAP] Global feature importance (mean |SHAP|):\n",
      "                feature  mean_abs_shap\n",
      "11              cluster   13858.031524\n",
      "7          ContractType    1861.701293\n",
      "12         BuildingArea    1065.363957\n",
      "8              Building     524.610453\n",
      "10            UnitFloor     480.749939\n",
      "5              TranCode     355.527032\n",
      "9              UnitArea     250.202519\n",
      "13    LeaseDurationDays     245.557289\n",
      "16         LeaseYearEnd     231.731324\n",
      "2         LeaseDayStart     222.547547\n",
      "15       LeaseYearStart     216.317196\n",
      "4           LeaseDayEnd     205.341669\n",
      "3         LeaseMonthEnd     190.255028\n",
      "18            Inflation     183.920872\n",
      "19           GDP_Growth     170.335980\n",
      "1       LeaseMonthStart     146.009718\n",
      "0          BusinessType     118.529404\n",
      "14  LeaseDurationMonths      31.474319\n",
      "17            n_subunit       1.219514\n",
      "6        ContractPeriod       0.000000\n",
      "[SHAP] Rangkuman SHAP importance tersimpan di file: catboost_oof_pred_with_cluster_walkforward_SHAP_importance.xlsx | sheet: Daily\n",
      "\n",
      "Prediksi OOF tersimpan di: catboost_oof_pred_with_cluster_walkforward.xlsx | sheet: Daily\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load data inflasi & PDRB\n",
    "    infl_long = load_monthly_inflation(INFLATION_FILE)\n",
    "    pdrb_growth = load_pdrb_growth(PDRB_FILE)\n",
    "\n",
    "    # Load Excel utama\n",
    "    xls = pd.ExcelFile(FILE_CLUSTERED)\n",
    "\n",
    "    # Loop untuk masing-masing konfigurasi sheet (Monthly & Daily)\n",
    "    for cfg in SHEET_CONFIGS:\n",
    "        run_for_sheet(\n",
    "            xls=xls,\n",
    "            sheet_cluster=cfg[\"SHEET_CLUSTER\"],\n",
    "            price_col_name=cfg[\"PRICE_COL\"],\n",
    "            infl_long=infl_long,\n",
    "            pdrb_growth=pdrb_growth,\n",
    "            sheet_name_out=cfg[\"sheet_name_out\"],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8116b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Proses Monthly_Fixed_clustered / Monthly_Fixed_CuryUnitPrice =================\n",
      "[Monthly_Fixed_clustered] Fold 1: Train RMSE=39402.07 | Val RMSE=75605.53 | MAE=48665.33 | RPMSE=29.92% | R²=0.889\n",
      "[Monthly_Fixed_clustered] Fold 2: Train RMSE=38918.18 | Val RMSE=70459.53 | MAE=43083.04 | RPMSE=30.15% | R²=0.889\n",
      "[Monthly_Fixed_clustered] Fold 3: Train RMSE=37819.88 | Val RMSE=56336.91 | MAE=36555.17 | RPMSE=23.83% | R²=0.938\n",
      "[Monthly_Fixed_clustered] Fold 4: Train RMSE=54612.72 | Val RMSE=60556.49 | MAE=42169.52 | RPMSE=25.34% | R²=0.921\n",
      "[Monthly_Fixed_clustered] Fold 5: Train RMSE=45453.37 | Val RMSE=201341.30 | MAE=69180.15 | RPMSE=83.68% | R²=0.714\n",
      "\n",
      "=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk Monthly_Fixed_clustered ===\n",
      "MAE   : 47930.64 ± 11297.54\n",
      "RMSE  : 92859.96 ± 54672.01\n",
      "RPMSE : 38.58% ± 22.69%\n",
      "R²    : 0.870 ± 0.081\n",
      "\n",
      "[SHAP] Training final CatBoost model untuk SHAP pada sheet Monthly_Fixed_clustered ...\n",
      "\n",
      "[SHAP] Global feature importance (mean |SHAP|):\n",
      "                feature  mean_abs_shap\n",
      "11              cluster  130683.180285\n",
      "12         BuildingArea   30646.743832\n",
      "8              Building   12096.178213\n",
      "7          ContractType    8573.893867\n",
      "14  LeaseDurationMonths    3900.735993\n",
      "10            UnitFloor    3825.801190\n",
      "9              UnitArea    3039.364317\n",
      "1       LeaseMonthStart    2474.540833\n",
      "2         LeaseDayStart    2437.544210\n",
      "3         LeaseMonthEnd    2396.689092\n",
      "5              TranCode    2273.581008\n",
      "4           LeaseDayEnd    2186.480072\n",
      "16         LeaseYearEnd    2035.610905\n",
      "18            Inflation    1986.738524\n",
      "13    LeaseDurationDays    1977.396052\n",
      "19           GDP_Growth    1692.259548\n",
      "0          BusinessType    1565.739671\n",
      "15       LeaseYearStart    1335.064448\n",
      "17            n_subunit     953.219040\n",
      "6        ContractPeriod       0.000000\n",
      "[SHAP] Rangkuman SHAP importance tersimpan di: catboost_oof_pred_with_cluster_walkforward_Monthly_SHAP_importance.xlsx\n",
      "\n",
      "Prediksi OOF tersimpan di: catboost_oof_pred_with_cluster_walkforward_Monthly.xlsx\n",
      "\n",
      "================= Proses Daily_Fixed_clustered / Daily_Fixed_CuryUnitPrice =================\n",
      "[Daily_Fixed_clustered] Fold 1: Train RMSE=3146.38 | Val RMSE=5788.99 | MAE=4424.46 | RPMSE=17.38% | R²=0.920\n",
      "[Daily_Fixed_clustered] Fold 2: Train RMSE=3694.48 | Val RMSE=5396.39 | MAE=4250.41 | RPMSE=14.21% | R²=0.955\n",
      "[Daily_Fixed_clustered] Fold 3: Train RMSE=4026.96 | Val RMSE=5616.55 | MAE=4205.43 | RPMSE=15.09% | R²=0.946\n",
      "[Daily_Fixed_clustered] Fold 4: Train RMSE=4096.21 | Val RMSE=5312.65 | MAE=4254.90 | RPMSE=16.60% | R²=0.936\n",
      "[Daily_Fixed_clustered] Fold 5: Train RMSE=3391.56 | Val RMSE=4633.12 | MAE=3610.86 | RPMSE=14.38% | R²=0.938\n",
      "\n",
      "=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk Daily_Fixed_clustered ===\n",
      "MAE   : 4149.21 ± 279.34\n",
      "RMSE  : 5349.54 ± 395.28\n",
      "RPMSE : 15.53% ± 1.25%\n",
      "R²    : 0.939 ± 0.012\n",
      "\n",
      "[SHAP] Training final CatBoost model untuk SHAP pada sheet Daily_Fixed_clustered ...\n",
      "\n",
      "[SHAP] Global feature importance (mean |SHAP|):\n",
      "                feature  mean_abs_shap\n",
      "11              cluster   13858.031524\n",
      "7          ContractType    1861.701293\n",
      "12         BuildingArea    1065.363957\n",
      "8              Building     524.610453\n",
      "10            UnitFloor     480.749939\n",
      "5              TranCode     355.527032\n",
      "9              UnitArea     250.202519\n",
      "13    LeaseDurationDays     245.557289\n",
      "16         LeaseYearEnd     231.731324\n",
      "2         LeaseDayStart     222.547547\n",
      "15       LeaseYearStart     216.317196\n",
      "4           LeaseDayEnd     205.341669\n",
      "3         LeaseMonthEnd     190.255028\n",
      "18            Inflation     183.920872\n",
      "19           GDP_Growth     170.335980\n",
      "1       LeaseMonthStart     146.009718\n",
      "0          BusinessType     118.529404\n",
      "14  LeaseDurationMonths      31.474319\n",
      "17            n_subunit       1.219514\n",
      "6        ContractPeriod       0.000000\n",
      "[SHAP] Rangkuman SHAP importance tersimpan di: catboost_oof_pred_with_cluster_walkforward_Daily_SHAP_importance.xlsx\n",
      "\n",
      "Prediksi OOF tersimpan di: catboost_oof_pred_with_cluster_walkforward_Daily.xlsx\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load data inflasi & PDRB\n",
    "    infl_long = load_monthly_inflation(INFLATION_FILE)\n",
    "    pdrb_growth = load_pdrb_growth(PDRB_FILE)\n",
    "    \n",
    "    # Load Excel utama\n",
    "    xls = pd.ExcelFile(FILE_CLUSTERED)\n",
    "\n",
    "    # Loop untuk masing-masing konfigurasi sheet (Monthly & Daily)\n",
    "    for cfg in SHEET_CONFIGS:\n",
    "        run_for_sheet(\n",
    "            xls=xls,\n",
    "            sheet_cluster=cfg[\"SHEET_CLUSTER\"],\n",
    "            price_sheet=cfg[\"PRICE_SHEET\"],\n",
    "            price_col_name=cfg[\"PRICE_COL\"],\n",
    "            output_file=cfg[\"OUTPUT_FILE\"],\n",
    "            infl_long=infl_long,\n",
    "            pdrb_growth=pdrb_growth,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0c8d7",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _smart_read(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Helper kecil: baca file berdasarkan ekstensi.\n",
    "    Sesuaikan kalau semua file kamu pasti Excel / Parquet saja.\n",
    "    \"\"\"\n",
    "    path_lower = path.lower()\n",
    "    if path_lower.endswith(\".parquet\"):\n",
    "        return pd.read_parquet(path)\n",
    "    elif path_lower.endswith((\".xlsx\", \".xls\")):\n",
    "        return pd.read_excel(path)\n",
    "    else:\n",
    "        # default ke CSV\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def plot_oof_per_unitid(cfg: dict, unit_id: str,\n",
    "                        id_col: str = \"UnitID\"):\n",
    "\n",
    "    freq_name    = cfg[\"freq_name\"]\n",
    "    price_col    = cfg[\"PRICE_COL\"]              # nama kolom harga ACTUAL di kontrak / target\n",
    "    oof_file     = cfg[\"OUTPUT_FILE\"]            # <-- isi dengan \"catboost_oof_pred_with_cluster....\"\n",
    "    kontrak_file = cfg[\"KONTRAK_FILE\"]           # <-- isi dengan \"kontrak_sewa_bersih....\"\n",
    "\n",
    "    # === 1. Baca 2 file ===\n",
    "    df_oof     = _smart_read(oof_file)\n",
    "    df_kontrak = _smart_read(kontrak_file)\n",
    "\n",
    "    # Pastikan RowID ada di kedua file\n",
    "    if \"RowID\" not in df_oof.columns:\n",
    "        raise KeyError(\"Kolom 'RowID' tidak ada di file catboost_oof_pred_with_cluster.\")\n",
    "    if \"RowID\" not in df_kontrak.columns:\n",
    "        raise KeyError(\"Kolom 'RowID' tidak ada di file kontrak_sewa_bersih.\")\n",
    "\n",
    "    # === 2. Merge berdasarkan RowID ===\n",
    "    df_base = df_oof.merge(\n",
    "        df_kontrak,\n",
    "        on=\"RowID\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_kontrak\")\n",
    "    )\n",
    "\n",
    "    # === 3. Pastikan kolom harga ACTUAL benar ===\n",
    "    #    (harga actual biasanya di kontrak / target)\n",
    "    if price_col not in df_base.columns:\n",
    "        cands = [c for c in df_base.columns if \"price\" in c.lower() or \"tarif\" in c.lower()]\n",
    "        if not cands:\n",
    "            raise KeyError(\n",
    "                f\"Kolom harga actual '{price_col}' tidak ditemukan dan tidak ada kolom mirip 'price/tarif'.\"\n",
    "            )\n",
    "        price_col = cands[0]  # pakai kandidat pertama\n",
    "\n",
    "    # === 4. Pastikan kolom prediksi ada ===\n",
    "    if \"oof_pred\" not in df_base.columns:\n",
    "        cands_pred = [c for c in df_base.columns if \"pred\" in c.lower()]\n",
    "        if not cands_pred:\n",
    "            raise KeyError(\"Kolom 'oof_pred' tidak ditemukan di file catboost_oof_pred_with_cluster.\")\n",
    "        pred_col = cands_pred[0]\n",
    "    else:\n",
    "        pred_col = \"oof_pred\"\n",
    "\n",
    "    # === 5. Isi kolom Actual & Predicted ===\n",
    "    df_base[\"Actual\"]    = pd.to_numeric(df_base[price_col], errors=\"coerce\")\n",
    "    df_base[\"Predicted\"] = pd.to_numeric(df_base[pred_col],  errors=\"coerce\")\n",
    "\n",
    "    # === 6. Filter hanya baris untuk UnitID yang diminta ===\n",
    "    if id_col not in df_base.columns:\n",
    "        raise KeyError(f\"Kolom ID '{id_col}' tidak ada di hasil merge (cek file kontrak_sewa_bersih).\")\n",
    "\n",
    "    df_base = df_base[df_base[id_col] == unit_id].copy()\n",
    "\n",
    "    if df_base.empty:\n",
    "        print(f\"Tidak ada data untuk {id_col} = {unit_id}\")\n",
    "        return None\n",
    "\n",
    "    # Pastikan LeaseStartDate dalam bentuk datetime\n",
    "    if \"LeaseStartDate\" not in df_base.columns:\n",
    "        raise KeyError(\"Kolom 'LeaseStartDate' tidak ada di hasil merge (cek kontrak_sewa_bersih).\")\n",
    "\n",
    "    df_base[\"LeaseStartDate\"] = pd.to_datetime(df_base[\"LeaseStartDate\"])\n",
    "\n",
    "    # Sort berdasarkan tanggal\n",
    "    df_base = df_base.sort_values(\"LeaseStartDate\")\n",
    "\n",
    "    # === 7. Hitung SMA untuk Predicted di seluruh periode ===\n",
    "    SMOOTH_WINDOW = 7   # smoothing Predicted\n",
    "    df_base[\"Predicted_SMA\"] = (\n",
    "        df_base[\"Predicted\"]\n",
    "        .rolling(window=SMOOTH_WINDOW, min_periods=1)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    # === 8. Plot dalam 1 grafik ===\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Raw data Actual & Predicted\n",
    "    plt.plot(\n",
    "        df_base[\"LeaseStartDate\"], df_base[\"Actual\"],\n",
    "        alpha=0.6, linewidth=2.0, label=\"Actual (raw)\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        df_base[\"LeaseStartDate\"], df_base[\"Predicted\"],\n",
    "        alpha=0.6, linewidth=2.0, label=\"Predicted (raw)\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    plt.title(f\"{freq_name} — {id_col}={unit_id} — Actual vs Predicted\")\n",
    "    plt.xlabel(\"Lease Start Date\")\n",
    "    plt.ylabel(price_col)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # === 9. Simpan gambar ===\n",
    "    safe_unit = str(unit_id).replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    out_file = f\"{freq_name}_{id_col}_{safe_unit}_actual_vs_predicted.png\"\n",
    "\n",
    "    if os.path.exists(out_file):\n",
    "        os.remove(out_file)\n",
    "\n",
    "    plt.savefig(out_file, dpi=200, bbox_inches=\"tight\")\n",
    "    print(f\"Gambar disimpan: {out_file}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return out_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1524aa",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6ba7b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_price_column(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    s = df[col].astype(str).str.strip()\n",
    "    s = s.str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# Load Inflasi Bulanan \n",
    "def load_monthly_inflation(path: str) -> pd.DataFrame:\n",
    "    df_raw = pd.read_csv(path, sep=';', engine='python')\n",
    "    df_raw = clean_columns(df_raw)\n",
    "\n",
    "    # baris pertama (index 0) berisi label tahun untuk kolom-kolom lain\n",
    "    year_labels = df_raw.iloc[0, 1:]\n",
    "\n",
    "    month_map = {\n",
    "        \"Januari\": 1, \"Februari\": 2, \"Maret\": 3, \"April\": 4, \"Mei\": 5,\n",
    "        \"Juni\": 6, \"Juli\": 7, \"Agustus\": 8, \"September\": 9, \"Oktober\": 10,\n",
    "        \"November\": 11, \"Desember\": 12\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    # data bulan mulai di baris index 3 (sesuai file inflasi)\n",
    "    for i in range(3, len(df_raw)):\n",
    "        month_name = df_raw.iloc[i, 0]\n",
    "        if not isinstance(month_name, str):\n",
    "            continue\n",
    "        month_name = month_name.strip()\n",
    "        if month_name == \"\" or \"sumber\" in month_name.lower():\n",
    "            continue\n",
    "\n",
    "        m = month_map.get(month_name)\n",
    "        if m is None:\n",
    "            continue\n",
    "\n",
    "        for col in df_raw.columns[1:]:\n",
    "            year_val = year_labels[col]\n",
    "            try:\n",
    "                y = int(str(year_val))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            val = df_raw.at[i, col]\n",
    "            if isinstance(val, str):\n",
    "                val = val.replace(\",\", \".\")\n",
    "            try:\n",
    "                infl_val = float(val)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"LeaseYearStart\": y,\n",
    "                \"LeaseMonthStart\": m,\n",
    "                \"Inflation\": infl_val\n",
    "            })\n",
    "\n",
    "    infl_long = pd.DataFrame(rows)\n",
    "\n",
    "    infl_long = (\n",
    "        infl_long\n",
    "        .groupby([\"LeaseYearStart\", \"LeaseMonthStart\"], as_index=False)[\"Inflation\"]\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    return infl_long\n",
    "\n",
    "\n",
    "# Load Pertumbuhan PDRB \n",
    "def load_pdrb_growth(path: str) -> pd.DataFrame:\n",
    "    import pandas as pd\n",
    "\n",
    "    # Paksa pakai delimiter ';'\n",
    "    df_raw = pd.read_csv(\n",
    "        path,\n",
    "        sep=';',            \n",
    "        header=None,\n",
    "        encoding='utf-8-sig'  \n",
    "    )\n",
    "\n",
    "\n",
    "    # --- kolom 0: tahun ---\n",
    "    col_year_raw = df_raw.iloc[:, 0].astype(str).str.strip()\n",
    "    col_year = pd.to_numeric(col_year_raw, errors=\"coerce\")\n",
    "\n",
    "    # --- kolom 1: pertumbuhan ---\n",
    "    col_growth_raw = df_raw.iloc[:, 1].astype(str).str.strip()\n",
    "    col_growth_clean = (\n",
    "        col_growth_raw\n",
    "        .str.replace(\"%\", \"\", regex=False)\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "    )\n",
    "    col_growth = pd.to_numeric(col_growth_clean, errors=\"coerce\")\n",
    "\n",
    "    mask = ~col_year.isna() & ~col_growth.isna()\n",
    "\n",
    "    pdrb = pd.DataFrame({\n",
    "        \"LeaseYearStart\": col_year[mask].astype(\"Int64\"),\n",
    "        \"GDP_Growth\": col_growth[mask]\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    return pdrb\n",
    "\n",
    "\n",
    "# Fungsi utama per sheet\n",
    "\n",
    "def run_for_sheet(\n",
    "    xls: pd.ExcelFile,\n",
    "    sheet_cluster: str,\n",
    "    price_sheet: str,\n",
    "    price_col_name: str,\n",
    "    output_file: str,\n",
    "    infl_long: pd.DataFrame,\n",
    "    pdrb_growth: pd.DataFrame,\n",
    "):\n",
    "    print(f\"\\n================= Proses {sheet_cluster} / {price_sheet} =================\")\n",
    "\n",
    "    if sheet_cluster not in xls.sheet_names:\n",
    "        raise KeyError(\n",
    "            f\"Sheet cluster '{sheet_cluster}' tidak ditemukan di {FILE_CLUSTERED}.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        df_main = clean_columns(pd.read_excel(xls, sheet_name=sheet_cluster))\n",
    "    except ValueError:\n",
    "        df_main = clean_columns(pd.read_excel(xls, sheet_name=0))\n",
    "\n",
    "    if CLUSTER_COL not in df_main.columns:\n",
    "        raise KeyError(\n",
    "            f\"Kolom cluster '{CLUSTER_COL}' tidak ditemukan di sheet '{sheet_cluster}'. \"\n",
    "            \"Pastikan hasil clustering sudah disimpan sebagai kolom tersebut.\"\n",
    "        )\n",
    "\n",
    "    # ---- merge Inflasi dan PDRB ----\n",
    "    if {\"LeaseYearStart\", \"LeaseMonthStart\"}.issubset(df_main.columns):\n",
    "        df_main = df_main.merge(\n",
    "            infl_long,\n",
    "            on=[\"LeaseYearStart\", \"LeaseMonthStart\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "    if \"LeaseYearStart\" in df_main.columns and \"LeaseYearStart\" in pdrb_growth.columns:\n",
    "        df_main = df_main.merge(\n",
    "            pdrb_growth,\n",
    "            on=\"LeaseYearStart\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"PERINGATAN: 'LeaseYearStart' tidak ada di pdrb_growth – GDP_Growth tidak dipakai.\")\n",
    "\n",
    "    # ---- load price ----\n",
    "    if price_sheet not in xls.sheet_names:\n",
    "        raise KeyError(f\"Sheet '{price_sheet}' tidak ditemukan di {FILE_CLUSTERED}.\")\n",
    "\n",
    "    df_price = clean_columns(pd.read_excel(xls, sheet_name=price_sheet))\n",
    "\n",
    "    price_col = price_col_name\n",
    "    if price_col not in df_price.columns:\n",
    "        cands = [c for c in df_price.columns if \"price\" in c.lower()]\n",
    "        if not cands:\n",
    "            raise KeyError(\n",
    "                f\"Kolom target '{price_col}' tidak ditemukan dan tidak ada kolom mirip 'price' di sheet '{price_sheet}'.\"\n",
    "            )\n",
    "        price_col = cands[0]\n",
    "\n",
    "    if \"RowID\" in df_price.columns:\n",
    "        df_price[\"RowID\"] = pd.to_numeric(df_price[\"RowID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        s_price = df_price.set_index(\"RowID\")[price_col]\n",
    "        y_all = pd.Series(df_main.index, index=df_main.index).map(s_price).astype(float)\n",
    "    else:\n",
    "        if len(df_price) != len(df_main):\n",
    "            raise ValueError(\n",
    "                f\"Panjang sheet utama ({len(df_main)}) berbeda dengan sheet '{price_sheet}' ({len(df_price)}). \"\n",
    "                \"Tambahkan kolom RowID di price sheet agar bisa dipetakan.\"\n",
    "            )\n",
    "        y_all = (\n",
    "            pd.to_numeric(df_price[price_col], errors=\"coerce\")\n",
    "            .astype(float)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "    # ---- urutkan berdasarkan tanggal ----\n",
    "    need_cols = {\"LeaseYearStart\", \"LeaseMonthStart\", \"LeaseDayStart\"}\n",
    "    if not need_cols.issubset(df_main.columns):\n",
    "        raise KeyError(\n",
    "            \"Untuk walk-forward CV dibutuhkan kolom LeaseYearStart, LeaseMonthStart, LeaseDayStart.\"\n",
    "        )\n",
    "\n",
    "    lease_start_date = pd.to_datetime(\n",
    "        dict(\n",
    "            year=df_main[\"LeaseYearStart\"],\n",
    "            month=df_main[\"LeaseMonthStart\"],\n",
    "            day=df_main[\"LeaseDayStart\"],\n",
    "        ),\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "\n",
    "    valid_date_mask = ~lease_start_date.isna()\n",
    "    df_main = df_main.loc[valid_date_mask].reset_index(drop=True)\n",
    "    y_all = y_all.loc[valid_date_mask].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.loc[valid_date_mask].reset_index(drop=True)\n",
    "\n",
    "    order = np.argsort(lease_start_date.values)\n",
    "    df_main = df_main.iloc[order].reset_index(drop=True)\n",
    "    y_all = y_all.iloc[order].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.iloc[order].reset_index(drop=True)\n",
    "\n",
    "    # ---- fitur ----\n",
    "    all_cat_cols = CATEGORICAL_COLS + [CLUSTER_COL]\n",
    "\n",
    "    cat_all = [c for c in all_cat_cols if c in df_main.columns]\n",
    "    num_all = [c for c in NUMERIC_COLS if c in df_main.columns]\n",
    "\n",
    "    for extra in [\"Inflation\", \"GDP_Growth\"]:\n",
    "        if extra in df_main.columns and extra not in num_all:\n",
    "            num_all.append(extra)\n",
    "\n",
    "    feature_cols = cat_all + num_all\n",
    "\n",
    "    X_all = df_main[feature_cols].copy()\n",
    "\n",
    "    for c in cat_all:\n",
    "        X_all[c] = X_all[c].astype(str)\n",
    "    for c in num_all:\n",
    "        X_all[c] = pd.to_numeric(X_all[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    keep_mask = ~y_all.isna()\n",
    "    X = X_all.loc[keep_mask].reset_index(drop=True)\n",
    "    y = y_all.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    cat_feature_idx = [X.columns.get_loc(c) for c in cat_all]\n",
    "\n",
    "        \n",
    "    # HYPERPARAMETER TUNING DENGAN OPTUNA\n",
    "    \n",
    "    print(\"\\n-- Hyperparameter tuning dengan Optuna --\")\n",
    "\n",
    "    X_tune = X\n",
    "    y_tune = y\n",
    "   \n",
    "    tscv_tune = TimeSeriesSplit(n_splits=3)\n",
    "    splits_tune = list(tscv_tune.split(X_tune))\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        depth = trial.suggest_int(\"depth\", 4, 10)\n",
    "        lr = trial.suggest_float(\"learning_rate\", 0.01, 0.15, log=True)\n",
    "        l2 = trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0)\n",
    "        iterations = trial.suggest_int(\"iterations\", 500, 1500)\n",
    "\n",
    "        rmses = []\n",
    "        for tr_idx, va_idx in splits_tune:\n",
    "            X_tr, X_va = X_tune.iloc[tr_idx], X_tune.iloc[va_idx]\n",
    "            y_tr, y_va = y_tune.iloc[tr_idx], y_tune.iloc[va_idx]\n",
    "\n",
    "            train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "            valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "            model = CatBoostRegressor(\n",
    "                loss_function=\"RMSE\",\n",
    "                depth=int(depth),\n",
    "                learning_rate=float(lr),\n",
    "                l2_leaf_reg=float(l2),\n",
    "                iterations=int(iterations),\n",
    "                random_seed=42,\n",
    "                od_type=\"Iter\",\n",
    "                od_wait=50,\n",
    "                verbose=False,\n",
    "            )\n",
    "            model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "            pred_va = model.predict(valid_pool)\n",
    "            rmse = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        mean_rmse = float(np.mean(rmses))\n",
    "\n",
    "        # CETAK PARAMETER + RMSE SETIAP TRIAL\n",
    "        print(\n",
    "            f\"Optuna trial {trial.number}: \"\n",
    "            f\"depth={depth}, lr={lr:.4f}, l2={l2:.2f}, iter={iterations} \"\n",
    "            f\"→ mean RMSE={mean_rmse:.4f}\"\n",
    "        )\n",
    "\n",
    "        return mean_rmse\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=30,            \n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params.setdefault(\"iterations\", 1000)\n",
    "\n",
    "    print(\n",
    "        f\"Best params (Optuna) untuk {sheet_cluster}: \"\n",
    "        f\"{best_params} | Best CV RMSE={study.best_value:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5b5329bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data PDRB Growth:\n",
      "   LeaseYearStart  GDP_Growth\n",
      "0            2015        5.97\n",
      "1            2016        6.00\n",
      "2            2017        6.13\n",
      "3            2018        6.19\n",
      "4            2019        6.09\n",
      "5            2020       -4.25\n",
      "6            2021        4.29\n",
      "7            2022        6.51\n",
      "8            2023        5.70\n",
      "9            2024        5.76\n",
      "\n",
      "================= Proses Monthly_Fixed_clustered / Monthly_Fixed_CuryUnitPrice =================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:11:04,677] A new study created in memory with name: no-name-6db78e3a-be16-4d40-bf30-2ba2b187efc6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Hyperparameter tuning dengan Optuna --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:18:01,038] Trial 0 finished with value: 102462.4455808956 and parameters: {'depth': 7, 'learning_rate': 0.01096322722032367, 'l2_leaf_reg': 5.63175402716522, 'iterations': 1136}. Best is trial 0 with value: 102462.4455808956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 0: depth=7, lr=0.0110, l2=5.63, iter=1136 → mean RMSE=102462.4456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:19:37,162] Trial 1 finished with value: 97524.02799246868 and parameters: {'depth': 5, 'learning_rate': 0.11090865932159462, 'l2_leaf_reg': 6.147903201542478, 'iterations': 1317}. Best is trial 1 with value: 97524.02799246868.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 1: depth=5, lr=0.1109, l2=6.15, iter=1317 → mean RMSE=97524.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:21:14,889] Trial 2 finished with value: 99026.96092661562 and parameters: {'depth': 5, 'learning_rate': 0.08657152652063035, 'l2_leaf_reg': 3.645227666122696, 'iterations': 960}. Best is trial 1 with value: 97524.02799246868.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 2: depth=5, lr=0.0866, l2=3.65, iter=960 → mean RMSE=99026.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:23:20,817] Trial 3 finished with value: 95348.99535160558 and parameters: {'depth': 7, 'learning_rate': 0.11402910749778719, 'l2_leaf_reg': 7.698883115169276, 'iterations': 557}. Best is trial 3 with value: 95348.99535160558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 3: depth=7, lr=0.1140, l2=7.70, iter=557 → mean RMSE=95348.9954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:28:48,869] Trial 4 finished with value: 109269.02650510799 and parameters: {'depth': 9, 'learning_rate': 0.010138291279747606, 'l2_leaf_reg': 7.570239864734668, 'iterations': 771}. Best is trial 3 with value: 95348.99535160558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 4: depth=9, lr=0.0101, l2=7.57, iter=771 → mean RMSE=109269.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:36:24,872] Trial 5 finished with value: 104149.35496211082 and parameters: {'depth': 10, 'learning_rate': 0.0637957012292081, 'l2_leaf_reg': 5.917827232314831, 'iterations': 986}. Best is trial 3 with value: 95348.99535160558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 5: depth=10, lr=0.0638, l2=5.92, iter=986 → mean RMSE=104149.3550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:42:15,451] Trial 6 finished with value: 98932.34073195315 and parameters: {'depth': 7, 'learning_rate': 0.028526223251654933, 'l2_leaf_reg': 5.8896453715957815, 'iterations': 1230}. Best is trial 3 with value: 95348.99535160558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 6: depth=7, lr=0.0285, l2=5.89, iter=1230 → mean RMSE=98932.3407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:44:02,254] Trial 7 finished with value: 92359.28540031247 and parameters: {'depth': 5, 'learning_rate': 0.052471558648346704, 'l2_leaf_reg': 5.119412186345439, 'iterations': 1368}. Best is trial 7 with value: 92359.28540031247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 7: depth=5, lr=0.0525, l2=5.12, iter=1368 → mean RMSE=92359.2854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:46:50,460] Trial 8 finished with value: 88356.03313050955 and parameters: {'depth': 4, 'learning_rate': 0.03054886415434049, 'l2_leaf_reg': 4.884660432197855, 'iterations': 1213}. Best is trial 8 with value: 88356.03313050955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 8: depth=4, lr=0.0305, l2=4.88, iter=1213 → mean RMSE=88356.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:50:22,622] Trial 9 finished with value: 88657.00292751552 and parameters: {'depth': 5, 'learning_rate': 0.045088370479409536, 'l2_leaf_reg': 9.228672831949686, 'iterations': 1373}. Best is trial 8 with value: 88356.03313050955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 9: depth=5, lr=0.0451, l2=9.23, iter=1373 → mean RMSE=88657.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:52:33,066] Trial 10 finished with value: 93280.62144372759 and parameters: {'depth': 4, 'learning_rate': 0.021382699640955436, 'l2_leaf_reg': 1.4251854179034025, 'iterations': 800}. Best is trial 8 with value: 88356.03313050955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 10: depth=4, lr=0.0214, l2=1.43, iter=800 → mean RMSE=93280.6214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:55:11,633] Trial 11 finished with value: 86329.80565736693 and parameters: {'depth': 4, 'learning_rate': 0.03374762277567507, 'l2_leaf_reg': 9.91095678843365, 'iterations': 1471}. Best is trial 11 with value: 86329.80565736693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 11: depth=4, lr=0.0337, l2=9.91, iter=1471 → mean RMSE=86329.8057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 13:58:26,650] Trial 12 finished with value: 86310.06843625235 and parameters: {'depth': 4, 'learning_rate': 0.02338587391004517, 'l2_leaf_reg': 9.970610585903879, 'iterations': 1446}. Best is trial 12 with value: 86310.06843625235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 12: depth=4, lr=0.0234, l2=9.97, iter=1446 → mean RMSE=86310.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:04:48,680] Trial 13 finished with value: 90996.98268319418 and parameters: {'depth': 6, 'learning_rate': 0.01776809917924522, 'l2_leaf_reg': 9.538578037073304, 'iterations': 1495}. Best is trial 12 with value: 86310.06843625235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 13: depth=6, lr=0.0178, l2=9.54, iter=1495 → mean RMSE=90996.9827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:08:46,840] Trial 14 finished with value: 84641.19658311208 and parameters: {'depth': 4, 'learning_rate': 0.017061632916473186, 'l2_leaf_reg': 9.951160526990996, 'iterations': 1491}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 14: depth=4, lr=0.0171, l2=9.95, iter=1491 → mean RMSE=84641.1966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:13:45,241] Trial 15 finished with value: 92479.80549401918 and parameters: {'depth': 6, 'learning_rate': 0.015594040817676715, 'l2_leaf_reg': 8.344003133409789, 'iterations': 1107}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 15: depth=6, lr=0.0156, l2=8.34, iter=1107 → mean RMSE=92479.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:27:20,906] Trial 16 finished with value: 96972.50000979508 and parameters: {'depth': 9, 'learning_rate': 0.02246417599843458, 'l2_leaf_reg': 8.457732862132897, 'iterations': 1474}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 16: depth=9, lr=0.0225, l2=8.46, iter=1474 → mean RMSE=96972.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:33:30,073] Trial 17 finished with value: 94161.91710394219 and parameters: {'depth': 6, 'learning_rate': 0.014360171306249827, 'l2_leaf_reg': 7.084463788024738, 'iterations': 1294}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 17: depth=6, lr=0.0144, l2=7.08, iter=1294 → mean RMSE=94161.9171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:36:01,078] Trial 18 finished with value: 90667.12885069288 and parameters: {'depth': 4, 'learning_rate': 0.023558520485023132, 'l2_leaf_reg': 3.33866407651162, 'iterations': 850}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 18: depth=4, lr=0.0236, l2=3.34, iter=850 → mean RMSE=90667.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:39:09,596] Trial 19 finished with value: 105727.37679278587 and parameters: {'depth': 8, 'learning_rate': 0.013383551060162311, 'l2_leaf_reg': 8.754474942291907, 'iterations': 595}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 19: depth=8, lr=0.0134, l2=8.75, iter=595 → mean RMSE=105727.3768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:43:36,035] Trial 20 finished with value: 88591.52418000558 and parameters: {'depth': 6, 'learning_rate': 0.04038215835055412, 'l2_leaf_reg': 9.881044940828053, 'iterations': 1074}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 20: depth=6, lr=0.0404, l2=9.88, iter=1074 → mean RMSE=88591.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:46:40,268] Trial 21 finished with value: 85494.01735150542 and parameters: {'depth': 4, 'learning_rate': 0.03183295784297967, 'l2_leaf_reg': 9.806487326264715, 'iterations': 1433}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 21: depth=4, lr=0.0318, l2=9.81, iter=1433 → mean RMSE=85494.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:50:39,978] Trial 22 finished with value: 86147.20412373326 and parameters: {'depth': 4, 'learning_rate': 0.019295989828784617, 'l2_leaf_reg': 9.02408019113351, 'iterations': 1405}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 22: depth=4, lr=0.0193, l2=9.02, iter=1405 → mean RMSE=86147.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:55:55,183] Trial 23 finished with value: 87451.26809730136 and parameters: {'depth': 5, 'learning_rate': 0.01775455608114032, 'l2_leaf_reg': 8.84536141510474, 'iterations': 1391}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 23: depth=5, lr=0.0178, l2=8.85, iter=1391 → mean RMSE=87451.2681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 14:59:13,313] Trial 24 finished with value: 85857.00145132992 and parameters: {'depth': 4, 'learning_rate': 0.02801084926431573, 'l2_leaf_reg': 6.988343679535298, 'iterations': 1207}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 24: depth=4, lr=0.0280, l2=6.99, iter=1207 → mean RMSE=85857.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:03:15,897] Trial 25 finished with value: 92102.15214974363 and parameters: {'depth': 5, 'learning_rate': 0.027211511323634915, 'l2_leaf_reg': 6.590386023041105, 'iterations': 1241}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 25: depth=5, lr=0.0272, l2=6.59, iter=1241 → mean RMSE=92102.1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:06:34,956] Trial 26 finished with value: 84957.24725220562 and parameters: {'depth': 4, 'learning_rate': 0.0363643112229607, 'l2_leaf_reg': 7.917725664066974, 'iterations': 1327}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 26: depth=4, lr=0.0364, l2=7.92, iter=1327 → mean RMSE=84957.2473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:09:42,710] Trial 27 finished with value: 86192.93190922165 and parameters: {'depth': 5, 'learning_rate': 0.06008735639425399, 'l2_leaf_reg': 8.021934303918968, 'iterations': 1340}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 27: depth=5, lr=0.0601, l2=8.02, iter=1340 → mean RMSE=86192.9319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:12:31,463] Trial 28 finished with value: 86703.38564912321 and parameters: {'depth': 4, 'learning_rate': 0.04590547802615867, 'l2_leaf_reg': 9.26063752769853, 'iterations': 1267}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 28: depth=4, lr=0.0459, l2=9.26, iter=1267 → mean RMSE=86703.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:16:23,491] Trial 29 finished with value: 91653.6247572493 and parameters: {'depth': 6, 'learning_rate': 0.03614038979013491, 'l2_leaf_reg': 7.966904730397174, 'iterations': 1149}. Best is trial 14 with value: 84641.19658311208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 29: depth=6, lr=0.0361, l2=7.97, iter=1149 → mean RMSE=91653.6248\n",
      "Best params (Optuna) untuk Monthly_Fixed_clustered: {'depth': 4, 'learning_rate': 0.017061632916473186, 'l2_leaf_reg': 9.951160526990996, 'iterations': 1491} | Best CV RMSE=84641.1966\n",
      "\n",
      "================= Proses Daily_Fixed_clustered / Daily_Fixed_CuryUnitPrice =================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:16:25,042] A new study created in memory with name: no-name-08a0b768-6295-4fff-a169-f02251e3ad5f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Hyperparameter tuning dengan Optuna --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:20:08,548] Trial 0 finished with value: 6113.168853809509 and parameters: {'depth': 8, 'learning_rate': 0.03434583959170398, 'l2_leaf_reg': 7.1709316188412, 'iterations': 1338}. Best is trial 0 with value: 6113.168853809509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 0: depth=8, lr=0.0343, l2=7.17, iter=1338 → mean RMSE=6113.1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:24:26,374] Trial 1 finished with value: 5663.367241828714 and parameters: {'depth': 7, 'learning_rate': 0.017161819201357422, 'l2_leaf_reg': 3.650523809718015, 'iterations': 779}. Best is trial 1 with value: 5663.367241828714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 1: depth=7, lr=0.0172, l2=3.65, iter=779 → mean RMSE=5663.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:25:22,557] Trial 2 finished with value: 5939.035801605569 and parameters: {'depth': 7, 'learning_rate': 0.10263166487754748, 'l2_leaf_reg': 3.870209377169701, 'iterations': 1361}. Best is trial 1 with value: 5663.367241828714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 2: depth=7, lr=0.1026, l2=3.87, iter=1361 → mean RMSE=5939.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:31:29,745] Trial 3 finished with value: 5458.159782349357 and parameters: {'depth': 7, 'learning_rate': 0.013108067495388634, 'l2_leaf_reg': 8.540844725008482, 'iterations': 1386}. Best is trial 3 with value: 5458.159782349357.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 3: depth=7, lr=0.0131, l2=8.54, iter=1386 → mean RMSE=5458.1598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:32:59,990] Trial 4 finished with value: 5223.614531249575 and parameters: {'depth': 4, 'learning_rate': 0.04678255727374182, 'l2_leaf_reg': 2.4456737389765006, 'iterations': 1044}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 4: depth=4, lr=0.0468, l2=2.45, iter=1044 → mean RMSE=5223.6145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:36:20,494] Trial 5 finished with value: 5941.7589231473585 and parameters: {'depth': 8, 'learning_rate': 0.03568016467104605, 'l2_leaf_reg': 9.873057742118618, 'iterations': 576}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 5: depth=8, lr=0.0357, l2=9.87, iter=576 → mean RMSE=5941.7589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:37:34,804] Trial 6 finished with value: 6331.675014090947 and parameters: {'depth': 10, 'learning_rate': 0.09940258079574438, 'l2_leaf_reg': 1.596697789165464, 'iterations': 1275}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 6: depth=10, lr=0.0994, l2=1.60, iter=1275 → mean RMSE=6331.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:40:05,230] Trial 7 finished with value: 5993.5629538873545 and parameters: {'depth': 9, 'learning_rate': 0.04848049687281344, 'l2_leaf_reg': 5.748216602250538, 'iterations': 1257}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 7: depth=9, lr=0.0485, l2=5.75, iter=1257 → mean RMSE=5993.5630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:43:07,299] Trial 8 finished with value: 6094.273629165732 and parameters: {'depth': 9, 'learning_rate': 0.0837069582750667, 'l2_leaf_reg': 9.902528095660267, 'iterations': 1104}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 8: depth=9, lr=0.0837, l2=9.90, iter=1104 → mean RMSE=6094.2736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:45:17,993] Trial 9 finished with value: 5893.504028238121 and parameters: {'depth': 8, 'learning_rate': 0.07367533559624322, 'l2_leaf_reg': 9.807465253035131, 'iterations': 687}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 9: depth=8, lr=0.0737, l2=9.81, iter=687 → mean RMSE=5893.5040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:47:08,325] Trial 10 finished with value: 5290.436558671656 and parameters: {'depth': 4, 'learning_rate': 0.022050283801056853, 'l2_leaf_reg': 1.0465325105628978, 'iterations': 920}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 10: depth=4, lr=0.0221, l2=1.05, iter=920 → mean RMSE=5290.4366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:48:26,062] Trial 11 finished with value: 5366.243842007984 and parameters: {'depth': 4, 'learning_rate': 0.021436862825061288, 'l2_leaf_reg': 1.2748814774801818, 'iterations': 945}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 11: depth=4, lr=0.0214, l2=1.27, iter=945 → mean RMSE=5366.2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:49:55,568] Trial 12 finished with value: 5297.136179847245 and parameters: {'depth': 4, 'learning_rate': 0.026413357618777365, 'l2_leaf_reg': 2.730220508867245, 'iterations': 932}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 12: depth=4, lr=0.0264, l2=2.73, iter=932 → mean RMSE=5297.1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:53:17,639] Trial 13 finished with value: 5296.587890124071 and parameters: {'depth': 5, 'learning_rate': 0.010043953243441582, 'l2_leaf_reg': 2.7544700005410596, 'iterations': 1106}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 13: depth=5, lr=0.0100, l2=2.75, iter=1106 → mean RMSE=5296.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:54:21,542] Trial 14 finished with value: 5401.041805614081 and parameters: {'depth': 5, 'learning_rate': 0.05452929025395204, 'l2_leaf_reg': 5.040722692145758, 'iterations': 1083}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 14: depth=5, lr=0.0545, l2=5.04, iter=1083 → mean RMSE=5401.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:56:47,326] Trial 15 finished with value: 5396.171739513832 and parameters: {'depth': 5, 'learning_rate': 0.02579407093629689, 'l2_leaf_reg': 2.338973846120432, 'iterations': 850}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 15: depth=5, lr=0.0258, l2=2.34, iter=850 → mean RMSE=5396.1717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:58:21,354] Trial 16 finished with value: 5384.554880516388 and parameters: {'depth': 6, 'learning_rate': 0.058594882798937736, 'l2_leaf_reg': 4.127620369427938, 'iterations': 512}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 16: depth=6, lr=0.0586, l2=4.13, iter=512 → mean RMSE=5384.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 15:59:02,757] Trial 17 finished with value: 5648.683921886147 and parameters: {'depth': 4, 'learning_rate': 0.1366405178064921, 'l2_leaf_reg': 1.035390032773657, 'iterations': 1490}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 17: depth=4, lr=0.1366, l2=1.04, iter=1490 → mean RMSE=5648.6839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:00:55,233] Trial 18 finished with value: 5591.944334112533 and parameters: {'depth': 6, 'learning_rate': 0.04132828399682599, 'l2_leaf_reg': 6.130565926838806, 'iterations': 1018}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 18: depth=6, lr=0.0413, l2=6.13, iter=1018 → mean RMSE=5591.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:03:14,968] Trial 19 finished with value: 5416.064519751918 and parameters: {'depth': 5, 'learning_rate': 0.01709018867618998, 'l2_leaf_reg': 2.183103300494226, 'iterations': 761}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 19: depth=5, lr=0.0171, l2=2.18, iter=761 → mean RMSE=5416.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:05:11,676] Trial 20 finished with value: 5573.800393618748 and parameters: {'depth': 6, 'learning_rate': 0.03297018169484282, 'l2_leaf_reg': 3.3566505389909445, 'iterations': 1178}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 20: depth=6, lr=0.0330, l2=3.36, iter=1178 → mean RMSE=5573.8004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:08:00,755] Trial 21 finished with value: 5252.122409202674 and parameters: {'depth': 4, 'learning_rate': 0.010871381197732765, 'l2_leaf_reg': 2.631603754537317, 'iterations': 1145}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 21: depth=4, lr=0.0109, l2=2.63, iter=1145 → mean RMSE=5252.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:10:25,712] Trial 22 finished with value: 5307.173386078314 and parameters: {'depth': 4, 'learning_rate': 0.01039135577184727, 'l2_leaf_reg': 2.003452210963152, 'iterations': 1015}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 22: depth=4, lr=0.0104, l2=2.00, iter=1015 → mean RMSE=5307.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:12:29,654] Trial 23 finished with value: 5308.175290707924 and parameters: {'depth': 4, 'learning_rate': 0.015178171765638243, 'l2_leaf_reg': 4.474025681058926, 'iterations': 897}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 23: depth=4, lr=0.0152, l2=4.47, iter=897 → mean RMSE=5308.1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:15:10,897] Trial 24 finished with value: 5247.984806990608 and parameters: {'depth': 5, 'learning_rate': 0.022497438304971133, 'l2_leaf_reg': 3.0130166634661495, 'iterations': 1189}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 24: depth=5, lr=0.0225, l2=3.01, iter=1189 → mean RMSE=5247.9848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:17:53,087] Trial 25 finished with value: 5374.3858583476185 and parameters: {'depth': 5, 'learning_rate': 0.013943166156077639, 'l2_leaf_reg': 3.1939700607115613, 'iterations': 1200}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 25: depth=5, lr=0.0139, l2=3.19, iter=1200 → mean RMSE=5374.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:19:40,710] Trial 26 finished with value: 5330.154051946581 and parameters: {'depth': 6, 'learning_rate': 0.04400164495205723, 'l2_leaf_reg': 4.7567020125921555, 'iterations': 1180}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 26: depth=6, lr=0.0440, l2=4.76, iter=1180 → mean RMSE=5330.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:21:55,459] Trial 27 finished with value: 5312.163548640098 and parameters: {'depth': 5, 'learning_rate': 0.027992290446347472, 'l2_leaf_reg': 6.718266230880018, 'iterations': 1066}. Best is trial 4 with value: 5223.614531249575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 27: depth=5, lr=0.0280, l2=6.72, iter=1066 → mean RMSE=5312.1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:23:56,445] Trial 28 finished with value: 5223.435406593727 and parameters: {'depth': 4, 'learning_rate': 0.02003066367920022, 'l2_leaf_reg': 2.9125448236612685, 'iterations': 1230}. Best is trial 28 with value: 5223.435406593727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 28: depth=4, lr=0.0200, l2=2.91, iter=1230 → mean RMSE=5223.4354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 16:25:55,496] Trial 29 finished with value: 5690.073650712849 and parameters: {'depth': 5, 'learning_rate': 0.03190262082487524, 'l2_leaf_reg': 7.778649978852744, 'iterations': 1248}. Best is trial 28 with value: 5223.435406593727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna trial 29: depth=5, lr=0.0319, l2=7.78, iter=1248 → mean RMSE=5690.0737\n",
      "Best params (Optuna) untuk Daily_Fixed_clustered: {'depth': 4, 'learning_rate': 0.02003066367920022, 'l2_leaf_reg': 2.9125448236612685, 'iterations': 1230} | Best CV RMSE=5223.4354\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load data inflasi & PDRB\n",
    "    infl_long = load_monthly_inflation(INFLATION_FILE)\n",
    "    pdrb_growth = load_pdrb_growth(PDRB_FILE)\n",
    "\n",
    "    print(\"Data PDRB Growth:\")\n",
    "    print(pdrb_growth)\n",
    "\n",
    "    # Load Excel utama\n",
    "    xls = pd.ExcelFile(FILE_CLUSTERED)\n",
    "\n",
    "    # Loop untuk masing-masing konfigurasi sheet (Monthly & Daily)\n",
    "    for cfg in SHEET_CONFIGS:\n",
    "        run_for_sheet(\n",
    "            xls=xls,\n",
    "            sheet_cluster=cfg[\"SHEET_CLUSTER\"],\n",
    "            price_sheet=cfg[\"PRICE_SHEET\"],\n",
    "            price_col_name=cfg[\"PRICE_COL\"],\n",
    "            output_file=cfg[\"OUTPUT_FILE\"],\n",
    "            infl_long=infl_long,\n",
    "            pdrb_growth=pdrb_growth,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5762aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_for_sheet(\n",
    "    xls: pd.ExcelFile,\n",
    "    sheet_cluster: str,\n",
    "    price_sheet: str,\n",
    "    price_col_name: str,\n",
    "    output_file: str,\n",
    "):\n",
    "    print(f\"\\n================= Proses {sheet_cluster} / {price_sheet} =================\")\n",
    "\n",
    "\n",
    "    if sheet_cluster not in xls.sheet_names:\n",
    "        raise KeyError(\n",
    "            f\"Sheet cluster '{sheet_cluster}' tidak ditemukan di {FILE_CLUSTERED}.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        df_main = clean_columns(pd.read_excel(xls, sheet_name=sheet_cluster))\n",
    "    except ValueError:\n",
    "        df_main = clean_columns(pd.read_excel(xls, sheet_name=0))\n",
    "\n",
    "    # pastikan kolom cluster ada\n",
    "    if CLUSTER_COL not in df_main.columns:\n",
    "        raise KeyError(\n",
    "            f\"Kolom cluster '{CLUSTER_COL}' tidak ditemukan di sheet '{sheet_cluster}'. \"\n",
    "            \"Pastikan hasil clustering sudah disimpan sebagai kolom tersebut.\"\n",
    "        )\n",
    "\n",
    "    if price_sheet not in xls.sheet_names:\n",
    "        raise KeyError(f\"Sheet '{price_sheet}' tidak ditemukan di {FILE_CLUSTERED}.\")\n",
    "\n",
    "    df_price = clean_columns(pd.read_excel(xls, sheet_name=price_sheet))\n",
    "\n",
    "    # gunakan local variable untuk kolom price\n",
    "    price_col = price_col_name\n",
    "\n",
    "    # pastikan kolom harga ada (atau fallback cari yang mengandung 'price')\n",
    "    if price_col not in df_price.columns:\n",
    "        cands = [c for c in df_price.columns if \"price\" in c.lower()]\n",
    "        if not cands:\n",
    "            raise KeyError(\n",
    "                f\"Kolom target '{price_col}' tidak ditemukan dan tidak ada kolom mirip 'price' di sheet '{price_sheet}'.\"\n",
    "            )\n",
    "        price_col = cands[0]\n",
    "\n",
    "    # parsing harga: ganti koma -> titik\n",
    "    df_price[price_col] = parse_price_column(df_price, price_col)\n",
    "\n",
    "    # mapping harga ke baris df_main\n",
    "    if \"RowID\" in df_price.columns:\n",
    "        df_price[\"RowID\"] = pd.to_numeric(df_price[\"RowID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        s_price = df_price.set_index(\"RowID\")[price_col]\n",
    "        y_all = pd.Series(df_main.index, index=df_main.index).map(s_price)\n",
    "    else:\n",
    "        if len(df_price) != len(df_main):\n",
    "            raise ValueError(\n",
    "                f\"Panjang sheet utama ({len(df_main)}) berbeda dengan sheet '{price_sheet}' ({len(df_price)}). \"\n",
    "                \"Tambahkan kolom RowID di price sheet agar bisa dipetakan.\"\n",
    "            )\n",
    "        y_all = df_price[price_col].reset_index(drop=True)\n",
    "\n",
    "   \n",
    "    need_cols = {\"LeaseYearStart\", \"LeaseMonthStart\", \"LeaseDayStart\"}\n",
    "    if not need_cols.issubset(df_main.columns):\n",
    "        raise KeyError(\n",
    "            \"Untuk walk-forward CV dibutuhkan kolom LeaseYearStart, LeaseMonthStart, LeaseDayStart.\"\n",
    "        )\n",
    "\n",
    "    lease_start_date = pd.to_datetime(\n",
    "        dict(\n",
    "            year=df_main[\"LeaseYearStart\"],\n",
    "            month=df_main[\"LeaseMonthStart\"],\n",
    "            day=df_main[\"LeaseDayStart\"],\n",
    "        ),\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "\n",
    "    valid_date_mask = ~lease_start_date.isna()\n",
    "    df_main = df_main.loc[valid_date_mask].reset_index(drop=True)\n",
    "    y_all   = y_all.loc[valid_date_mask].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.loc[valid_date_mask].reset_index(drop=True)\n",
    "\n",
    "    order = np.argsort(lease_start_date.values)\n",
    "    df_main = df_main.iloc[order].reset_index(drop=True)\n",
    "    y_all   = y_all.iloc[order].reset_index(drop=True)\n",
    "    lease_start_date = lease_start_date.iloc[order].reset_index(drop=True)\n",
    "\n",
    " \n",
    "    all_cat_cols = CATEGORICAL_COLS + [CLUSTER_COL]\n",
    "\n",
    "    cat_all = [c for c in all_cat_cols if c in df_main.columns]\n",
    "    num_all = [c for c in NUMERIC_COLS if c in df_main.columns]\n",
    "    feature_cols = cat_all + num_all\n",
    "\n",
    "    X_all = df_main[feature_cols].copy()\n",
    "\n",
    "    for c in cat_all:\n",
    "        X_all[c] = X_all[c].astype(str)\n",
    "    for c in num_all:\n",
    "        X_all[c] = pd.to_numeric(X_all[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    keep_mask = ~y_all.isna()\n",
    "    X = X_all.loc[keep_mask].reset_index(drop=True)\n",
    "    y = y_all.loc[keep_mask].reset_index(drop=True)\n",
    "\n",
    "    if len(X) == 0:\n",
    "        print(\"Semua target NaN setelah parsing harga; cek lagi format CuryUnitPrice.\")\n",
    "        df_out = df_main.copy()\n",
    "        df_out[\"oof_pred\"] = np.nan\n",
    "        if price_col not in df_out.columns:\n",
    "            df_out[price_col] = y_all.values\n",
    "        cols_to_save = [CLUSTER_COL, price_col, \"oof_pred\"]\n",
    "        df_out[cols_to_save].to_excel(output_file, index=False)\n",
    "        return\n",
    "\n",
    "    cat_feature_idx = [X.columns.get_loc(c) for c in cat_all]\n",
    "\n",
    "   \n",
    "    param_grid = {\n",
    "        \"depth\": [6, 8, 10],\n",
    "        \"learning_rate\": [0.03, 0.05, 0.1],\n",
    "        \"l2_leaf_reg\": [1, 3, 5],\n",
    "    }\n",
    "\n",
    "    tscv_tune = TimeSeriesSplit(n_splits=3)\n",
    "    best_rmse = np.inf\n",
    "    best_params = None\n",
    "\n",
    "    print(\"\\n-- Hyperparameter tuning --\")\n",
    "    for depth in param_grid[\"depth\"]:\n",
    "        for lr in param_grid[\"learning_rate\"]:\n",
    "            for l2 in param_grid[\"l2_leaf_reg\"]:\n",
    "                rmses = []\n",
    "                for tr_idx, va_idx in tscv_tune.split(X):\n",
    "                    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "                    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "                    train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "                    valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "                    model = CatBoostRegressor(\n",
    "                        loss_function=\"RMSE\",\n",
    "                        depth=depth,\n",
    "                        learning_rate=lr,\n",
    "                        l2_leaf_reg=l2,\n",
    "                        iterations=2000,\n",
    "                        random_seed=42,\n",
    "                        od_type=\"Iter\",\n",
    "                        od_wait=100,\n",
    "                        verbose=False,\n",
    "                    )\n",
    "                    model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "                    pred_va = model.predict(valid_pool)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "                    rmses.append(rmse)\n",
    "\n",
    "                mean_rmse = np.mean(rmses)\n",
    "                print(\n",
    "                    f\"Tuning: depth={depth}, lr={lr}, l2={l2} -> \"\n",
    "                    f\"CV RMSE={mean_rmse:.2f}\"\n",
    "                )\n",
    "                if mean_rmse < best_rmse:\n",
    "                    best_rmse = mean_rmse\n",
    "                    best_params = {\"depth\": depth, \"learning_rate\": lr, \"l2_leaf_reg\": l2}\n",
    "\n",
    "    print(f\"Best params: {best_params} | Best CV RMSE={best_rmse:.2f}\")\n",
    "\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    mae_scores, rmse_scores, r2_scores, rpmse_scores = [], [], [], []\n",
    "\n",
    "    oof_pred = np.full(len(df_main), np.nan)\n",
    "    idx_map  = np.where(keep_mask)[0]\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(X), 1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_idx)\n",
    "        valid_pool = Pool(X_va, y_va, cat_features=cat_feature_idx)\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function=\"RMSE\",\n",
    "            depth=best_params[\"depth\"],\n",
    "            learning_rate=best_params[\"learning_rate\"],\n",
    "            l2_leaf_reg=best_params[\"l2_leaf_reg\"],\n",
    "            iterations=2000,\n",
    "            random_seed=42,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=100,\n",
    "            verbose=False,\n",
    "        )\n",
    "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "\n",
    "        pred_tr = model.predict(train_pool)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_tr, pred_tr))\n",
    "\n",
    "        pred_va = model.predict(valid_pool)\n",
    "        oof_pred[idx_map[va_idx]] = pred_va\n",
    "\n",
    "        mae   = mean_absolute_error(y_va, pred_va)\n",
    "        rmse  = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "        r2    = r2_score(y_va, pred_va)\n",
    "        rpmse = (rmse / np.mean(y_va)) * 100\n",
    "\n",
    "        print(\n",
    "            f\"[{sheet_cluster}] Fold {fold}: \"\n",
    "            f\"Train RMSE={rmse_train:.2f} | \"\n",
    "            f\"Val RMSE={rmse:.2f} | \"\n",
    "            f\"MAE={mae:.2f} | \"\n",
    "            f\"RPMSE={rpmse:.2f}% | \"\n",
    "            f\"R²={r2:.3f}\"\n",
    "        )\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        rpmse_scores.append(rpmse)\n",
    "\n",
    "    print(f\"\\n=== Hasil Walk-Forward CV (TimeSeriesSplit) untuk {sheet_cluster} ===\")\n",
    "    print(f\"MAE   : {np.mean(mae_scores):.2f} ± {np.std(mae_scores):.2f}\")\n",
    "    print(f\"RMSE  : {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f}\")\n",
    "    print(f\"RPMSE : {np.mean(rpmse_scores):.2f}% ± {np.std(rpmse_scores):.2f}%\")\n",
    "    print(f\"R²    : {np.mean(r2_scores):.3f} ± {np.std(r2_scores):.3f}\")\n",
    "\n",
    "    # Simpan hasil OOF \n",
    "    df_out = df_main.copy()\n",
    "    df_out[\"oof_pred\"] = oof_pred\n",
    "\n",
    "    if price_col not in df_out.columns:\n",
    "        df_out[price_col] = y_all.values\n",
    "\n",
    "    cols_to_save = [CLUSTER_COL, price_col, \"oof_pred\"]\n",
    "    df_out[cols_to_save].to_excel(output_file, index=False)\n",
    "\n",
    "    print(f\"\\nPrediksi OOF tersimpan di: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
