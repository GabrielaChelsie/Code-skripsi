{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a56654",
   "metadata": {},
   "source": [
    "## + metrik evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6707032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca43b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _impute_numeric(\n",
    "    s: pd.Series,\n",
    "    strategy: str = \"median\"\n",
    ") -> pd.Series:\n",
    "    if strategy == \"median\":\n",
    "        return s.fillna(s.median())\n",
    "    elif strategy == \"mean\":\n",
    "        return s.fillna(s.mean())\n",
    "    elif strategy == \"zero\":\n",
    "        return s.fillna(0)\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def _clip_outliers_quantile(\n",
    "    s: pd.Series,\n",
    "    q_low: float = 0.01,\n",
    "    q_high: float = 0.99\n",
    ") -> pd.Series:\n",
    "    lo, hi = s.quantile(q_low), s.quantile(q_high)\n",
    "    if pd.isna(lo) or pd.isna(hi):\n",
    "        return s\n",
    "    return s.clip(lo, hi)\n",
    "\n",
    "def _consolidate_rare_categories(\n",
    "    s: pd.Series,\n",
    "    min_ratio: float = 0.01,\n",
    "    other_label: str = \"OTHER\"\n",
    ") -> pd.Series:\n",
    "    counts = s.value_counts(dropna=False)\n",
    "    total = counts.sum()\n",
    "    rare = set(counts[counts / max(total, 1) <= min_ratio].index)\n",
    "    return s.apply(lambda v: other_label if v in rare else v)\n",
    "\n",
    "def _scale_numeric(\n",
    "    df_num: pd.DataFrame,\n",
    "    method: str = \"minmax\"\n",
    "):\n",
    "    if df_num.empty:\n",
    "        return df_num, None\n",
    "    if method == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "    scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(df_num.values),\n",
    "        columns=df_num.columns,\n",
    "        index=df_num.index\n",
    "    )\n",
    "    return scaled, scaler\n",
    "\n",
    "def preprocess_for_kmedoids_gower(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: List[str],\n",
    "    numeric_cols: List[str],\n",
    "    *,\n",
    "    fill_num: str = \"median\",            \n",
    "    fill_cat_label: str = \"MISSING\",     \n",
    "    rare_thresh: float = 0.01,           \n",
    "    other_label: str = \"OTHER\",\n",
    "    clip_outliers: bool = True,\n",
    "    q_low: float = 0.01,\n",
    "    q_high: float = 0.99,\n",
    "    scale_method: str = \"minmax\",        \n",
    "    force_upper: bool = False,           \n",
    "    strip_space: bool = True\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    dfp = df.copy()\n",
    "\n",
    "    \n",
    "    categorical_cols = [c for c in categorical_cols if c in dfp.columns]\n",
    "    numeric_cols     = [c for c in numeric_cols if c in dfp.columns]\n",
    "\n",
    "    \n",
    "    if numeric_cols:\n",
    "        for c in numeric_cols:\n",
    "            dfp[c] = pd.to_numeric(dfp[c], errors=\"coerce\")\n",
    "            if fill_num != \"none\":\n",
    "                dfp[c] = _impute_numeric(dfp[c], strategy=fill_num)\n",
    "            if clip_outliers:\n",
    "                dfp[c] = _clip_outliers_quantile(dfp[c], q_low=q_low, q_high=q_high)\n",
    "\n",
    "        scaled_block, scaler = _scale_numeric(dfp[numeric_cols], method=scale_method)\n",
    "        dfp[numeric_cols] = scaled_block.values\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    \n",
    "    for c in categorical_cols:\n",
    "        dfp[c] = dfp[c].astype(\"string\") \n",
    "        if strip_space:\n",
    "            dfp[c] = dfp[c].str.strip()\n",
    "        if force_upper:\n",
    "            dfp[c] = dfp[c].str.upper()\n",
    "        dfp[c] = dfp[c].fillna(fill_cat_label)\n",
    "        dfp[c] = dfp[c].replace({\"\": fill_cat_label})\n",
    "\n",
    "        if rare_thresh is not None and rare_thresh > 0:\n",
    "            dfp[c] = _consolidate_rare_categories(dfp[c], min_ratio=rare_thresh, other_label=other_label)\n",
    "\n",
    "        \n",
    "        dfp[c] = dfp[c].astype(object)\n",
    "\n",
    "    artifacts = {\n",
    "        \"scaler\": scaler,\n",
    "        \"numeric_cols\": numeric_cols,\n",
    "        \"categorical_cols\": categorical_cols,\n",
    "        \"scale_method\": scale_method,\n",
    "        \"fill_num\": fill_num,\n",
    "        \"fill_cat_label\": fill_cat_label,\n",
    "        \"rare_thresh\": rare_thresh,\n",
    "        \"other_label\": other_label,\n",
    "        \"clip_outliers\": clip_outliers,\n",
    "        \"q_low\": q_low,\n",
    "        \"q_high\": q_high,\n",
    "        \"force_upper\": force_upper,\n",
    "        \"strip_space\": strip_space,\n",
    "    }\n",
    "    return dfp, artifacts\n",
    "\n",
    "\n",
    "def prepare_for_kmedoids_gower(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: Optional[List[str]] = None,\n",
    "    numeric_cols: Optional[List[str]] = None,\n",
    "    force_cat_as_str: bool = True,\n",
    "    *,\n",
    "    \n",
    "    preprocess: bool = True,\n",
    "    fill_num: str = \"median\",\n",
    "    fill_cat_label: str = \"MISSING\",\n",
    "    rare_thresh: float = 0.01,\n",
    "    other_label: str = \"OTHER\",\n",
    "    clip_outliers: bool = True,\n",
    "    q_low: float = 0.01,\n",
    "    q_high: float = 0.99,\n",
    "    scale_method: str = \"minmax\",\n",
    "    force_upper: bool = False,\n",
    "    strip_space: bool = True,\n",
    ") -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Mengembalikan:\n",
    "      - df siap Gower (numerik sudah bersih & skala konsisten, kategori object)\n",
    "      - daftar kolom kategori & numerik\n",
    "    \"\"\"\n",
    "    df_local = df.copy()\n",
    "\n",
    "    \n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = df_local.select_dtypes(\n",
    "            include=[\"object\", \"string\", \"category\"]\n",
    "        ).columns.tolist()\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = df_local.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    \n",
    "    for c in df_local.columns:\n",
    "        if c not in numeric_cols and c not in categorical_cols:\n",
    "            continue\n",
    "        if pd.api.types.is_integer_dtype(df_local[c]) and df_local[c].nunique(dropna=True) <= 20:\n",
    "            if c in numeric_cols:\n",
    "                numeric_cols.remove(c)\n",
    "            if c not in categorical_cols:\n",
    "                categorical_cols.append(c)\n",
    "\n",
    "    \n",
    "    if force_cat_as_str:\n",
    "        for c in categorical_cols:\n",
    "            if c in df_local.columns:\n",
    "                df_local[c] = df_local[c].astype(\"string\").astype(object)\n",
    "\n",
    "    # preprocessing\n",
    "    if preprocess:\n",
    "        df_local, _art = preprocess_for_kmedoids_gower(\n",
    "            df_local,\n",
    "            categorical_cols=categorical_cols,\n",
    "            numeric_cols=numeric_cols,\n",
    "            fill_num=fill_num,\n",
    "            fill_cat_label=fill_cat_label,\n",
    "            rare_thresh=rare_thresh,\n",
    "            other_label=other_label,\n",
    "            clip_outliers=clip_outliers,\n",
    "            q_low=q_low,\n",
    "            q_high=q_high,\n",
    "            scale_method=scale_method,\n",
    "            force_upper=force_upper,\n",
    "            strip_space=strip_space,\n",
    "        )\n",
    "\n",
    "    return df_local, categorical_cols, numeric_cols\n",
    "\n",
    "def choose_k_by_elbow(k_vals: np.ndarray, costs: np.ndarray) -> int:\n",
    "    k_vals = np.asarray(k_vals, dtype=float)\n",
    "    costs = np.asarray(costs, dtype=float)\n",
    "\n",
    "    # print per iterasi\n",
    "    print(\"Iterasi K dan Cost:\")\n",
    "    for k, c in zip(k_vals, costs):\n",
    "        print(f\"  k = {k:.0f}, cost = {c}\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "    if k_vals.size < 2:\n",
    "        return int(k_vals[0])\n",
    "\n",
    "    if k_vals.size >= 3:\n",
    "        k_norm = (k_vals - k_vals.min()) / (k_vals.max() - k_vals.min() + 1e-12)\n",
    "        c_norm = (costs - costs.min()) / (costs.max() - costs.min() + 1e-12)\n",
    "\n",
    "        p1 = np.array([k_norm[0], c_norm[0]])\n",
    "        p2 = np.array([k_norm[-1], c_norm[-1]])\n",
    "        v = p2 - p1\n",
    "        v_len = np.linalg.norm(v) + 1e-12\n",
    "\n",
    "        pts = np.stack([k_norm, c_norm], axis=1)\n",
    "\n",
    "        dists = np.abs(\n",
    "            v[0] * (p1[1] - pts[:, 1]) - \n",
    "            v[1] * (p1[0] - pts[:, 0])\n",
    "        ) / v_len\n",
    "\n",
    "        \n",
    "        dists[0] = -np.inf\n",
    "        dists[-1] = -np.inf\n",
    "\n",
    "        idx = int(np.nanargmax(dists))\n",
    "        print(f\"Elbow ditemukan pada k = {int(k_vals[idx])} dengan jarak = {dists[idx]}\")\n",
    "        return int(k_vals[idx])\n",
    "\n",
    "    # pilih delta terbesar\n",
    "    deltas = -np.diff(costs)\n",
    "    idx = int(np.nanargmax(deltas))\n",
    "    print(f\"Elbow (2 titik) pada k = {int(k_vals[idx + 1])}\")\n",
    "    return int(k_vals[idx + 1])\n",
    "\n",
    "\n",
    "# Gower Distance \n",
    "def _gower_numeric_block(X: np.ndarray, Y: np.ndarray, minv: np.ndarray, maxv: np.ndarray) -> np.ndarray:\n",
    "    rng = np.where((maxv - minv) > 0, (maxv - minv), 1.0)\n",
    "    diff = np.abs(X[:, None, :] - Y[None, :, :]) / rng\n",
    "    return diff\n",
    "\n",
    "def _gower_categorical_block(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "    eq = (X[:, None, :] == Y[None, :, :])\n",
    "    return (~eq).astype(float)\n",
    "\n",
    "def gower_distance_matrix(\n",
    "    df: pd.DataFrame,\n",
    "    cat_cols: List[str],\n",
    "    num_cols: List[str],\n",
    "    *,\n",
    "    chunk_size: int = 1000\n",
    ") -> np.ndarray:\n",
    "    m = df.shape[0]\n",
    "    P = len(cat_cols) + len(num_cols)\n",
    "    if P == 0:\n",
    "        raise ValueError(\"Tidak ada kolom untuk menghitung jarak.\")\n",
    "\n",
    "    num_data = df[num_cols].to_numpy(dtype=float) if num_cols else None\n",
    "    cat_data = df[cat_cols].to_numpy(dtype=object) if cat_cols else None\n",
    "\n",
    "    if num_cols:\n",
    "        minv = np.nanmin(num_data, axis=0)\n",
    "        maxv = np.nanmax(num_data, axis=0)\n",
    "\n",
    "    D = np.zeros((m, m), dtype=float)\n",
    "    for start in range(0, m, chunk_size):\n",
    "        end = min(m, start + chunk_size)\n",
    "        part = 0.0\n",
    "        if num_cols:\n",
    "            part += _gower_numeric_block(num_data[start:end, :], num_data, minv, maxv).sum(axis=2)\n",
    "        if cat_cols:\n",
    "            part += _gower_categorical_block(cat_data[start:end, :], cat_data).sum(axis=2)\n",
    "        D[start:end, :] = part / float(P)\n",
    "\n",
    "    D = (D + D.T) / 2.0\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "    return D\n",
    "\n",
    "# K-Medoids \n",
    "\n",
    "def _kmedoids_plus_plus_init(D: np.ndarray, k: int, rng: np.random.RandomState) -> List[int]:\n",
    "    n = D.shape[0]\n",
    "    centers = [rng.randint(0, n)]\n",
    "    for _ in range(1, k):\n",
    "        dmin = np.min(D[:, centers], axis=1)\n",
    "        probs = dmin ** 2\n",
    "        s = probs.sum()\n",
    "        if s <= 0 or not np.isfinite(s):\n",
    "            cand = [i for i in range(n) if i not in centers]\n",
    "            centers.append(rng.choice(cand))\n",
    "        else:\n",
    "            probs = probs / s\n",
    "            centers.append(rng.choice(np.arange(n), p=probs))\n",
    "    return centers\n",
    "\n",
    "def _assign_labels(D: np.ndarray, medoids: List[int]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # k= len(medoids); untuk tiap i, pilih medoid terdekat\n",
    "    dist_to_medoids = D[:, medoids]  \n",
    "    labels = np.argmin(dist_to_medoids, axis=1)\n",
    "    dists = dist_to_medoids[np.arange(D.shape[0]), labels]\n",
    "    return labels, dists\n",
    "\n",
    "def _pam_swap(D: np.ndarray, medoids: List[int], labels: np.ndarray, cur_cost: float, max_iter: int) -> Tuple[List[int], np.ndarray, float]:\n",
    "    n = D.shape[0]\n",
    "    medoids = medoids.copy()\n",
    "    k = len(medoids)\n",
    "    for _ in range(max_iter):\n",
    "        improved = False\n",
    "        dist_to_medoids = D[:, medoids]  \n",
    "        best = np.argmin(dist_to_medoids, axis=1)\n",
    "        best_dist = dist_to_medoids[np.arange(n), best]\n",
    "        second_dist = np.partition(dist_to_medoids + np.eye(k)[best] * 1e12, 0, axis=1)[:, 1]\n",
    "\n",
    "        for mi_idx in range(k):\n",
    "            mi = medoids[mi_idx]\n",
    "            # kandidat non-medoid\n",
    "            for h in range(n):\n",
    "                if h in medoids:\n",
    "                    continue\n",
    "                d_ih = D[:, h]\n",
    "                new_dist = np.where(\n",
    "                    best == mi_idx,\n",
    "                    np.minimum(second_dist, d_ih),\n",
    "                    np.minimum(best_dist, d_ih)\n",
    "                )\n",
    "                new_cost = float(new_dist.sum())\n",
    "                if new_cost + 1e-12 < cur_cost:\n",
    "                    medoids[mi_idx] = h\n",
    "                    labels = np.argmin(D[:, medoids], axis=1)\n",
    "                    cur_cost = new_cost\n",
    "                    improved = True\n",
    "                    break\n",
    "            if improved:\n",
    "                break\n",
    "        if not improved:\n",
    "            break\n",
    "    return medoids, labels, cur_cost\n",
    "\n",
    "def kmedoids_fit(\n",
    "    D: np.ndarray,\n",
    "    k: int,\n",
    "    n_init: int = 5,\n",
    "    max_iter: int = 100,\n",
    "    random_state: int = 42\n",
    ") -> Tuple[np.ndarray, List[int], float]:\n",
    "    \"\"\"\n",
    "    K-Medoids (PAM) pada matriks jarak precomputed D.\n",
    "    Mengembalikan: labels (n,), medoids (list idx), total_cost (∑ jarak ke medoid).\n",
    "    \"\"\"\n",
    "    rng_master = np.random.RandomState(random_state)\n",
    "    n = D.shape[0]\n",
    "    best_labels, best_medoids, best_cost = None, None, np.inf\n",
    "\n",
    "    for run in range(n_init):\n",
    "        rng = np.random.RandomState(rng_master.randint(0, 10**9))\n",
    "        medoids = _kmedoids_plus_plus_init(D, k, rng)\n",
    "        labels, dists = _assign_labels(D, medoids)\n",
    "        cost = float(dists.sum())\n",
    "        medoids, labels, cost = _pam_swap(D, medoids, labels, cost, max_iter=max_iter)\n",
    "        if cost < best_cost:\n",
    "            best_labels, best_medoids, best_cost = labels.copy(), medoids.copy(), float(cost)\n",
    "    return best_labels, best_medoids, best_cost\n",
    "\n",
    "# METRICS untuk medoids (Silhouette & DB)\n",
    "def davies_bouldin_medoids(D: np.ndarray, labels: np.ndarray, medoids: List[int]) -> float:\n",
    "    labels = np.asarray(labels)\n",
    "    clusters = np.unique(labels)\n",
    "    k = clusters.size\n",
    "    if k < 2:\n",
    "        return np.nan\n",
    "\n",
    "    # S_i: rata2 jarak anggota cluster i ke medoid cluster i\n",
    "    S = {}\n",
    "    for i, cid in enumerate(clusters):\n",
    "        idx = np.where(labels == cid)[0]\n",
    "        if idx.size == 0:\n",
    "            S[cid] = 0.0\n",
    "            continue\n",
    "        med = medoids[i]  \n",
    "        S[cid] = float(D[idx[:, None], med].mean())\n",
    "\n",
    "    # jarak antar medoid\n",
    "    medoid_dmat = np.zeros((k, k), dtype=float)\n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            medoid_dmat[i, j] = medoid_dmat[j, i] = float(D[medoids[i], medoids[j]])\n",
    "\n",
    "    # DB\n",
    "    R = []\n",
    "    for i, ci in enumerate(clusters):\n",
    "        vals = []\n",
    "        for j, cj in enumerate(clusters):\n",
    "            if i == j:\n",
    "                continue\n",
    "            Mij = medoid_dmat[i, j]\n",
    "            if Mij <= 0:\n",
    "                continue\n",
    "            vals.append((S[ci] + S[cj]) / Mij)\n",
    "        R.append(max(vals) if len(vals) else 0.0)\n",
    "    return float(np.mean(R))\n",
    "\n",
    "# Konfigurasi preprocess\n",
    "PREPROCESS_OPTS = dict(\n",
    "    preprocess=True,           \n",
    "    scale_method=\"minmax\",     \n",
    "    clip_outliers=True,        \n",
    "    q_low=0.01, q_high=0.99,   \n",
    "    fill_num=\"median\",         \n",
    "    fill_cat_label=\"MISSING\",  \n",
    "    rare_thresh=0.01,          \n",
    "    other_label=\"OTHER\",\n",
    "    force_upper=True,\n",
    "    strip_space=True           \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57033d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Proses periode: Monthly_Fixed ===\n",
      "Iterasi K dan Cost:\n",
      "  k = 2, cost = 1756.1488568428522\n",
      "  k = 3, cost = 1623.8029381144336\n",
      "  k = 4, cost = 1572.9048612737229\n",
      "  k = 5, cost = 1534.9092339698827\n",
      "  k = 6, cost = 1495.2415679936444\n",
      "-----------------------------------\n",
      "Elbow ditemukan pada k = 3 dengan jarak = 0.18190510699396664\n",
      "\n",
      "=== Proses periode: Daily_Fixed ===\n",
      "Iterasi K dan Cost:\n",
      "  k = 2, cost = 1156.4646102343377\n",
      "  k = 3, cost = 1097.7486848397896\n",
      "  k = 4, cost = 1047.942763358115\n",
      "  k = 5, cost = 1006.0227164036347\n",
      "  k = 6, cost = 970.6829485674536\n",
      "-----------------------------------\n",
      "Elbow ditemukan pada k = 4 dengan jarak = 0.0594934792891184\n",
      "Selesai. Output: D:\\DATA SKRIPSI\\kontrak_sewa_bersih_clustered_kmedoids_gower.xlsx\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import Workbook \n",
    "\n",
    "# Main function (loop per sheet) — K-Medoids + Gower\n",
    "processed_any = False\n",
    "errors = []\n",
    "\n",
    "# Konfigurasi\n",
    "FILE_PATH = r\"D:/DATA SKRIPSI/kontrak_sewa_bersih.xlsx\"  \n",
    "PERIOD_SHEETS = [\"Monthly_Fixed\", \"Daily_Fixed\"]  \n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\",\"LeaseYearStart\",\"LeaseMonthStart\",\"LeaseDayStart\",\n",
    "    \"LeaseYearEnd\",\"LeaseMonthEnd\",\"LeaseDayEnd\",\"TranCode\",\n",
    "    \"ContractPeriod\",\"ContractType\",\"Building\",\"UnitArea\",\"UnitFloor\"\n",
    "]\n",
    "NUMERIC_COLS = [\"BuildingArea\",\"LeaseDurationDays\",\"LeaseDurationMonths\",\"n_subunit\"]\n",
    "K_RANGE = range(2, 7)\n",
    "DROP_COLS = [\"UnitNum\"]\n",
    "\n",
    "# batasan untuk perhitungan silhouette di dataset \n",
    "MAX_SILHOUETTE_SAMPLES = 2000\n",
    "RANDOM_STATE_SIL = 42\n",
    "\n",
    "# Proses tiap sheet (periode)\n",
    "in_path = Path(FILE_PATH)\n",
    "out_path = in_path.with_name(f\"{in_path.stem}_clustered_kmedoids_gower{in_path.suffix}\")\n",
    "\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as ew:\n",
    "    for SHEET_NAME in PERIOD_SHEETS:\n",
    "        try:\n",
    "            print(f\"\\n=== Proses periode: {SHEET_NAME} ===\")\n",
    "\n",
    "            df_raw = pd.read_excel(FILE_PATH, sheet_name=SHEET_NAME)\n",
    "\n",
    "            # validasi minimum\n",
    "            if df_raw.shape[0] < 2:\n",
    "                raise ValueError(\"Baris data < 2\")\n",
    "\n",
    "            # buang kolom tak terpakai\n",
    "            df_raw = df_raw.drop(columns=[c for c in DROP_COLS if c in df_raw.columns], errors=\"ignore\")\n",
    "\n",
    "            # coerce numerik (awal) agar konsisten\n",
    "            for col in NUMERIC_COLS:\n",
    "                if col in df_raw.columns:\n",
    "                    df_raw[col] = pd.to_numeric(df_raw[col], errors=\"coerce\").astype(float)\n",
    "\n",
    "            # pilih kolom yang tersedia di sheet\n",
    "            CATEG_COLS_USED = [c for c in CATEGORICAL_COLS if c in df_raw.columns]\n",
    "            NUMERIC_COLS_USED = [c for c in NUMERIC_COLS if c in df_raw.columns]\n",
    "\n",
    "            if len(CATEG_COLS_USED) == 0 and len(NUMERIC_COLS_USED) == 0:\n",
    "                raise ValueError(\"Tidak ada kolom dari daftar yang ditemukan\")\n",
    "\n",
    "            # PREP + PREPROCESS untuk Gower & K-Medoids \n",
    "            df_prep, cat_cols, num_cols = prepare_for_kmedoids_gower(\n",
    "                df_raw,\n",
    "                categorical_cols=CATEG_COLS_USED,\n",
    "                numeric_cols=NUMERIC_COLS_USED,\n",
    "                force_cat_as_str=True,\n",
    "                **PREPROCESS_OPTS\n",
    "            )\n",
    "\n",
    "            if max(K_RANGE) >= df_prep.shape[0]:\n",
    "                raise ValueError(f\"Jumlah baris ({df_prep.shape[0]}) harus > max K ({max(K_RANGE)})\")\n",
    "\n",
    "            # Matriks jarak Gower (precomputed) \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                D = gower_distance_matrix(df_prep, cat_cols=cat_cols, num_cols=num_cols, chunk_size=1000)\n",
    "\n",
    "            # Cari K (Elbow) lewat biaya K-Medoids (total jarak ke medoid) \n",
    "            elbow_rows = []\n",
    "            for k in K_RANGE:\n",
    "                labels_k, medoids_k, cost_k = kmedoids_fit(D, k=int(k), n_init=10, max_iter=100, random_state=42)\n",
    "                elbow_rows.append({\"k\": int(k), \"cost\": float(cost_k)})\n",
    "\n",
    "            elbow_tbl = pd.DataFrame(elbow_rows).sort_values(\"k\").reset_index(drop=True)\n",
    "            FINAL_K = choose_k_by_elbow(elbow_tbl[\"k\"].to_numpy(), elbow_tbl[\"cost\"].to_numpy())\n",
    "\n",
    "            # Model final dengan K terpilih \n",
    "            labels, medoids, total_cost = kmedoids_fit(D, k=int(FINAL_K), n_init=15, max_iter=200, random_state=42)\n",
    "\n",
    "            # cek kluster kecil (untuk silhouette)\n",
    "            counts = np.bincount(labels, minlength=FINAL_K)\n",
    "            if np.any(counts < 2):\n",
    "                print(f\"[INFO] Ada kluster berisi <2 baris: {counts}. Silhouette mungkin di-skip.\")\n",
    "\n",
    "            # simpan hasil klaster\n",
    "            df_out = df_raw.copy()\n",
    "            df_out[\"cluster\"] = labels\n",
    "\n",
    "            # METRICS \n",
    "            try:\n",
    "                n_rows = df_prep.shape[0]\n",
    "                if n_rows > MAX_SILHOUETTE_SAMPLES:\n",
    "                    rng = np.random.RandomState(RANDOM_STATE_SIL)\n",
    "                    sample_idx = np.sort(rng.choice(n_rows, size=MAX_SILHOUETTE_SAMPLES, replace=False))\n",
    "                    D_samp = D[np.ix_(sample_idx, sample_idx)]\n",
    "                    labels_samp = np.asarray(labels)[sample_idx]\n",
    "                else:\n",
    "                    D_samp = D\n",
    "                    labels_samp = np.asarray(labels)\n",
    "\n",
    "                ok_for_sil = np.all(np.bincount(labels_samp, minlength=FINAL_K) >= 2)\n",
    "                if ok_for_sil:\n",
    "                    sil_score = silhouette_score(D_samp, labels_samp, metric='precomputed')\n",
    "                else:\n",
    "                    sil_score = np.nan\n",
    "                    print(\"[INFO] Silhouette di-skip (ada kluster sample berisi <2).\")\n",
    "            except Exception as e:\n",
    "                sil_score = np.nan\n",
    "                print(f\"[WARN] Gagal hitung Silhouette: {e}\")\n",
    "\n",
    "            try:\n",
    "                uniq = np.unique(labels)\n",
    "                medoids_ordered = []\n",
    "                for cid in uniq:\n",
    "                    idx = np.where(labels == cid)[0]\n",
    "                    sums = D[np.ix_(idx, idx)].sum(axis=1)\n",
    "                    medoids_ordered.append(idx[int(np.argmin(sums))])\n",
    "                db_index = davies_bouldin_medoids(D, labels, medoids_ordered)\n",
    "            except Exception as e:\n",
    "                db_index = np.nan\n",
    "                print(f\"[WARN] Gagal hitung Davies–Bouldin: {e}\")\n",
    "\n",
    "            # Tulis output\n",
    "            df_out.to_excel(ew, index=False, sheet_name=f\"{SHEET_NAME}_clustered\")\n",
    "            pd.DataFrame({\n",
    "                \"Sheet\": [SHEET_NAME],\n",
    "                \"FINAL_K\": [FINAL_K],\n",
    "                \"Silhouette\": [sil_score],\n",
    "                \"DaviesBouldin\": [db_index],\n",
    "                \"TotalCost\": [total_cost],\n",
    "                \"Rows\": [df_prep.shape[0]]\n",
    "            }).to_excel(ew, index=False, sheet_name=f\"{SHEET_NAME}_metrics\")\n",
    "\n",
    "            medoid_rows = pd.DataFrame({\"medoid_row_index\": medoids})\n",
    "            medoid_rows.to_excel(ew, index=False, sheet_name=f\"{SHEET_NAME}_medoids\")\n",
    "\n",
    "            if \"CuryUnitPrice\" in df_raw.columns:\n",
    "                df_raw.reset_index()[[\"index\", \"CuryUnitPrice\"]].rename(columns={\"index\": \"RowID\"}).to_excel(\n",
    "                    ew, index=False, sheet_name=f\"{SHEET_NAME}_CuryUnitPrice\"\n",
    "                )\n",
    "\n",
    "            processed_any = True\n",
    "\n",
    "        except Exception as e:\n",
    "            msg = f\"{SHEET_NAME}: {type(e).__name__} - {e}\"\n",
    "            print(\"[ERROR]\", msg)\n",
    "            errors.append({\"sheet\": SHEET_NAME, \"error\": msg})\n",
    "\n",
    "    if not processed_any:\n",
    "        pd.DataFrame({\"status\": [\"No valid sheets processed\"]}).to_excel(ew, index=False, sheet_name=\"error_info\")\n",
    "    elif errors:\n",
    "        pd.DataFrame(errors).to_excel(ew, index=False, sheet_name=\"error_info\")\n",
    "\n",
    "print(\"Selesai. Output:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b788dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
