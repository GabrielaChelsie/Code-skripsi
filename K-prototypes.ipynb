{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897fc166",
   "metadata": {},
   "source": [
    "## code lama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824f3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple\n",
    "from kmodes.kprototypes import KPrototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec47e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_kprototypes(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: Optional[List[str]] = None,\n",
    "    numeric_cols: Optional[List[str]] = None,\n",
    "    force_cat_as_str: bool = True,\n",
    ") -> Tuple[pd.DataFrame, List[int], List[str], List[str]]:\n",
    "    df = df.copy()\n",
    "\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = df.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist()\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    if force_cat_as_str:\n",
    "        for c in categorical_cols:\n",
    "            if c in df.columns:\n",
    "                df[c] = df[c].astype(\"string\").astype(object)\n",
    "\n",
    "    cat_idx = [df.columns.get_loc(c) for c in categorical_cols if c in df.columns]\n",
    "    return df, cat_idx, categorical_cols, numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1b8052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_gamma(df: pd.DataFrame, numeric_cols: List[str]) -> float:\n",
    "    \"\"\"Heuristik sederhana untuk gamma (penyeimbang numerik vs kategorikal).\"\"\"\n",
    "    if not numeric_cols:\n",
    "        return 1.0\n",
    "    stds = [df[c].astype(float).std(ddof=0) for c in numeric_cols if c in df.columns]\n",
    "    g = float(np.nanmean(stds)) if len(stds) else np.nan\n",
    "    return 1.0 if (np.isnan(g) or g == 0) else g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023db7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def choose_k_by_elbow(k_vals: np.ndarray, costs: np.ndarray) -> int:\n",
    "    k_vals = np.asarray(k_vals, dtype=float)\n",
    "    costs  = np.asarray(costs, dtype=float)\n",
    "\n",
    "    # jika kurang dari 2 titik, default ke K minimum\n",
    "    if k_vals.size < 2:\n",
    "        return int(k_vals[0])\n",
    "\n",
    "    if k_vals.size >= 3:\n",
    "        # normalisasi ke [0,1]\n",
    "        k_norm = (k_vals - k_vals.min()) / (k_vals.max() - k_vals.min() + 1e-12)\n",
    "        c_norm = (costs  - costs.min()) / (costs.max() - costs.min() + 1e-12)\n",
    "        p1 = np.array([k_norm[0],  c_norm[0]])\n",
    "        p2 = np.array([k_norm[-1], c_norm[-1]])\n",
    "        v  = p2 - p1\n",
    "        v_len = np.linalg.norm(v) + 1e-12\n",
    "\n",
    "        pts = np.stack([k_norm, c_norm], axis=1)\n",
    "        dists = np.abs(np.cross(v, pts - p1)) / v_len\n",
    "        dists[0]  = -np.inf\n",
    "        dists[-1] = -np.inf\n",
    "        idx = int(np.nanargmax(dists))\n",
    "        return int(k_vals[idx])\n",
    "\n",
    "    \n",
    "    deltas = -np.diff(costs)  \n",
    "    idx = int(np.nanargmax(deltas))\n",
    "    return int(k_vals[idx + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH  = r\"kontrak-sewa-for-clustering.xlsx\"  \n",
    "SHEET_NAME = \"Sheet1\"  \n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\",\"LeaseYearStart\",\"LeaseMonthStart\",\"LeaseDayStart\",\n",
    "    \"LeaseYearEnd\",\"LeaseMonthEnd\",\"LeaseDayEnd\",\"TranCode\",\n",
    "    \"ContractPeriod\",\"ContractType\",\"Building\",\"UnitArea\",\"UnitFloor\"\n",
    "]\n",
    "NUMERIC_COLS     = [\"BuildingArea\",\"LeaseDurationDays\",\"LeaseDurationMonths\",\"n_subunit\"]\n",
    "\n",
    "\n",
    "K_RANGE = range(2, 7)\n",
    "DROP_COLS = [\"UnitNum\"]\n",
    "\n",
    "\n",
    "# Load & Persiapan Data\n",
    "df_raw = pd.read_excel(FILE_PATH, sheet_name=SHEET_NAME)\n",
    "df_raw = df_raw.drop(columns=[c for c in DROP_COLS if c in df_raw.columns])\n",
    "\n",
    "for col in NUMERIC_COLS:\n",
    "    if col in df_raw.columns:\n",
    "        df_raw[col] = pd.to_numeric(df_raw[col], errors=\"coerce\").astype(float)\n",
    "\n",
    "# kolom yg tidak terdaftar masuk ke kategori\n",
    "listed = set(CATEGORICAL_COLS) | set(NUMERIC_COLS)\n",
    "CATEGORICAL_COLS = [c for c in CATEGORICAL_COLS if c in df_raw.columns]\n",
    "NUMERIC_COLS     = [c for c in NUMERIC_COLS if c in df_raw.columns]\n",
    "\n",
    "\n",
    "df_prep, cat_idx, cat_cols, num_cols = prepare_for_kprototypes(\n",
    "    df_raw,\n",
    "    categorical_cols=CATEGORICAL_COLS,\n",
    "    numeric_cols=NUMERIC_COLS,\n",
    "    force_cat_as_str=True,\n",
    ")\n",
    "\n",
    "gamma = auto_gamma(df_prep, num_cols)\n",
    "X = df_prep.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "687b2ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Elbow (cost vs k) ===\n",
      "   k          cost  n_iter\n",
      "0  2  2.098539e+17       5\n",
      "1  3  1.022850e+17      17\n",
      "2  4  6.317248e+16      11\n",
      "3  5  4.417157e+16       6\n",
      "4  6  3.802799e+16       8\n",
      "\n",
      "FINAL_K yang dipilih= 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_26416\\2839456375.py:22: DeprecationWarning: Arrays of 2-dimensional vectors are deprecated. Use arrays of 3-dimensional vectors instead. (deprecated in NumPy 2.0)\n",
      "  dists = np.abs(np.cross(v, pts - p1)) / v_len\n"
     ]
    }
   ],
   "source": [
    "elbow_rows = []\n",
    "for k in K_RANGE:\n",
    "    mk = KPrototypes(\n",
    "        n_clusters=int(k), init=\"Huang\", n_init=5, max_iter=100,\n",
    "        random_state=42, gamma=gamma, verbose=0\n",
    "    )\n",
    "    mk.fit_predict(X, categorical=cat_idx)\n",
    "    elbow_rows.append({\"k\": int(k), \"cost\": float(mk.cost_), \"n_iter\": int(mk.n_iter_)})\n",
    "\n",
    "elbow_tbl = pd.DataFrame(elbow_rows).sort_values(\"k\").reset_index(drop=True)\n",
    "print(\"\\n=== Elbow (cost vs k) ===\")\n",
    "print(elbow_tbl)\n",
    "\n",
    "FINAL_K = choose_k_by_elbow(elbow_tbl[\"k\"].to_numpy(), elbow_tbl[\"cost\"].to_numpy())\n",
    "print(f\"\\nFINAL_K yang dipilih= {FINAL_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00370712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai. Hasil tersimpan di: kontrak-sewa-for-clustering_with_cluster.xlsx\n",
      "Fitur kategorikal: ['BusinessType', 'LeaseYearStart', 'LeaseMonthStart', 'LeaseDayStart', 'LeaseYearEnd', 'LeaseMonthEnd', 'LeaseDayEnd', 'TranCode', 'ContractPeriod', 'ContractType', 'Building', 'UnitArea', 'UnitFloor']\n",
      "Fitur numerik    : ['BuildingArea', 'LeaseDurationDays', 'LeaseDurationMonths', 'n_subunit']\n",
      "Jumlah cluster   : 3\n"
     ]
    }
   ],
   "source": [
    "model_final = KPrototypes(\n",
    "    n_clusters=int(FINAL_K),\n",
    "    init=\"Huang\",\n",
    "    n_init=5,\n",
    "    max_iter=100,\n",
    "    random_state=42,\n",
    "    gamma=gamma,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "labels = model_final.fit_predict(X, categorical=cat_idx)\n",
    "\n",
    "df_out = df_raw.copy()\n",
    "df_out[\"cluster\"] = labels  \n",
    "\n",
    "if \"CuryUnitPrice\" in df_out.columns:\n",
    "    df_out = df_out.drop(columns=[\"CuryUnitPrice\"])\n",
    "\n",
    "#CuryUnitPrice\n",
    "price_sheet_df = (\n",
    "    df_raw.reset_index()[[\"index\",\"CuryUnitPrice\"]]\n",
    "    .rename(columns={\"index\": \"RowID\"})\n",
    "    if \"CuryUnitPrice\" in df_raw.columns else\n",
    "    pd.DataFrame(columns=[\"RowID\",\"CuryUnitPrice\"])\n",
    ")\n",
    "\n",
    "in_path  = Path(FILE_PATH)\n",
    "out_path = in_path.with_name(f\"{in_path.stem}_with_cluster{in_path.suffix}\")\n",
    "\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as ew:\n",
    "    sheet_main = SHEET_NAME if SHEET_NAME is not None else \"Sheet1\"\n",
    "    df_out.to_excel(ew, index=False, sheet_name=sheet_main)\n",
    "    price_sheet_df.to_excel(ew, index=False, sheet_name=\"CuryUnitPrice\")\n",
    "\n",
    "print(f\"Selesai. Hasil tersimpan di: {out_path}\")\n",
    "print(\"Fitur kategorikal:\", cat_cols)\n",
    "print(\"Fitur numerik    :\", num_cols)\n",
    "print(f\"Jumlah cluster   : {FINAL_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ae9a2f",
   "metadata": {},
   "source": [
    "## code lengkap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64c19a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kprototypes import KPrototypes\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d268e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _impute_numeric(\n",
    "    s: pd.Series,\n",
    "    strategy: str = \"median\"\n",
    ") -> pd.Series:\n",
    "    if strategy == \"median\":\n",
    "        return s.fillna(s.median())\n",
    "    elif strategy == \"mean\":\n",
    "        return s.fillna(s.mean())\n",
    "    elif strategy == \"zero\":\n",
    "        return s.fillna(0)\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def _clip_outliers_quantile(\n",
    "    s: pd.Series,\n",
    "    q_low: float = 0.01,\n",
    "    q_high: float = 0.99\n",
    ") -> pd.Series:\n",
    "    lo, hi = s.quantile(q_low), s.quantile(q_high)\n",
    "    if pd.isna(lo) or pd.isna(hi):\n",
    "        return s\n",
    "    return s.clip(lo, hi)\n",
    "\n",
    "def _consolidate_rare_categories(\n",
    "    s: pd.Series,\n",
    "    min_ratio: float = 0.01,\n",
    "    other_label: str = \"OTHER\"\n",
    ") -> pd.Series:\n",
    "    # bekerja pada string/object\n",
    "    counts = s.value_counts(dropna=False)\n",
    "    total = counts.sum()\n",
    "    rare = set(counts[counts / max(total, 1) <= min_ratio].index)\n",
    "    return s.apply(lambda v: other_label if v in rare else v)\n",
    "\n",
    "def _scale_numeric(\n",
    "    df_num: pd.DataFrame,\n",
    "    method: str = \"minmax\"\n",
    "):\n",
    "    if df_num.empty:\n",
    "        return df_num, None\n",
    "    if method == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "    scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(df_num.values),\n",
    "        columns=df_num.columns,\n",
    "        index=df_num.index\n",
    "    )\n",
    "    return scaled, scaler\n",
    "\n",
    "def preprocess_for_kprototypes(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: List[str],\n",
    "    numeric_cols: List[str],\n",
    "    *,\n",
    "    fill_num: str = \"median\",            \n",
    "    fill_cat_label: str = \"MISSING\",     \n",
    "    rare_thresh: float = 0.01,           \n",
    "    other_label: str = \"OTHER\",\n",
    "    clip_outliers: bool = True,\n",
    "    q_low: float = 0.01,\n",
    "    q_high: float = 0.99,\n",
    "    scale_method: str = \"minmax\",        \n",
    "    force_upper: bool = False,           \n",
    "    strip_space: bool = True\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Mengembalikan df yang sudah siap untuk K-Prototypes + artifacts (scaler, mapping).\n",
    "    \"\"\"\n",
    "    dfp = df.copy()\n",
    "\n",
    "    # cek kolom\n",
    "    categorical_cols = [c for c in categorical_cols if c in dfp.columns]\n",
    "    numeric_cols     = [c for c in numeric_cols if c in dfp.columns]\n",
    "\n",
    "    # numerik: coerce, imputasi, clipping, scaling\n",
    "    if numeric_cols:\n",
    "        for c in numeric_cols:\n",
    "            dfp[c] = pd.to_numeric(dfp[c], errors=\"coerce\")\n",
    "            if fill_num != \"none\":\n",
    "                dfp[c] = _impute_numeric(dfp[c], strategy=fill_num)\n",
    "            if clip_outliers:\n",
    "                dfp[c] = _clip_outliers_quantile(dfp[c], q_low=q_low, q_high=q_high)\n",
    "\n",
    "        scaled_block, scaler = _scale_numeric(dfp[numeric_cols], method=scale_method)\n",
    "        dfp[numeric_cols] = scaled_block.values\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    # kategorikal: cast ke string object, normalisasi teks, imputasi NA, rare merge\n",
    "    for c in categorical_cols:\n",
    "        dfp[c] = dfp[c].astype(\"string\")  # string dtype\n",
    "        if strip_space:\n",
    "            dfp[c] = dfp[c].str.strip()\n",
    "        if force_upper:\n",
    "            dfp[c] = dfp[c].str.upper()\n",
    "        dfp[c] = dfp[c].fillna(fill_cat_label)\n",
    "        # jika ada string kosong setelah strip, ganti ke MISSING\n",
    "        dfp[c] = dfp[c].replace({\"\": fill_cat_label})\n",
    "\n",
    "        if rare_thresh is not None and rare_thresh > 0:\n",
    "            dfp[c] = _consolidate_rare_categories(dfp[c], min_ratio=rare_thresh, other_label=other_label)\n",
    "\n",
    "        \n",
    "        dfp[c] = dfp[c].astype(object)\n",
    "\n",
    "    artifacts = {\n",
    "        \"scaler\": scaler,\n",
    "        \"numeric_cols\": numeric_cols,\n",
    "        \"categorical_cols\": categorical_cols,\n",
    "        \"scale_method\": scale_method,\n",
    "        \"fill_num\": fill_num,\n",
    "        \"fill_cat_label\": fill_cat_label,\n",
    "        \"rare_thresh\": rare_thresh,\n",
    "        \"other_label\": other_label,\n",
    "        \"clip_outliers\": clip_outliers,\n",
    "        \"q_low\": q_low,\n",
    "        \"q_high\": q_high,\n",
    "        \"force_upper\": force_upper,\n",
    "        \"strip_space\": strip_space,\n",
    "    }\n",
    "    return dfp, artifacts\n",
    "\n",
    "\n",
    "def prepare_for_kprototypes(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: Optional[List[str]] = None,\n",
    "    numeric_cols: Optional[List[str]] = None,\n",
    "    force_cat_as_str: bool = True,\n",
    "    *,\n",
    "    preprocess: bool = True,\n",
    "    fill_num: str = \"median\",\n",
    "    fill_cat_label: str = \"MISSING\",\n",
    "    rare_thresh: float = 0.01,\n",
    "    other_label: str = \"OTHER\",\n",
    "    clip_outliers: bool = True,\n",
    "    q_low: float = 0.01,\n",
    "    q_high: float = 0.99,\n",
    "    scale_method: str = \"minmax\",\n",
    "    force_upper: bool = False,\n",
    "    strip_space: bool = True,\n",
    ") -> Tuple[pd.DataFrame, List[int], List[str], List[str]]:\n",
    "   \n",
    "    df_local = df.copy()\n",
    "\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = df_local.select_dtypes(\n",
    "            include=[\"object\", \"string\", \"category\"]\n",
    "        ).columns.tolist()\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = df_local.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "\n",
    "    for c in df_local.columns:\n",
    "        if c not in numeric_cols and c not in categorical_cols:\n",
    "            continue\n",
    "        if pd.api.types.is_integer_dtype(df_local[c]) and df_local[c].nunique(dropna=True) <= 20:\n",
    "            if c in numeric_cols:\n",
    "                numeric_cols.remove(c)\n",
    "            if c not in categorical_cols:\n",
    "                categorical_cols.append(c)\n",
    "\n",
    "    \n",
    "    if force_cat_as_str:\n",
    "        for c in categorical_cols:\n",
    "            if c in df_local.columns:\n",
    "                df_local[c] = df_local[c].astype(\"string\").astype(object)\n",
    "\n",
    "    \n",
    "    if preprocess:\n",
    "        df_local, _art = preprocess_for_kprototypes(\n",
    "            df_local,\n",
    "            categorical_cols=categorical_cols,\n",
    "            numeric_cols=numeric_cols,\n",
    "            fill_num=fill_num,\n",
    "            fill_cat_label=fill_cat_label,\n",
    "            rare_thresh=rare_thresh,\n",
    "            other_label=other_label,\n",
    "            clip_outliers=clip_outliers,\n",
    "            q_low=q_low,\n",
    "            q_high=q_high,\n",
    "            scale_method=scale_method,\n",
    "            force_upper=force_upper,\n",
    "            strip_space=strip_space,\n",
    "        )\n",
    "\n",
    "   \n",
    "    cat_idx = [df_local.columns.get_loc(c) for c in categorical_cols if c in df_local.columns]\n",
    "    return df_local, cat_idx, categorical_cols, numeric_cols\n",
    "\n",
    "\n",
    "def auto_gamma(df: pd.DataFrame, numeric_cols: List[str]) -> float:\n",
    "    if not numeric_cols:\n",
    "        return 1.0\n",
    "    stds = [pd.to_numeric(df[c], errors=\"coerce\").astype(float).std(ddof=0) for c in numeric_cols if c in df.columns]\n",
    "    g = float(np.nanmean(stds)) if len(stds) else np.nan\n",
    "    return 1.0 if (np.isnan(g) or g == 0) else g\n",
    "\n",
    "\n",
    "def choose_k_by_elbow(k_vals: np.ndarray, costs: np.ndarray) -> int:\n",
    "    k_vals = np.asarray(k_vals, dtype=float)\n",
    "    costs = np.asarray(costs, dtype=float)\n",
    "\n",
    "    # print per iterasi\n",
    "    print(\"Iterasi K dan Cost:\")\n",
    "    for k, c in zip(k_vals, costs):\n",
    "        print(f\"  k = {k:.0f}, cost = {c}\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "    if k_vals.size < 2:\n",
    "        return int(k_vals[0])\n",
    "\n",
    "    if k_vals.size >= 3:\n",
    "        k_norm = (k_vals - k_vals.min()) / (k_vals.max() - k_vals.min() + 1e-12)\n",
    "        c_norm = (costs - costs.min()) / (costs.max() - costs.min() + 1e-12)\n",
    "\n",
    "        p1 = np.array([k_norm[0], c_norm[0]])\n",
    "        p2 = np.array([k_norm[-1], c_norm[-1]])\n",
    "        v = p2 - p1\n",
    "        v_len = np.linalg.norm(v) + 1e-12\n",
    "\n",
    "        pts = np.stack([k_norm, c_norm], axis=1)\n",
    "\n",
    "        \n",
    "        dists = np.abs(\n",
    "            v[0] * (p1[1] - pts[:, 1]) - \n",
    "            v[1] * (p1[0] - pts[:, 0])\n",
    "        ) / v_len\n",
    "\n",
    "        \n",
    "        dists[0] = -np.inf\n",
    "        dists[-1] = -np.inf\n",
    "\n",
    "        idx = int(np.nanargmax(dists))\n",
    "        print(f\"Elbow ditemukan pada k = {int(k_vals[idx])} dengan jarak = {dists[idx]}\")\n",
    "        return int(k_vals[idx])\n",
    "\n",
    "    \n",
    "    deltas = -np.diff(costs)\n",
    "    idx = int(np.nanargmax(deltas))\n",
    "    print(f\"Elbow (2 titik) pada k = {int(k_vals[idx + 1])}\")\n",
    "    return int(k_vals[idx + 1])\n",
    "\n",
    "\n",
    "\n",
    "MAX_SILHOUETTE_SAMPLES = 2000\n",
    "RANDOM_STATE_SIL = 42\n",
    "\n",
    "def _split_cols_positions(n_total_cols: int, cat_idx: List[int]):\n",
    "    cat_idx = np.array(sorted(cat_idx), dtype=int)\n",
    "    all_idx = np.arange(n_total_cols, dtype=int)\n",
    "    num_idx = np.setdiff1d(all_idx, cat_idx, assume_unique=True)\n",
    "    return num_idx, cat_idx\n",
    "\n",
    "def _kproto_pairwise_dissim_matrix(X: np.ndarray, cat_idx: List[int], gamma: float) -> np.ndarray:\n",
    "    m, p = X.shape\n",
    "    num_idx, cat_idx_arr = _split_cols_positions(p, cat_idx)\n",
    "\n",
    "    if num_idx.size > 0:\n",
    "        Xn = X[:, num_idx].astype(float)\n",
    "        sq_norms = np.sum(Xn * Xn, axis=1, keepdims=True)\n",
    "        num_D = sq_norms + sq_norms.T - 2.0 * (Xn @ Xn.T)\n",
    "        num_D[num_D < 0] = 0.0\n",
    "    else:\n",
    "        num_D = np.zeros((m, m), dtype=float)\n",
    "\n",
    "    if cat_idx_arr.size > 0:\n",
    "        Xc = X[:, cat_idx_arr]\n",
    "        cat_D = np.zeros((m, m), dtype=float)\n",
    "        for j in range(Xc.shape[1]):\n",
    "            col = Xc[:, j]\n",
    "            eq = (col.reshape(-1, 1) == col.reshape(1, -1))\n",
    "            cat_D += (~eq).astype(float)\n",
    "        cat_D *= float(gamma)\n",
    "    else:\n",
    "        cat_D = np.zeros((m, m), dtype=float)\n",
    "\n",
    "    return num_D + cat_D\n",
    "\n",
    "def _mode_series(values):\n",
    "    cnt = Counter(values)\n",
    "    return cnt.most_common(1)[0][0] if values else None\n",
    "\n",
    "def _prototype_for_cluster(df_like: pd.DataFrame, labels: np.ndarray, cid: int,\n",
    "                           cat_cols: List[str], num_cols: List[str]) -> pd.Series:\n",
    "    sub = df_like.loc[labels == cid]\n",
    "    proto = {}\n",
    "    for c in num_cols:\n",
    "        proto[c] = float(sub[c].astype(float).mean()) if c in sub.columns else np.nan\n",
    "    for c in cat_cols:\n",
    "        proto[c] = _mode_series(sub[c].tolist()) if c in sub.columns else None\n",
    "    return pd.Series(proto)\n",
    "\n",
    "def _mixed_dissim_point_to_proto(x_row: pd.Series, proto: pd.Series,\n",
    "                                 cat_cols: List[str], num_cols: List[str], gamma: float) -> float:\n",
    "    d_num = 0.0\n",
    "    if num_cols:\n",
    "        x_num = x_row[num_cols].astype(float).to_numpy()\n",
    "        p_num = pd.to_numeric(proto[num_cols], errors=\"coerce\").astype(float).to_numpy()\n",
    "        diff = x_num - p_num\n",
    "        d_num = float(np.nansum(diff * diff))\n",
    "    d_cat = 0.0\n",
    "    for c in cat_cols:\n",
    "        d_cat += 0.0 if x_row.get(c, None) == proto.get(c, None) else 1.0\n",
    "    return d_num + gamma * d_cat\n",
    "\n",
    "def davies_bouldin_mixed(df_like: pd.DataFrame, labels: np.ndarray,\n",
    "                         cat_cols: List[str], num_cols: List[str], gamma: float) -> float:\n",
    "    labels = np.asarray(labels)\n",
    "    clusters = np.unique(labels)\n",
    "    k = clusters.size\n",
    "    if k < 2:\n",
    "        return np.nan\n",
    "\n",
    "    protos = {c: _prototype_for_cluster(df_like, labels, c, cat_cols, num_cols) for c in clusters}\n",
    "\n",
    "    S = {}\n",
    "    for c in clusters:\n",
    "        idxs = np.where(labels == c)[0]\n",
    "        if idxs.size <= 1:\n",
    "            S[c] = 0.0\n",
    "            continue\n",
    "        proto = protos[c]\n",
    "        dists = [\n",
    "            _mixed_dissim_point_to_proto(df_like.iloc[i], proto, cat_cols, num_cols, gamma)\n",
    "            for i in idxs\n",
    "        ]\n",
    "        S[c] = float(np.mean(dists))\n",
    "\n",
    "    def proto_proto_dist(pi: pd.Series, pj: pd.Series) -> float:\n",
    "        d_num = 0.0\n",
    "        if num_cols:\n",
    "            ni = pd.to_numeric(pi[num_cols], errors=\"coerce\").astype(float).to_numpy()\n",
    "            nj = pd.to_numeric(pj[num_cols], errors=\"coerce\").astype(float).to_numpy()\n",
    "            diff = ni - nj\n",
    "            d_num = float(np.nansum(diff * diff))\n",
    "        d_cat = 0.0\n",
    "        for c in cat_cols:\n",
    "            d_cat += 0.0 if pi.get(c, None) == pj.get(c, None) else 1.0\n",
    "        return d_num + gamma * d_cat\n",
    "\n",
    "    R = []\n",
    "    for i in clusters:\n",
    "        Ri = -np.inf\n",
    "        for j in clusters:\n",
    "            if i == j:\n",
    "                continue\n",
    "            Mij = proto_proto_dist(protos[i], protos[j])\n",
    "            if Mij == 0:\n",
    "                continue\n",
    "            Rij = (S[i] + S[j]) / Mij\n",
    "            if Rij > Ri:\n",
    "                Ri = Rij\n",
    "        R.append(Ri if np.isfinite(Ri) else 0.0)\n",
    "\n",
    "    return float(np.mean(R))\n",
    "\n",
    "from sklearn.metrics import silhouette_score  # pastikan ini ada di atas\n",
    "\n",
    "def silhouette_kprototypes_mixed(\n",
    "    df_like: pd.DataFrame,\n",
    "    labels: np.ndarray,\n",
    "    cat_idx: List[int],\n",
    "    gamma: float,\n",
    "    max_samples: int = MAX_SILHOUETTE_SAMPLES,\n",
    "    random_state: int = RANDOM_STATE_SIL\n",
    ") -> float:\n",
    "    \n",
    "    labels = np.asarray(labels)\n",
    "    n_samples = df_like.shape[0]\n",
    "\n",
    "    if n_samples < 2:\n",
    "        return np.nan\n",
    "\n",
    "    rng = np.random.RandomState(random_state)\n",
    "\n",
    "    if n_samples > max_samples:\n",
    "        idx = np.sort(rng.choice(n_samples, size=max_samples, replace=False))\n",
    "        X_sub = df_like.to_numpy()[idx]\n",
    "        labels_sub = labels[idx]\n",
    "    else:\n",
    "        X_sub = df_like.to_numpy()\n",
    "        labels_sub = labels\n",
    "\n",
    "    clusters_sub = np.unique(labels_sub)\n",
    "    if clusters_sub.size < 2:\n",
    "        return np.nan\n",
    "\n",
    "    # matriks dissimilarity mixed untuk sample yang dipakai\n",
    "    D = _kproto_pairwise_dissim_matrix(X_sub, cat_idx, gamma)\n",
    "    D = np.asarray(D, dtype=float)\n",
    "    D[D < 0] = 0.0\n",
    "    D = 0.5 * (D + D.T)\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "\n",
    "    sil = silhouette_score(D, labels_sub, metric=\"precomputed\")\n",
    "    return float(sil)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b8ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File output sudah ada, menghapus: D:\\DATA SKRIPSI\\kontrak_sewa_bersih_clustered.xlsx\n",
      "\n",
      "=== Proses periode: Monthly_Fixed ===\n",
      "Iterasi K dan Cost:\n",
      "  k = 2, cost = 94559134698437.77\n",
      "  k = 3, cost = 61845414922512.55\n",
      "  k = 4, cost = 21833507347716.35\n",
      "  k = 5, cost = 14122752653322.16\n",
      "  k = 6, cost = 9275087068763.059\n",
      "-----------------------------------\n",
      "Elbow ditemukan pada k = 4 dengan jarak = 0.24942906269063833\n",
      "\n",
      "=== Proses periode: Daily_Fixed ===\n",
      "Iterasi K dan Cost:\n",
      "  k = 2, cost = 304409666998.77313\n",
      "  k = 3, cost = 172198676837.30658\n",
      "  k = 4, cost = 80522341554.1603\n",
      "  k = 5, cost = 57358960933.33165\n",
      "  k = 6, cost = 39585334111.49639\n",
      "-----------------------------------\n",
      "Elbow ditemukan pada k = 4 dengan jarak = 0.24424759059880363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PREPROCESS_OPTS = dict(\n",
    "    preprocess=True,          \n",
    "    scale_method=\"minmax\",     \n",
    "    clip_outliers=True,        \n",
    "    q_low=0.01, q_high=0.99,   \n",
    "    fill_num=\"median\",         \n",
    "    fill_cat_label=\"MISSING\",  \n",
    "    rare_thresh=0.01,          \n",
    "    other_label=\"OTHER\",\n",
    "    force_upper=True,          \n",
    "    strip_space=True           \n",
    ")\n",
    "\n",
    "# main\n",
    "processed_any = False\n",
    "errors = []\n",
    "\n",
    "# Konfigurasi\n",
    "FILE_PATH = r\"D:/DATA SKRIPSI/kontrak_sewa_bersih.xlsx\"  # file input\n",
    "PERIOD_SHEETS = [\"Monthly_Fixed\", \"Daily_Fixed\"]  # nama sheet\n",
    "CATEGORICAL_COLS = [\n",
    "    \"BusinessType\",\"LeaseYearStart\",\"LeaseMonthStart\",\"LeaseDayStart\",\n",
    "    \"LeaseYearEnd\",\"LeaseMonthEnd\",\"LeaseDayEnd\",\"TranCode\",\n",
    "    \"ContractPeriod\",\"ContractType\",\"Building\",\"UnitArea\",\"UnitFloor\"\n",
    "]\n",
    "NUMERIC_COLS = [\"BuildingArea\",\"LeaseDurationDays\",\"LeaseDurationMonths\",\"n_subunit\"]\n",
    "K_RANGE = range(2, 7)\n",
    "DROP_COLS = [\"UnitNum\"]\n",
    "\n",
    "in_path = Path(FILE_PATH)\n",
    "out_path = in_path.with_name(f\"{in_path.stem}_clustered{in_path.suffix}\")\n",
    "\n",
    "if out_path.exists():\n",
    "    print(f\"File output sudah ada, menghapus: {out_path}\")\n",
    "    out_path.unlink()\n",
    "\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as ew:\n",
    "    for SHEET_NAME in PERIOD_SHEETS:\n",
    "        try:\n",
    "            print(f\"\\n=== Proses periode: {SHEET_NAME} ===\")\n",
    "            df_raw_full = pd.read_excel(FILE_PATH, sheet_name=SHEET_NAME)\n",
    "\n",
    "            if df_raw_full.shape[0] < 2:\n",
    "                raise ValueError(\"Baris data < 2\")\n",
    "\n",
    "            df_raw = df_raw_full.drop(columns=[\"UnitID\"], errors=\"ignore\").copy()\n",
    "\n",
    "            df_raw = df_raw.drop(columns=[c for c in DROP_COLS if c in df_raw.columns],\n",
    "                                errors=\"ignore\")\n",
    "\n",
    "            for col in NUMERIC_COLS:\n",
    "                if col in df_raw.columns:\n",
    "                    df_raw[col] = pd.to_numeric(df_raw[col], errors=\"coerce\").astype(float)\n",
    "\n",
    "            CATEG_COLS_USED = [c for c in CATEGORICAL_COLS if c in df_raw.columns]\n",
    "            NUMERIC_COLS_USED = [c for c in NUMERIC_COLS if c in df_raw.columns]\n",
    "\n",
    "            df_prep, cat_idx, cat_cols, num_cols = prepare_for_kprototypes(\n",
    "                df_raw,\n",
    "                categorical_cols=CATEG_COLS_USED,\n",
    "                numeric_cols=NUMERIC_COLS_USED,\n",
    "                force_cat_as_str=True,\n",
    "                **PREPROCESS_OPTS\n",
    "            )\n",
    "\n",
    "            gamma = auto_gamma(df_prep, num_cols)\n",
    "            X = df_prep.to_numpy()\n",
    "\n",
    "            elbow_rows = []\n",
    "            for k in K_RANGE:\n",
    "                mk = KPrototypes(\n",
    "                    n_clusters=int(k),\n",
    "                    init=\"Cao\",\n",
    "                    n_init=10,\n",
    "                    max_iter=100,\n",
    "                    random_state=42,\n",
    "                    gamma=gamma\n",
    "                )\n",
    "                mk.fit_predict(X, categorical=cat_idx)\n",
    "                elbow_rows.append({\"k\": int(k), \"cost\": float(mk.cost_), \"n_iter\": mk.n_iter_})\n",
    "\n",
    "            elbow_tbl = pd.DataFrame(elbow_rows).sort_values(\"k\")\n",
    "            FINAL_K = choose_k_by_elbow(elbow_tbl[\"k\"].to_numpy(),\n",
    "                                        elbow_tbl[\"cost\"].to_numpy())\n",
    "\n",
    "            # model final\n",
    "            model_final = KPrototypes(\n",
    "                n_clusters=FINAL_K,\n",
    "                init=\"Cao\",\n",
    "                n_init=15,\n",
    "                max_iter=100,\n",
    "                random_state=42,\n",
    "                gamma=gamma\n",
    "            )\n",
    "            labels = model_final.fit_predict(X, categorical=cat_idx)\n",
    "\n",
    "            # silhouette dan Davies-Bouldin\n",
    "            try:\n",
    "                sil_score = silhouette_kprototypes_mixed(\n",
    "                    df_prep,\n",
    "                    labels,\n",
    "                    cat_idx=cat_idx,\n",
    "                    gamma=gamma,\n",
    "                    max_samples=MAX_SILHOUETTE_SAMPLES,\n",
    "                    random_state=RANDOM_STATE_SIL\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Gagal hitung silhouette di sheet {SHEET_NAME}: {type(e).__name__} - {e}\")\n",
    "                sil_score = np.nan\n",
    "\n",
    "            try:\n",
    "                dbi_mixed = davies_bouldin_mixed(\n",
    "                    df_prep,\n",
    "                    labels,\n",
    "                    cat_cols=cat_cols,\n",
    "                    num_cols=num_cols,\n",
    "                    gamma=gamma\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Gagal hitung DBI di sheet {SHEET_NAME}: {type(e).__name__} - {e}\")\n",
    "                dbi_mixed = np.nan\n",
    "\n",
    "\n",
    "            # output\n",
    "            df_out = df_raw_full.copy()   \n",
    "            df_out[\"cluster\"] = labels    \n",
    "\n",
    "            df_out.to_excel(ew, index=False, sheet_name=f\"{SHEET_NAME}_clustered\")\n",
    "\n",
    "            # metrics + Silhouette & DaviesBouldin\n",
    "            pd.DataFrame({\n",
    "                \"Sheet\": [SHEET_NAME],\n",
    "                \"FINAL_K\": [FINAL_K],\n",
    "                \"Gamma\": [gamma],\n",
    "                \"Rows\": [df_prep.shape[0]],\n",
    "                \"Silhouette\": [sil_score],\n",
    "                \"DaviesBouldin\": [dbi_mixed],\n",
    "            }).to_excel(ew, index=False, sheet_name=f\"{SHEET_NAME}_metrics\")\n",
    "\n",
    "        except Exception as e:\n",
    "            msg = f\"{SHEET_NAME}: {type(e).__name__} - {e}\"\n",
    "            print(\"[ERROR]\", msg)\n",
    "            errors.append({\"sheet\": SHEET_NAME, \"error\": msg})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a02f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
